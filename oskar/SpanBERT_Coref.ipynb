{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coref_CRAFT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKsIN3H3QPBl"
      },
      "source": [
        "### System Installation\n",
        "Installing the coref tool from mandarjoshi90 along with tensorflow.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVxSDHkTAhjr"
      },
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99iZoir6JkCM"
      },
      "source": [
        "! python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g07Sx5jqQbPw"
      },
      "source": [
        "! git clone https://github.com/mandarjoshi90/coref.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mHoDEKQdLu"
      },
      "source": [
        "%cd coref\n",
        "! sed 's/MarkupSafe==1.0/MarkupSafe==1.1.1/; s/scikit-learn==0.19.1/scikit-learn==0.21/; s/scipy==1.0.0/scipy==1.6.2/' < requirements.txt > tmp\n",
        "! mv tmp requirements.txt\n",
        "\n",
        "! sed 's/.D.GLIBCXX.USE.CXX11.ABI.0//' < setup_all.sh  > tmp\n",
        "! mv tmp setup_all.sh \n",
        "! chmod u+x setup_all.sh "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cABghgMnQgkw"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "! pip uninstall -y tensorflow\n",
        "! pip install -r requirements.txt --log install-log.txt -q\n",
        "! ./setup_all.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtaUoOBJkNDw"
      },
      "source": [
        "### Specifying Input\n",
        "\n",
        "Input and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuq5EkiiqkpW",
        "outputId": "bf67fc4a-37a1-4410-b88a-e87884c0483a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaFGGbm2QN7r"
      },
      "source": [
        "genre = \"nw\"\n",
        "# The Ontonotes data for training the model contains text from several sources\n",
        "# of very different styles. You need to specify the most suitable one out of:\n",
        "# \"bc\": broadcast conversation\n",
        "# \"bn\": broadcast news\n",
        "# \"mz\": magazine\n",
        "# \"nw\": newswire\n",
        "# \"pt\": Bible text\n",
        "# \"tc\": telephone conversation\n",
        "# \"wb\": web data\n",
        "\n",
        "model_name = \"spanbert_base\"\n",
        "# The fine-tuned model to use. Options are:\n",
        "# bert_base\n",
        "# spanbert_base\n",
        "# bert_large\n",
        "# spanbert_large"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ163Z2uQevj"
      },
      "source": [
        "import os\n",
        "os.environ['data_dir'] = \"./data\"\n",
        "os.environ['CHOSEN_MODEL'] = model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi0-5VN-kr6N"
      },
      "source": [
        "Downloading the selected model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klQ48SSkQiWG"
      },
      "source": [
        "! ./download_pretrained.sh $CHOSEN_MODEL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDl_lF2EkyCx"
      },
      "source": [
        "## Splitting into chunks and merging.\n",
        "Choose the directory for the data. \n",
        "The input should be in the CoNLL format.\n",
        "Preferably without discontinous spans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khi-1IiWVkQi"
      },
      "source": [
        "import os\n",
        "\n",
        "# Change for each set.\n",
        "output = \"./data/dev.english.v4_gold_conll\"\n",
        "input = \"../CRAFT-conll/dev\"\n",
        "\n",
        "# Number of sentences to split on.\n",
        "N = 200\n",
        "\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "# Clears the current file from data.\n",
        "open(output, 'w').close()\n",
        "\n",
        "for file in [f for f in os.listdir(input) if f.endswith('.conll')]:\n",
        "\n",
        "  with open(input + \"/\" + file) as f_in:\n",
        "    \n",
        "    first_line = f_in.readline()\n",
        "\n",
        "    paragraphs = [line.split('\\n') for line in f_in.read().split('\\n\\n') if line]\n",
        "\n",
        "    chs = chunks(paragraphs, N)\n",
        "\n",
        "    with open(output, \"a\") as f_out:\n",
        "      \n",
        "      for idx, ch in enumerate(chs):\n",
        "        \n",
        "        f_out.write(first_line[0:-2] + str(idx) + \"\\n\")\n",
        "        \n",
        "        for paragraph in ch:\n",
        "          for line in paragraph:\n",
        "            parts = line.split()\n",
        "            parts[1] = idx\n",
        "            f_out.write(' '.join([str(p) for p in parts[0:2]]) + ' ' + '\\t'.join([str(p) for p in parts[2:]]) + \"\\n\")\n",
        "          f_out.write('\\n')\n",
        "        f_out.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpO9A5PWGYV"
      },
      "source": [
        "! ./setup_training.sh $data_dir $data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYbt9vAdW6dv"
      },
      "source": [
        "## Choose vocab file and data directory. \n",
        "\n",
        "Generates JSONline files from conll files. Change in experiments file for file names etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt44gUNvnNol"
      },
      "source": [
        "! python minimize.py ./data/cased_L-24_H-1024_A-16/vocab.txt ./data/ ./data/ true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XyK1DXUXGnq"
      },
      "source": [
        "Trains a new model. Choose starting model. Models without train prefix is finetuned on OntoNotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mSy_X25Xq7d"
      },
      "source": [
        "! GPU=0 python train.py train_spanbert_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9RcLDGBNWM7"
      },
      "source": [
        "### Evaluating\n",
        "Choose the model to evaluate. The evaluation script provided offical CoNLL-2012 score.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmpPpAAX6zrK"
      },
      "source": [
        "! gpu=0 python evaluate.py $CHOSEN_MODEL"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}