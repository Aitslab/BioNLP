{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coref_CRAFT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKsIN3H3QPBl"
      },
      "source": [
        "### System Installation\n",
        "Installing the coref tool from mandarjoshi90 along with tensorflow.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVxSDHkTAhjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287d5346-1a49-405e-fa26-343d24d373f4"
      },
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla K80, 460.32.03, 11441 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g07Sx5jqQbPw",
        "outputId": "caa33a34-0161-4d19-98a8-d9b97cda8d08"
      },
      "source": [
        "! git clone https://github.com/mandarjoshi90/coref.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'coref'...\n",
            "remote: Enumerating objects: 734, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 734 (delta 2), reused 0 (delta 0), pack-reused 728\u001b[K\n",
            "Receiving objects: 100% (734/734), 4.17 MiB | 11.31 MiB/s, done.\n",
            "Resolving deltas: 100% (441/441), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mHoDEKQdLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492fe899-ce7d-48b9-ef96-3e5ef92b4a14"
      },
      "source": [
        "%cd coref\n",
        "! sed 's/MarkupSafe==1.0/MarkupSafe==1.1.1/; s/scikit-learn==0.19.1/scikit-learn==0.21/; s/scipy==1.0.0/scipy==1.6.2/' < requirements.txt > tmp\n",
        "! mv tmp requirements.txt\n",
        "\n",
        "! sed 's/.D.GLIBCXX.USE.CXX11.ABI.0//' < setup_all.sh  > tmp\n",
        "! mv tmp setup_all.sh \n",
        "! chmod u+x setup_all.sh "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/coref\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cABghgMnQgkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac25933-1de0-4d9d-a1db-983e72c67df5"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "! pip uninstall -y tensorflow\n",
        "! pip install -r requirements.txt --log install-log.txt -q\n",
        "! ./setup_all.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 28.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 36.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6MB 20.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 22.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 37.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 31.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 43.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 38.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.3MB 2.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 14.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 32.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 430kB 30.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 38.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 43.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 33.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 16.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 27.4MB 102kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 27.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 491kB 36.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 377.1MB 43kB/s \n",
            "\u001b[K     |████████████████████████████████| 748.9MB 13kB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8MB 25.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 327kB 49.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 41.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1MB 29.2MB/s \n",
            "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for h5py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for JPype1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mmh3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for msgpack-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for psycopg2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyhocon (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-metadata 0.30.0 has requirement absl-py<0.13,>=0.9, but you'll have absl-py 0.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyasn1-modules 0.2.8 has requirement pyasn1<0.5.0,>=0.4.6, but you'll have pyasn1 0.4.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.1.5 has requirement python-dateutil>=2.7.3, but you'll have python-dateutil 2.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.9.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement astor~=0.8.1, but you'll have astor 0.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.9.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flask 1.1.2 has requirement Jinja2>=2.10.1, but you'll have jinja2 2.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flask 1.1.2 has requirement Werkzeug>=0.15, but you'll have werkzeug 0.14.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement python-dateutil>=2.8.0, but you'll have python-dateutil 2.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.3.2 has requirement pillow>=7.1.0, but you'll have pillow 6.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSfzbpk2oVsQ",
        "outputId": "94a69fb1-c529-438a-a443-1e8857cc7c9c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtaUoOBJkNDw"
      },
      "source": [
        "### Specifying Input\n",
        "\n",
        "Input and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuq5EkiiqkpW",
        "outputId": "b919793b-d251-4cb0-8dfc-50bdc932faaa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaFGGbm2QN7r"
      },
      "source": [
        "genre = \"nw\"\n",
        "# The Ontonotes data for training the model contains text from several sources\n",
        "# of very different styles. You need to specify the most suitable one out of:\n",
        "# \"bc\": broadcast conversation\n",
        "# \"bn\": broadcast news\n",
        "# \"mz\": magazine\n",
        "# \"nw\": newswire\n",
        "# \"pt\": Bible text\n",
        "# \"tc\": telephone conversation\n",
        "# \"wb\": web data\n",
        "\n",
        "model_name = \"spanbert_base\"\n",
        "# The fine-tuned model to use. Options are:\n",
        "# bert_base\n",
        "# spanbert_base\n",
        "# bert_large\n",
        "# spanbert_large"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ163Z2uQevj"
      },
      "source": [
        "import os\n",
        "os.environ['data_dir'] = \"./data\"\n",
        "os.environ['CHOSEN_MODEL'] = model_name"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi0-5VN-kr6N"
      },
      "source": [
        "Downloading the selected model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klQ48SSkQiWG",
        "outputId": "cceb3a3e-3d03-4f3a-df59-5a4d7fb95f13"
      },
      "source": [
        "! ./download_pretrained.sh $CHOSEN_MODEL"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading spanbert_base\n",
            "--2021-05-17 12:46:11--  http://nlp.cs.washington.edu/pair2vec/spanbert_base.tar.gz\n",
            "Resolving nlp.cs.washington.edu (nlp.cs.washington.edu)... 128.208.3.120, 2607:4000:200:12::78\n",
            "Connecting to nlp.cs.washington.edu (nlp.cs.washington.edu)|128.208.3.120|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1633726311 (1.5G) [application/x-gzip]\n",
            "/content/gdrive/CRAFT-conll/train: No such file or directory\n",
            "/content/gdrive/CRAFT-conll/train/spanbert_base.tar.gz: No such file or directory\n",
            "\n",
            "Cannot write to ‘/content/gdrive/CRAFT-conll/train/spanbert_base.tar.gz’ (No such file or directory).\n",
            "tar (child): /content/gdrive/CRAFT-conll/train//spanbert_base.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "rm: cannot remove '/content/gdrive/CRAFT-conll/train//spanbert_base.tar.gz': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDl_lF2EkyCx"
      },
      "source": [
        "Process the data to be in the required input format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-rCm36PQlaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a496a4b-616c-4f28-a37e-17e3a7bdcc8c"
      },
      "source": [
        "from bert import tokenization\n",
        "import json\n",
        "\n",
        "\n",
        "def tokenize(data):\n",
        "  data = {\n",
        "      'doc_key': genre,\n",
        "      'sentences': [[\"[CLS]\"]],\n",
        "      'speakers': [[\"[SPL]\"]],\n",
        "      'clusters': [],\n",
        "      'sentence_map': [0],\n",
        "      'subtoken_map': [0],\n",
        "  }\n",
        "\n",
        "  # Determine Max Segment\n",
        "  max_segment = None\n",
        "  for line in open('experiments.conf'):\n",
        "      if line.startswith(model_name):\n",
        "          max_segment = True\n",
        "      elif line.strip().startswith(\"max_segment_len\"):\n",
        "          if max_segment:\n",
        "              max_segment = int(line.strip().split()[-1])\n",
        "              break\n",
        "\n",
        "  tokenizer = tokenization.FullTokenizer(vocab_file=\"cased_config_vocab/vocab.txt\", do_lower_case=False)\n",
        "  subtoken_num = 0\n",
        "  for sent_num, line in enumerate(text):\n",
        "      raw_tokens = line.split()\n",
        "      tokens = tokenizer.tokenize(line)\n",
        "      if len(tokens) + len(data['sentences'][-1]) >= max_segment:\n",
        "          data['sentences'][-1].append(\"[SEP]\")\n",
        "          data['sentences'].append([\"[CLS]\"])\n",
        "          data['speakers'][-1].append(\"[SPL]\")\n",
        "          data['speakers'].append([\"[SPL]\"])\n",
        "          data['sentence_map'].append(sent_num - 1)\n",
        "          data['subtoken_map'].append(subtoken_num - 1)\n",
        "          data['sentence_map'].append(sent_num)\n",
        "          data['subtoken_map'].append(subtoken_num)\n",
        "\n",
        "      ctoken = raw_tokens[0]\n",
        "      cpos = 0\n",
        "      for token in tokens:\n",
        "          data['sentences'][-1].append(token)\n",
        "          data['speakers'][-1].append(\"-\")\n",
        "          data['sentence_map'].append(sent_num)\n",
        "          data['subtoken_map'].append(subtoken_num)\n",
        "          \n",
        "          if token.startswith(\"##\"):\n",
        "              token = token[2:]\n",
        "          if len(ctoken) == len(token):\n",
        "              subtoken_num += 1\n",
        "              cpos += 1\n",
        "              if cpos < len(raw_tokens):\n",
        "                  ctoken = raw_tokens[cpos]\n",
        "          else:\n",
        "              ctoken = ctoken[len(token):]\n",
        "\n",
        "  data['sentences'][-1].append(\"[SEP]\")\n",
        "  data['speakers'][-1].append(\"[SPL]\")\n",
        "  data['sentence_map'].append(sent_num - 1)\n",
        "  data['subtoken_map'].append(subtoken_num - 1)\n",
        "\n",
        "  return data\n",
        "\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p8BPjDcW4Iw"
      },
      "source": [
        "%mkdir ./data/training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO-ZodXJWXsH"
      },
      "source": [
        "os.environ['train_dir'] = \"/content/gdrive/MyDrive/CRAFT-conll/train/\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gGI0HaVrXDAa",
        "outputId": "54dad5de-1f9d-4fd2-ceab-f912dee2cf26"
      },
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/gdrive/MyDrive/CRAFT-conll/train/11532192.conll\"\n",
        "dst = \"./data/dev.english.v4_gold_conll\"\n",
        "shutil.copy(src,dst)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data/dev.english.v4_gold_conll'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpO9A5PWGYV"
      },
      "source": [
        "! ./setup_training.sh $train_dir $data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt44gUNvnNol",
        "outputId": "502c108a-b60e-4bf2-d48e-edc1716b4c80"
      },
      "source": [
        "! python minimize.py ./data/cased_L-24_H-1024_A-16/vocab.txt ./data/ ./data/ true"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0517 14:18:54.853331 140641810442112 deprecation_wrapper.py:119] From /content/coref/coref_ops.py:11: The name tf.NotDifferentiable is deprecated. Please use tf.no_gradient instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "W0517 14:18:54.901455 140641810442112 deprecation_wrapper.py:119] From /content/coref/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0517 14:18:56.085528 140641810442112 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "True\n",
            "W0517 14:18:56.085999 140641810442112 deprecation_wrapper.py:119] From /content/coref/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Minimizing ./data//dev.english.v4_gold_conll\n",
            "Wrote 1 documents to ./data//dev.english.128.jsonlines\n",
            "Minimizing ./data//train.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//train.english.128.jsonlines\n",
            "Minimizing ./data//test.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//test.english.128.jsonlines\n",
            "Minimizing ./data//dev.english.v4_gold_conll\n",
            "Wrote 1 documents to ./data//dev.english.256.jsonlines\n",
            "Minimizing ./data//train.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//train.english.256.jsonlines\n",
            "Minimizing ./data//test.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//test.english.256.jsonlines\n",
            "Minimizing ./data//dev.english.v4_gold_conll\n",
            "Wrote 1 documents to ./data//dev.english.384.jsonlines\n",
            "Minimizing ./data//train.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//train.english.384.jsonlines\n",
            "Minimizing ./data//test.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//test.english.384.jsonlines\n",
            "Minimizing ./data//dev.english.v4_gold_conll\n",
            "Wrote 1 documents to ./data//dev.english.512.jsonlines\n",
            "Minimizing ./data//train.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//train.english.512.jsonlines\n",
            "Minimizing ./data//test.english.v4_gold_conll\n",
            "Wrote 0 documents to ./data//test.english.512.jsonlines\n",
            "max_sent_len_english = 308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mSy_X25Xq7d",
        "outputId": "d6b38f13-df20-46dd-816b-b3894c977505"
      },
      "source": [
        "! GPU=0 python train.py train_spanbert_base"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0517 14:36:16.577187 140172378666880 deprecation_wrapper.py:119] From /content/coref/coref_ops.py:11: The name tf.NotDifferentiable is deprecated. Please use tf.no_gradient instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "W0517 14:36:16.629981 140172378666880 deprecation_wrapper.py:119] From /content/coref/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0517 14:36:17.776906 140172378666880 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Setting CUDA_VISIBLE_DEVICES to: 0\n",
            "Running experiment: train_spanbert_base\n",
            "data_dir = \"/sdb/data/new_coref\"\n",
            "model_type = \"independent\"\n",
            "max_top_antecedents = 50\n",
            "max_training_sentences = 3\n",
            "top_span_ratio = 0.4\n",
            "max_num_speakers = 20\n",
            "max_segment_len = 384\n",
            "bert_learning_rate = 2e-05\n",
            "task_learning_rate = 0.0001\n",
            "num_docs = 2802\n",
            "dropout_rate = 0.3\n",
            "ffnn_size = 3000\n",
            "ffnn_depth = 1\n",
            "num_epochs = 20\n",
            "feature_size = 20\n",
            "max_span_width = 30\n",
            "use_metadata = true\n",
            "use_features = true\n",
            "use_segment_distance = true\n",
            "model_heads = true\n",
            "coref_depth = 2\n",
            "coarse_to_fine = true\n",
            "fine_grained = true\n",
            "use_prior = true\n",
            "train_path = \"./data/train.english.384.jsonlines\"\n",
            "eval_path = \"./data/dev.english.384.jsonlines\"\n",
            "conll_eval_path = \"./data/dev.english.v4_gold_conll\"\n",
            "single_example = true\n",
            "genres = [\n",
            "  \"bc\"\n",
            "  \"bn\"\n",
            "  \"mz\"\n",
            "  \"nw\"\n",
            "  \"pt\"\n",
            "  \"tc\"\n",
            "  \"wb\"\n",
            "]\n",
            "eval_frequency = 1000\n",
            "report_frequency = 100\n",
            "log_root = \"./data\"\n",
            "adam_eps = 1e-06\n",
            "task_optimizer = \"adam\"\n",
            "bert_config_file = \"./data/spanbert_base/bert_config.json\"\n",
            "vocab_file = \"./data/spanbert_base/vocab.txt\"\n",
            "tf_checkpoint = \"./data/cased_L-12_H-768_A-12/bert_model.ckpt\"\n",
            "init_checkpoint = \"./data/spanbert_hf_base/pytorch_model.bin\"\n",
            "log_dir = \"./data/train_spanbert_base\"\n",
            "W0517 14:36:17.860317 140172378666880 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0517 14:36:17.941668 140172378666880 deprecation_wrapper.py:119] From /content/coref/independent.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0517 14:36:17.948824 140172378666880 deprecation_wrapper.py:119] From /content/coref/independent.py:50: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "W0517 14:36:17.952286 140172378666880 deprecation.py:323] From /content/coref/bert/modeling.py:158: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 14:36:17.967857 140172378666880 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0517 14:36:17.968030 140172378666880 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:175: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0517 14:36:18.052723 140172378666880 deprecation.py:506] From /content/coref/bert/modeling.py:362: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0517 14:36:18.103570 140172378666880 deprecation.py:323] From /content/coref/bert/modeling.py:676: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0517 14:36:21.349456 140172378666880 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0517 14:36:21.448094 140172378666880 deprecation.py:323] From /content/coref/independent.py:221: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 14:36:21.503935 140172378666880 deprecation_wrapper.py:119] From /content/coref/util.py:117: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
            "\n",
            "WARNING: bert/pooler/dense/bias not found in original model.\n",
            "WARNING: bert/pooler/dense/kernel not found in original model.\n",
            "**** Trainable Variables ****\n",
            "  name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = span_width_embeddings:0, shape = (30, 20)\n",
            "  name = mention_word_attn/output_weights:0, shape = (768, 1)\n",
            "  name = mention_word_attn/output_bias:0, shape = (1,)\n",
            "  name = mention_scores/hidden_weights_0:0, shape = (2324, 3000)\n",
            "  name = mention_scores/hidden_bias_0:0, shape = (3000,)\n",
            "  name = mention_scores/output_weights:0, shape = (3000, 1)\n",
            "  name = mention_scores/output_bias:0, shape = (1,)\n",
            "  name = span_width_prior_embeddings:0, shape = (30, 20)\n",
            "  name = width_scores/hidden_weights_0:0, shape = (20, 3000)\n",
            "  name = width_scores/hidden_bias_0:0, shape = (3000,)\n",
            "  name = width_scores/output_weights:0, shape = (3000, 1)\n",
            "  name = width_scores/output_bias:0, shape = (1,)\n",
            "  name = genre_embeddings:0, shape = (7, 20)\n",
            "  name = src_projection/output_weights:0, shape = (2324, 2324)\n",
            "  name = src_projection/output_bias:0, shape = (2324,)\n",
            "  name = antecedent_distance_emb:0, shape = (10, 20)\n",
            "  name = output_weights:0, shape = (20, 1)\n",
            "  name = output_bias:0, shape = (1,)\n",
            "  name = coref_layer/same_speaker_emb:0, shape = (2, 20)\n",
            "  name = coref_layer/antecedent_distance_emb:0, shape = (10, 20)\n",
            "  name = coref_layer/segment_distance/segment_distance_embeddings:0, shape = (3, 20)\n",
            "  name = coref_layer/slow_antecedent_scores/hidden_weights_0:0, shape = (7052, 3000)\n",
            "  name = coref_layer/slow_antecedent_scores/hidden_bias_0:0, shape = (3000,)\n",
            "  name = coref_layer/slow_antecedent_scores/output_weights:0, shape = (3000, 1)\n",
            "  name = coref_layer/slow_antecedent_scores/output_bias:0, shape = (1,)\n",
            "  name = coref_layer/f/output_weights:0, shape = (4648, 2324)\n",
            "  name = coref_layer/f/output_bias:0, shape = (2324,)\n",
            "W0517 14:36:25.496225 140172378666880 deprecation_wrapper.py:119] From /content/coref/independent.py:74: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0517 14:36:25.502846 140172378666880 deprecation_wrapper.py:119] From /content/coref/optimization.py:13: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0517 14:36:25.507193 140172378666880 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0517 14:36:25.531114 140172378666880 deprecation_wrapper.py:119] From /content/coref/optimization.py:64: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "bert:task 199 27\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "W0517 14:36:36.930600 140172378666880 deprecation_wrapper.py:119] From train.py:24: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0517 14:36:37.589986 140172378666880 deprecation_wrapper.py:119] From train.py:28: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2021-05-17 14:36:37.591572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-17 14:36:37.616108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.617037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-05-17 14:36:37.617118: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-05-17 14:36:37.618552: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-05-17 14:36:37.619872: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-05-17 14:36:37.620313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-05-17 14:36:37.622050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-05-17 14:36:37.623263: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-05-17 14:36:37.627072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-05-17 14:36:37.627238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.628204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.629054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-05-17 14:36:37.629411: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-05-17 14:36:37.634409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-05-17 14:36:37.634759: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5576f862c000 executing computations on platform Host. Devices:\n",
            "2021-05-17 14:36:37.634795: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-05-17 14:36:37.740862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.741735: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5576f862c1c0 executing computations on platform CUDA. Devices:\n",
            "2021-05-17 14:36:37.741769: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-05-17 14:36:37.741988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.742684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-05-17 14:36:37.742748: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-05-17 14:36:37.742810: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-05-17 14:36:37.742873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-05-17 14:36:37.742926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-05-17 14:36:37.742968: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-05-17 14:36:37.743007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-05-17 14:36:37.743046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-05-17 14:36:37.743138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.743974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:37.744711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-05-17 14:36:37.744783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-05-17 14:36:39.342202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-17 14:36:39.342311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-05-17 14:36:39.342353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-05-17 14:36:39.342679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:39.343425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 14:36:39.344133: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-05-17 14:36:39.344184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10562 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-05-17 14:37:09.786442: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "I0517 14:37:11.861484 140172378666880 train.py:58] [0] loss=6.95, steps/s=0.00\n",
            "I0517 14:39:55.531178 140172378666880 train.py:58] [100] loss=14.08, steps/s=0.57\n",
            "I0517 14:42:39.704953 140172378666880 train.py:58] [200] loss=2.44, steps/s=0.59\n",
            "I0517 14:45:21.607168 140172378666880 train.py:58] [300] loss=0.00, steps/s=0.60\n",
            "I0517 14:48:03.053545 140172378666880 train.py:58] [400] loss=0.00, steps/s=0.60\n",
            "I0517 14:50:48.486391 140172378666880 train.py:58] [500] loss=0.00, steps/s=0.60\n",
            "I0517 14:53:32.361874 140172378666880 train.py:58] [600] loss=0.00, steps/s=0.61\n",
            "I0517 14:56:12.355104 140172378666880 train.py:58] [700] loss=0.00, steps/s=0.61\n",
            "I0517 14:58:55.046746 140172378666880 train.py:58] [800] loss=0.00, steps/s=0.61\n",
            "I0517 15:01:36.092754 140172378666880 train.py:58] [900] loss=0.00, steps/s=0.61\n",
            "I0517 15:04:16.873461 140172378666880 train.py:58] [1000] loss=0.00, steps/s=0.61\n",
            "Loaded 1 eval examples.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "Evaluated 1/1 examples.\n",
            "Average F1 (py): 27.93% on 1 docs\n",
            "Average precision (py): 100.00%\n",
            "Average recall (py): 16.44%\n",
            "I0517 15:05:35.961914 140172378666880 train.py:73] [1000] evaL_f1=0.2793, max_f1=0.2793\n",
            "I0517 15:08:19.582908 140172378666880 train.py:58] [1100] loss=0.00, steps/s=0.59\n",
            "I0517 15:11:03.112078 140172378666880 train.py:58] [1200] loss=1.01, steps/s=0.59\n",
            "I0517 15:13:43.594213 140172378666880 train.py:58] [1300] loss=0.00, steps/s=0.59\n",
            "I0517 15:16:25.421117 140172378666880 train.py:58] [1400] loss=0.00, steps/s=0.59\n",
            "I0517 15:19:08.078759 140172378666880 train.py:58] [1500] loss=0.00, steps/s=0.59\n",
            "I0517 15:21:50.511204 140172378666880 train.py:58] [1600] loss=0.02, steps/s=0.59\n",
            "I0517 15:24:31.399742 140172378666880 train.py:58] [1700] loss=6.70, steps/s=0.60\n",
            "I0517 15:27:14.173158 140172378666880 train.py:58] [1800] loss=0.35, steps/s=0.60\n",
            "I0517 15:29:59.336722 140172378666880 train.py:58] [1900] loss=0.00, steps/s=0.60\n",
            "I0517 15:32:41.248523 140172378666880 train.py:58] [2000] loss=0.00, steps/s=0.60\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "Evaluated 1/1 examples.\n",
            "Average F1 (py): 57.83% on 1 docs\n",
            "Average precision (py): 100.00%\n",
            "Average recall (py): 43.66%\n",
            "I0517 15:33:58.320623 140172378666880 train.py:73] [2000] evaL_f1=0.5783, max_f1=0.5783\n",
            "I0517 15:36:41.606769 140172378666880 train.py:58] [2100] loss=0.00, steps/s=0.59\n",
            "I0517 15:39:24.138938 140172378666880 train.py:58] [2200] loss=0.00, steps/s=0.59\n",
            "I0517 15:42:05.634005 140172378666880 train.py:58] [2300] loss=0.00, steps/s=0.59\n",
            "I0517 15:44:46.873790 140172378666880 train.py:58] [2400] loss=0.00, steps/s=0.59\n",
            "I0517 15:47:27.425251 140172378666880 train.py:58] [2500] loss=0.00, steps/s=0.59\n",
            "I0517 15:50:09.571051 140172378666880 train.py:58] [2600] loss=0.00, steps/s=0.59\n",
            "I0517 15:52:50.874973 140172378666880 train.py:58] [2700] loss=0.00, steps/s=0.59\n",
            "I0517 15:55:33.810058 140172378666880 train.py:58] [2800] loss=0.00, steps/s=0.59\n",
            "I0517 15:58:18.426934 140172378666880 train.py:58] [2900] loss=0.00, steps/s=0.59\n",
            "I0517 16:01:01.420317 140172378666880 train.py:58] [3000] loss=0.00, steps/s=0.60\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "Evaluated 1/1 examples.\n",
            "Average F1 (py): 57.83% on 1 docs\n",
            "Average precision (py): 100.00%\n",
            "Average recall (py): 43.66%\n",
            "I0517 16:01:25.302174 140172378666880 train.py:73] [3000] evaL_f1=0.5783, max_f1=0.5783\n",
            "I0517 16:04:11.395129 140172378666880 train.py:58] [3100] loss=0.00, steps/s=0.59\n",
            "I0517 16:06:56.283163 140172378666880 train.py:58] [3200] loss=0.00, steps/s=0.59\n",
            "I0517 16:09:38.180149 140172378666880 train.py:58] [3300] loss=0.00, steps/s=0.59\n",
            "I0517 16:12:21.582517 140172378666880 train.py:58] [3400] loss=0.00, steps/s=0.59\n",
            "I0517 16:15:03.741584 140172378666880 train.py:58] [3500] loss=0.00, steps/s=0.59\n",
            "I0517 16:17:46.237050 140172378666880 train.py:58] [3600] loss=0.00, steps/s=0.60\n",
            "I0517 16:20:27.789189 140172378666880 train.py:58] [3700] loss=0.00, steps/s=0.60\n",
            "I0517 16:23:10.866888 140172378666880 train.py:58] [3800] loss=0.00, steps/s=0.60\n",
            "I0517 16:25:52.054297 140172378666880 train.py:58] [3900] loss=0.00, steps/s=0.60\n",
            "I0517 16:28:33.916373 140172378666880 train.py:58] [4000] loss=0.00, steps/s=0.60\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "Evaluated 1/1 examples.\n",
            "Average F1 (py): 57.83% on 1 docs\n",
            "Average precision (py): 100.00%\n",
            "Average recall (py): 43.66%\n",
            "I0517 16:28:57.617251 140172378666880 train.py:73] [4000] evaL_f1=0.5783, max_f1=0.5783\n",
            "I0517 16:31:39.611765 140172378666880 train.py:58] [4100] loss=0.00, steps/s=0.60\n",
            "I0517 16:34:20.818515 140172378666880 train.py:58] [4200] loss=0.00, steps/s=0.60\n",
            "I0517 16:37:01.703032 140172378666880 train.py:58] [4300] loss=0.00, steps/s=0.60\n",
            "I0517 16:39:44.611243 140172378666880 train.py:58] [4400] loss=0.00, steps/s=0.60\n",
            "I0517 16:42:26.601536 140172378666880 train.py:58] [4500] loss=0.00, steps/s=0.60\n",
            "I0517 16:45:08.220921 140172378666880 train.py:58] [4600] loss=0.00, steps/s=0.60\n",
            "I0517 16:47:50.891090 140172378666880 train.py:58] [4700] loss=0.00, steps/s=0.60\n",
            "I0517 16:50:33.419600 140172378666880 train.py:58] [4800] loss=0.00, steps/s=0.60\n",
            "I0517 16:53:15.040124 140172378666880 train.py:58] [4900] loss=0.00, steps/s=0.60\n",
            "I0517 16:55:58.830313 140172378666880 train.py:58] [5000] loss=0.00, steps/s=0.60\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "Evaluated 1/1 examples.\n",
            "Average F1 (py): 57.83% on 1 docs\n",
            "Average precision (py): 100.00%\n",
            "Average recall (py): 43.66%\n",
            "I0517 16:56:24.765374 140172378666880 train.py:73] [5000] evaL_f1=0.5783, max_f1=0.5783\n",
            "I0517 16:59:08.122755 140172378666880 train.py:58] [5100] loss=0.00, steps/s=0.60\n",
            "I0517 17:01:51.615872 140172378666880 train.py:58] [5200] loss=0.00, steps/s=0.60\n",
            "I0517 17:04:34.076279 140172378666880 train.py:58] [5300] loss=0.00, steps/s=0.60\n",
            "I0517 17:07:14.614139 140172378666880 train.py:58] [5400] loss=0.00, steps/s=0.60\n",
            "I0517 17:09:57.621378 140172378666880 train.py:58] [5500] loss=0.00, steps/s=0.60\n",
            "I0517 17:12:43.270147 140172378666880 train.py:58] [5600] loss=0.00, steps/s=0.60\n",
            "I0517 17:15:23.748881 140172378666880 train.py:58] [5700] loss=0.00, steps/s=0.60\n",
            "I0517 17:18:05.130971 140172378666880 train.py:58] [5800] loss=0.00, steps/s=0.60\n",
            "I0517 17:20:46.393890 140172378666880 train.py:58] [5900] loss=0.00, steps/s=0.60\n",
            "I0517 17:23:29.917060 140172378666880 train.py:58] [6000] loss=0.00, steps/s=0.60\n",
            "W0517 17:23:43.389366 140172378666880 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "Evaluated 1/1 examples.\n",
            "Average F1 (py): 57.83% on 1 docs\n",
            "Average precision (py): 100.00%\n",
            "Average recall (py): 43.66%\n",
            "I0517 17:23:53.527279 140172378666880 train.py:73] [6000] evaL_f1=0.5783, max_f1=0.5783\n",
            "2021-05-17 17:26:20.642755: W tensorflow/core/kernels/queue_base.cc:277] _0_padding_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 49, in <module>\n",
            "    tf_loss, tf_global_step, _ = session.run([model.loss, model.global_step, model.train_op])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 950, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuC9mlsWkTuP"
      },
      "source": [
        "## Prediction & Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDJeLUoSV7kK"
      },
      "source": [
        "%mkdir ./data/in\n",
        "%mkdir ./data/out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "G1-ECn2LVrlv",
        "outputId": "5d9f0f27-c6a8-49da-f882-855f3db0970e"
      },
      "source": [
        "import subprocess\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "filename = \"/content/gdrive/MyDrive/CRAFT-txt/dev/17194222.txt\"\n",
        "text = []\n",
        "data = []\n",
        "\n",
        "with open(filename) as f_in:\n",
        "  \n",
        "  paragraphs = [line for line in f_in.read().split('\\n') if line]\n",
        "\n",
        "  for paragraph in paragraphs:\n",
        "    sentences = tokenizer.tokenize(paragraph)\n",
        "    text.extend(sentences)\n",
        "              \n",
        "chs = list(chunks(text, 100))\n",
        "\n",
        "N = len(chs)\n",
        "\n",
        "for i in range(0, N):\n",
        "  \n",
        "  text = chs[i]\n",
        "  data.append(tokenize(text))\n",
        "\n",
        "  file1 = \"./data/in/\"  + \"test\" + \"_\" + str(i) + \".json\"\n",
        "  file2 = \"./data/out/\" + \"test\" + \"_\" + str(i) + \".jsonlines\"\n",
        "\n",
        "  with open(file1, 'w') as out:\n",
        "    json.dump(data[i], out, sort_keys=True)\n",
        "  \n",
        "  subprocess.call(['python', 'predict.py', 'spanbert_base', file1, file2])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-e88a655ed483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spanbert_base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrQrj-PDW0h4"
      },
      "source": [
        "import subprocess\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "for file in [f for f in os.listdir('/content/gdrive/MyDrive/CRAFT-txt/test') if f.endswith('.txt')]:\n",
        "\n",
        "  text = []\n",
        "  data = []\n",
        "\n",
        "  with open(filename) as f_in:\n",
        "    \n",
        "    paragraphs = [line for line in f_in.read().split('\\n') if line]\n",
        "  \n",
        "    for paragraph in paragraphs:\n",
        "      sentences = tokenizer.tokenize(paragraph)\n",
        "      text.extend(sentences)\n",
        "                \n",
        "  chs = list(chunks(text, 100))\n",
        "\n",
        "  N = len(chs)\n",
        "\n",
        "  for i in range(0, N):\n",
        "    \n",
        "    text = chs[i]\n",
        "    data.append(tokenize(text))\n",
        "\n",
        "    file1 = \"./data/in/\"  + file[0:-4] + \"_\" + str(i) + \".json\"\n",
        "    file2 = \"./data/out/\" + file[0:-4] + \"_\" + str(i) + \".jsonlines\"\n",
        "\n",
        "    with open(file1, 'w') as out:\n",
        "      json.dump(data[i], out, sort_keys=True)\n",
        "    \n",
        "    subprocess.call(['python', 'predict.py', 'spanbert_base', file1, file2])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zniQuqNGQnOk",
        "outputId": "4f661f0d-f695-4927-a080-cd9db933cbcc"
      },
      "source": [
        "! gpu=0 python predict.py train_spanbert_base ./data/in/test_0.json ./data/out/test_0.json"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0517 17:28:26.962475 139812296517504 deprecation_wrapper.py:119] From /content/coref/coref_ops.py:11: The name tf.NotDifferentiable is deprecated. Please use tf.no_gradient instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "W0517 17:28:27.009939 139812296517504 deprecation_wrapper.py:119] From /content/coref/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0517 17:28:28.173907 139812296517504 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running experiment: train_spanbert_base\n",
            "data_dir = \"/sdb/data/new_coref\"\n",
            "model_type = \"independent\"\n",
            "max_top_antecedents = 50\n",
            "max_training_sentences = 3\n",
            "top_span_ratio = 0.4\n",
            "max_num_speakers = 20\n",
            "max_segment_len = 384\n",
            "bert_learning_rate = 2e-05\n",
            "task_learning_rate = 0.0001\n",
            "num_docs = 2802\n",
            "dropout_rate = 0.3\n",
            "ffnn_size = 3000\n",
            "ffnn_depth = 1\n",
            "num_epochs = 20\n",
            "feature_size = 20\n",
            "max_span_width = 30\n",
            "use_metadata = true\n",
            "use_features = true\n",
            "use_segment_distance = true\n",
            "model_heads = true\n",
            "coref_depth = 2\n",
            "coarse_to_fine = true\n",
            "fine_grained = true\n",
            "use_prior = true\n",
            "train_path = \"./data/train.english.384.jsonlines\"\n",
            "eval_path = \"./data/dev.english.384.jsonlines\"\n",
            "conll_eval_path = \"./data/dev.english.v4_gold_conll\"\n",
            "single_example = true\n",
            "genres = [\n",
            "  \"bc\"\n",
            "  \"bn\"\n",
            "  \"mz\"\n",
            "  \"nw\"\n",
            "  \"pt\"\n",
            "  \"tc\"\n",
            "  \"wb\"\n",
            "]\n",
            "eval_frequency = 1000\n",
            "report_frequency = 100\n",
            "log_root = \"./data\"\n",
            "adam_eps = 1e-06\n",
            "task_optimizer = \"adam\"\n",
            "bert_config_file = \"./data/spanbert_base/bert_config.json\"\n",
            "vocab_file = \"./data/spanbert_base/vocab.txt\"\n",
            "tf_checkpoint = \"./data/cased_L-12_H-768_A-12/bert_model.ckpt\"\n",
            "init_checkpoint = \"./data/spanbert_hf_base/pytorch_model.bin\"\n",
            "log_dir = \"./data/train_spanbert_base\"\n",
            "W0517 17:28:28.263999 139812296517504 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0517 17:28:28.345476 139812296517504 deprecation_wrapper.py:119] From /content/coref/independent.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0517 17:28:28.357758 139812296517504 deprecation_wrapper.py:119] From /content/coref/independent.py:50: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "W0517 17:28:28.362063 139812296517504 deprecation.py:323] From /content/coref/bert/modeling.py:158: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 17:28:28.377083 139812296517504 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0517 17:28:28.377259 139812296517504 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:175: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0517 17:28:28.456366 139812296517504 deprecation.py:506] From /content/coref/bert/modeling.py:362: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0517 17:28:28.507446 139812296517504 deprecation.py:323] From /content/coref/bert/modeling.py:676: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0517 17:28:31.766930 139812296517504 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0517 17:28:31.860810 139812296517504 deprecation.py:323] From /content/coref/independent.py:221: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0517 17:28:31.922205 139812296517504 deprecation_wrapper.py:119] From /content/coref/util.py:117: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
            "\n",
            "WARNING: bert/pooler/dense/bias not found in original model.\n",
            "WARNING: bert/pooler/dense/kernel not found in original model.\n",
            "**** Trainable Variables ****\n",
            "  name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = span_width_embeddings:0, shape = (30, 20)\n",
            "  name = mention_word_attn/output_weights:0, shape = (768, 1)\n",
            "  name = mention_word_attn/output_bias:0, shape = (1,)\n",
            "  name = mention_scores/hidden_weights_0:0, shape = (2324, 3000)\n",
            "  name = mention_scores/hidden_bias_0:0, shape = (3000,)\n",
            "  name = mention_scores/output_weights:0, shape = (3000, 1)\n",
            "  name = mention_scores/output_bias:0, shape = (1,)\n",
            "  name = span_width_prior_embeddings:0, shape = (30, 20)\n",
            "  name = width_scores/hidden_weights_0:0, shape = (20, 3000)\n",
            "  name = width_scores/hidden_bias_0:0, shape = (3000,)\n",
            "  name = width_scores/output_weights:0, shape = (3000, 1)\n",
            "  name = width_scores/output_bias:0, shape = (1,)\n",
            "  name = genre_embeddings:0, shape = (7, 20)\n",
            "  name = src_projection/output_weights:0, shape = (2324, 2324)\n",
            "  name = src_projection/output_bias:0, shape = (2324,)\n",
            "  name = antecedent_distance_emb:0, shape = (10, 20)\n",
            "  name = output_weights:0, shape = (20, 1)\n",
            "  name = output_bias:0, shape = (1,)\n",
            "  name = coref_layer/same_speaker_emb:0, shape = (2, 20)\n",
            "  name = coref_layer/antecedent_distance_emb:0, shape = (10, 20)\n",
            "  name = coref_layer/segment_distance/segment_distance_embeddings:0, shape = (3, 20)\n",
            "  name = coref_layer/slow_antecedent_scores/hidden_weights_0:0, shape = (7052, 3000)\n",
            "  name = coref_layer/slow_antecedent_scores/hidden_bias_0:0, shape = (3000,)\n",
            "  name = coref_layer/slow_antecedent_scores/output_weights:0, shape = (3000, 1)\n",
            "  name = coref_layer/slow_antecedent_scores/output_bias:0, shape = (1,)\n",
            "  name = coref_layer/f/output_weights:0, shape = (4648, 2324)\n",
            "  name = coref_layer/f/output_bias:0, shape = (2324,)\n",
            "W0517 17:28:41.606138 139812296517504 deprecation_wrapper.py:119] From /content/coref/independent.py:74: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0517 17:28:41.612516 139812296517504 deprecation_wrapper.py:119] From /content/coref/optimization.py:13: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0517 17:28:41.617071 139812296517504 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0517 17:28:41.642193 139812296517504 deprecation_wrapper.py:119] From /content/coref/optimization.py:64: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "bert:task 199 27\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "W0517 17:28:53.038943 139812296517504 deprecation_wrapper.py:119] From predict.py:22: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2021-05-17 17:28:53.720233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-17 17:28:53.769646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:53.770545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-05-17 17:28:53.770617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-05-17 17:28:53.782684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-05-17 17:28:53.823964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-05-17 17:28:53.830303: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-05-17 17:28:53.840802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-05-17 17:28:53.850471: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-05-17 17:28:53.945814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-05-17 17:28:53.946043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:53.946869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:53.949451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-05-17 17:28:53.951308: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-05-17 17:28:54.023062: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-05-17 17:28:54.023370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56553ac56000 executing computations on platform Host. Devices:\n",
            "2021-05-17 17:28:54.023423: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-05-17 17:28:54.168240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:54.169346: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56553ac561c0 executing computations on platform CUDA. Devices:\n",
            "2021-05-17 17:28:54.169377: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-05-17 17:28:54.169605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:54.170326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-05-17 17:28:54.170398: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-05-17 17:28:54.170473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-05-17 17:28:54.170514: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-05-17 17:28:54.170551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-05-17 17:28:54.170605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-05-17 17:28:54.170641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-05-17 17:28:54.170707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-05-17 17:28:54.170848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:54.171582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:54.172432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-05-17 17:28:54.176351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-05-17 17:28:57.258949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-17 17:28:57.259008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-05-17 17:28:57.259026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-05-17 17:28:57.259551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:57.260464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-17 17:28:57.261185: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-05-17 17:28:57.261239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10562 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Restoring from ./data/train_spanbert_base/model.max.ckpt\n",
            "W0517 17:29:31.306480 139812296517504 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-05-17 17:30:25.022854: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "Decoded 1 examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9RcLDGBNWM7"
      },
      "source": [
        "### Using Evaulate\n",
        "currently not working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmpPpAAX6zrK"
      },
      "source": [
        "! gpu=0 python evaluate.py $CHOSEN_MODEL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI6OkNG-kXIQ"
      },
      "source": [
        "## Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXpA3sW5QpSA",
        "outputId": "a6f1b073-cf39-42c0-ec14-8e21d36bd5be"
      },
      "source": [
        "output = json.load(open(\"./data/out/test_0.json\"))\n",
        "\n",
        "comb_text = [word for sentence in output['sentences'] for word in sentence]\n",
        "\n",
        "def convert_mention(mention):\n",
        "    start = output['subtoken_map'][mention[0]]\n",
        "    end = output['subtoken_map'][mention[1]] + 1\n",
        "    nmention = (start, end)\n",
        "    mtext = ''.join(' '.join(comb_text[mention[0]:mention[1]+1]).split(\" ##\"))\n",
        "    return (nmention, mtext)\n",
        "\n",
        "seen = set()\n",
        "print('Clusters:')\n",
        "for cluster in output['predicted_clusters']:\n",
        "    mapped = []\n",
        "    for mention in cluster:\n",
        "        seen.add(tuple(mention))\n",
        "        mapped.append(convert_mention(mention))\n",
        "    print(mapped, end=\",\\n\")\n",
        "\n",
        "print('\\nMentions:')\n",
        "for mention in output['top_spans']:\n",
        "    if tuple(mention) in seen:\n",
        "        continue\n",
        "    print(convert_mention(mention), end=\",\\n\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clusters:\n",
            "\n",
            "Mentions:\n",
            "((0, 1), 'Gene'),\n",
            "((0, 1), 'Genetic'),\n",
            "((0, 15), 'Genetic Analysis of the Roles of BMP2 , BMP4 , and BMP7 in Limb Patterning and Skeleto'),\n",
            "((6, 7), 'BMP'),\n",
            "((7, 8), 'B'),\n",
            "((7, 8), 'BMP'),\n",
            "((9, 10), 'BMP'),\n",
            "((9, 10), '##MP'),\n",
            "((11, 12), 'Limb'),\n",
            "((12, 13), 'Pat'),\n",
            "((12, 13), 'Pattern'),\n",
            "((14, 15), '##keleto'),\n",
            "((15, 16), 'Abs'),\n",
            "((17, 18), 'mor'),\n",
            "((17, 18), '##or'),\n",
            "((17, 18), '##phogen'),\n",
            "((19, 20), 'B'),\n",
            "((19, 20), 'BMP'),\n",
            "((19, 24), 'BMP ) family members , including BMP2'),\n",
            "((23, 24), '##MP2'),\n",
            "((24, 25), 'BMP'),\n",
            "((26, 27), 'B'),\n",
            "((26, 27), 'BMP'),\n",
            "((26, 27), '##MP'),\n",
            "((30, 32), 'limb development'),\n",
            "((31, 32), 'development'),\n",
            "((32, 33), 'B'),\n",
            "((32, 33), 'BMP'),\n",
            "((32, 48), 'BMPs have been implicated in early limb patterning as well as in the process of skeleto'),\n",
            "((38, 39), 'limb'),\n",
            "((39, 40), 'pattern'),\n",
            "((39, 40), 'patterning'),\n",
            "((47, 48), '##keleto'),\n",
            "((47, 48), '##eto'),\n",
            "((48, 49), 'However ,'),\n",
            "((55, 56), 'emb'),\n",
            "((55, 56), '##b'),\n",
            "((55, 56), '##ryo'),\n",
            "((56, 57), 'lethal'),\n",
            "((56, 57), 'lethality'),\n",
            "((59, 60), 'B'),\n",
            "((59, 60), 'Bmp'),\n",
            "((61, 62), 'B'),\n",
            "((61, 62), 'Bmp'),\n",
            "((61, 62), '##mp'),\n",
            "((67, 68), 'B'),\n",
            "((67, 68), 'BMP'),\n",
            "((67, 85), 'BMP molecules , it has been difficult to decipher the specific roles of these BMP molecules during different stages'),\n",
            "((68, 69), 'molecules'),\n",
            "((69, 70), 'it'),\n",
            "((74, 75), 'de'),\n",
            "((74, 75), 'deci'),\n",
            "((74, 85), 'decipher the specific roles of these BMP molecules during different stages'),\n",
            "((80, 81), 'B'),\n",
            "((80, 81), 'BMP'),\n",
            "((81, 82), 'molecules'),\n",
            "((86, 87), 'limb'),\n",
            "((86, 88), 'limb development'),\n",
            "((89, 90), 'cir'),\n",
            "((89, 90), '##ir'),\n",
            "((90, 92), 'these issues'),\n",
            "((92, 110), 'we have constructed a series of mouse strains lacking one or more of these BMPs , using conditional allele'),\n",
            "((92, 115), 'we have constructed a series of mouse strains lacking one or more of these BMPs , using conditional alleles in the case of Bmp2'),\n",
            "((97, 99), 'of mouse'),\n",
            "((109, 110), 'allele'),\n",
            "((109, 110), '##ele'),\n",
            "((114, 115), 'B'),\n",
            "((114, 115), 'Bmp'),\n",
            "((116, 117), 'B'),\n",
            "((116, 117), 'Bmp'),\n",
            "((124, 125), 'b'),\n",
            "((124, 125), 'bud'),\n",
            "((124, 125), '##ud'),\n",
            "((125, 126), '##chyme'),\n",
            "((125, 126), '##me'),\n",
            "((126, 127), 'Con'),\n",
            "((126, 127), 'Contrar'),\n",
            "((126, 127), '##y'),\n",
            "((134, 135), 'B'),\n",
            "((134, 135), 'BMP'),\n",
            "((134, 149), 'BMPs neither act as secondary signals downstream of Sonic Hedghog ( SHH ) in patterning the anteroposterior'),\n",
            "((134, 135), '##MP'),\n",
            "((143, 144), '##gh'),\n",
            "((143, 144), '##ghog'),\n",
            "((143, 144), '##og'),\n",
            "((144, 145), 'SHH'),\n",
            "((144, 145), '##H'),\n",
            "((146, 147), 'pattern'),\n",
            "((148, 149), 'antero'),\n",
            "((148, 149), '##erior'),\n",
            "((148, 149), '##or'),\n",
            "((155, 156), '##digit'),\n",
            "((159, 161), 'digit identity'),\n",
            "((161, 162), 'We'),\n",
            "((161, 163), 'We do'),\n",
            "((169, 170), 'B'),\n",
            "((169, 170), 'BMP'),\n",
            "((177, 178), 'ch'),\n",
            "((177, 178), 'chond'),\n",
            "((177, 194), ', and hence some chondrogenic condensations fail to form in limbs deficient in both BMP2 and BMP4'),\n",
            "((181, 182), 'ch'),\n",
            "((181, 182), 'chond'),\n",
            "((182, 183), 'conden'),\n",
            "((182, 183), '##den'),\n",
            "((182, 183), '##sation'),\n",
            "((182, 183), '##sations'),\n",
            "((182, 183), '##s'),\n",
            "((191, 192), 'BMP'),\n",
            "((191, 194), 'BMP2 and BMP4'),\n",
            "((193, 194), '##MP'),\n",
            "((193, 194), '##MP4'),\n",
            "((193, 194), '##4'),\n",
            "((197, 198), 'con'),\n",
            "((197, 198), 'conden'),\n",
            "((197, 198), '##den'),\n",
            "((197, 198), '##sation'),\n",
            "((197, 198), '##sations'),\n",
            "((199, 201), 'do form'),\n",
            "((200, 201), 'form'),\n",
            "((202, 203), '##rogenic'),\n",
            "((211, 212), 'BMP'),\n",
            "((213, 214), '##MP'),\n",
            "((213, 214), '##MP7'),\n",
            "((215, 216), 'BMP'),\n",
            "((217, 218), 'B'),\n",
            "((217, 218), '##MP'),\n",
            "((217, 218), '##MP4'),\n",
            "((217, 218), '##4'),\n",
            "((227, 228), 'BMP'),\n",
            "((229, 230), 'BMP'),\n",
            "((234, 235), 'impair'),\n",
            "((236, 237), '##steogen'),\n",
            "((236, 237), '##ogen'),\n",
            "((237, 238), 'Syn'),\n",
            "((237, 238), '##yn'),\n",
            "((238, 240), 'A group'),\n",
            "((240, 242), 'of related'),\n",
            "((242, 244), 'signaling molecules'),\n",
            "((246, 247), 'mor'),\n",
            "((246, 247), 'morphogen'),\n",
            "((246, 247), '##or'),\n",
            "((246, 247), '##phogen'),\n",
            "((248, 249), 'B'),\n",
            "((248, 249), 'BMP'),\n",
            "((248, 249), '##s'),\n",
            "((248, 249), '##s )'),\n",
            "((257, 258), 'formation'),\n",
            "((259, 260), 'the'),\n",
            "((263, 264), 'the'),\n",
            "((263, 265), 'the limbs'),\n",
            "((265, 266), 'However'),\n",
            "((265, 266), 'However ,'),\n",
            "((267, 269), 'different members'),\n",
            "((270, 272), 'this group'),\n",
            "((271, 272), 'group'),\n",
            "((287, 288), 'em'),\n",
            "((287, 288), 'emb'),\n",
            "((287, 288), '##b'),\n",
            "((287, 289), '##ryo and'),\n",
            "((291, 293), 'be redundant'),\n",
            "((303, 304), 'B'),\n",
            "((303, 304), 'BMP'),\n",
            "((318, 320), 'We have'),\n",
            "((331, 333), 'these factors'),\n",
            "((333, 334), 'BMP'),\n",
            "((335, 336), '##MP4'),\n",
            "((337, 338), 'BMP'),\n",
            "((339, 340), 'B'),\n",
            "((339, 340), 'BMP'),\n",
            "((339, 340), '##MP'),\n",
            "((344, 345), 'limb'),\n",
            "((359, 360), '“ pattern'),\n",
            "((359, 360), 'pattern'),\n",
            "((364, 366), 'the limb'),\n",
            "((365, 366), 'limb'),\n",
            "((366, 367), 'we'),\n",
            "((366, 368), 'we find'),\n",
            "((372, 374), 'a role'),\n",
            "((376, 377), 'find ,'),\n",
            "((383, 384), 'B'),\n",
            "((383, 384), 'BMP'),\n",
            "((384, 385), 'signal'),\n",
            "((384, 386), 'signal is'),\n",
            "((388, 390), 'form cart'),\n",
            "((389, 390), 'cart'),\n",
            "((393, 394), 'cart'),\n",
            "((393, 394), 'cartila'),\n",
            "((394, 395), 'elements'),\n",
            "((403, 404), 'BMP'),\n",
            "((405, 406), '##MP'),\n",
            "((405, 406), '##MP4'),\n",
            "((411, 413), 'these two'),\n",
            "((413, 414), 'B'),\n",
            "((413, 414), 'BMP'),\n",
            "((413, 414), '##MP'),\n",
            "((414, 416), 'family members'),\n",
            "((420, 421), 'impair'),\n",
            "((420, 421), '##air'),\n",
            "((422, 424), 'the development'),\n",
            "((425, 426), 'bone'),\n",
            "((425, 427), 'bone tissue'),\n",
            "((430, 431), 'def'),\n",
            "((430, 431), 'deform'),\n",
            "((432, 434), 'This study'),\n",
            "((433, 434), 'study'),\n",
            "((439, 441), 'the roles'),\n",
            "((443, 444), 'B'),\n",
            "((443, 444), 'BMP'),\n",
            "((451, 452), 'em'),\n",
            "((451, 452), 'emb'),\n",
            "((451, 452), '##ryo'),\n",
            "((454, 455), 'm'),\n",
            "((454, 455), 'mor'),\n",
            "((454, 455), 'morphogen'),\n",
            "((454, 455), '##or'),\n",
            "((454, 455), '##phogen'),\n",
            "((456, 457), 'B'),\n",
            "((456, 457), '##MPs'),\n",
            "((458, 459), 'secret'),\n",
            "((458, 459), 'secreted'),\n",
            "((459, 461), 'signaling molecules'),\n",
            "((459, 482), 'signaling molecules belonging to the transforming growth factor β superfamily , originally identified on the basis of their ability to induce ectopic bone formation'),\n",
            "((462, 482), 'to the transforming growth factor β superfamily , originally identified on the basis of their ability to induce ectopic bone formation'),\n",
            "((465, 467), 'growth factor'),\n",
            "((466, 467), 'factor'),\n",
            "((468, 469), 'superfamily'),\n",
            "((475, 482), 'their ability to induce ectopic bone formation'),\n",
            "((478, 480), 'induce ectop'),\n",
            "((478, 482), 'induce ectopic bone formation'),\n",
            "((479, 480), 'ectop'),\n",
            "((479, 480), '##ct'),\n",
            "((479, 480), '##ctop'),\n",
            "((479, 480), '##op'),\n",
            "((480, 481), 'bone'),\n",
            "((480, 482), 'bone formation'),\n",
            "((483, 484), 'imp'),\n",
            "((483, 484), 'implanted'),\n",
            "((488, 489), 'v'),\n",
            "((488, 489), 'vivo'),\n",
            "((488, 490), 'vivo [ 1 – 3'),\n",
            "((489, 490), '[ 1'),\n",
            "((489, 490), '[ 1 – 3'),\n",
            "((489, 490), '1'),\n",
            "((489, 490), '– 3'),\n",
            "((489, 490), '3'),\n",
            "((489, 490), ']'),\n",
            "((489, 490), '] .'),\n",
            "((490, 491), 'B'),\n",
            "((490, 491), 'BMP'),\n",
            "((490, 493), 'BMP family members'),\n",
            "((491, 492), 'family'),\n",
            "((491, 493), 'family members'),\n",
            "((492, 493), 'members'),\n",
            "((493, 494), 'are'),\n",
            "((493, 495), 'are now'),\n",
            "((499, 501), 'extremely diverse'),\n",
            "((501, 502), 'set'),\n",
            "((501, 503), 'set of'),\n",
            "((509, 510), 'developmental'),\n",
            "((509, 511), 'developmental processes'),\n",
            "((511, 512), '[ 4'),\n",
            "((514, 516), 'the context'),\n",
            "((518, 519), 'm'),\n",
            "((518, 519), 'mor'),\n",
            "((518, 519), 'morphogen'),\n",
            "((518, 519), 'morphogenesis'),\n",
            "((518, 523), 'morphogenesis of a single structure'),\n",
            "((518, 533), 'morphogenesis of a single structure , these molecules can play a series of quite divergent roles .'),\n",
            "((518, 519), '##or'),\n",
            "((518, 519), '##phogen'),\n",
            "((518, 519), '##ogen'),\n",
            "((521, 523), 'single structure'),\n",
            "((522, 523), 'structure'),\n",
            "((525, 527), 'can play'),\n",
            "((531, 532), 'diver'),\n",
            "((531, 532), 'divergent'),\n",
            "((532, 533), 'roles'),\n",
            "((532, 533), 'roles .'),\n",
            "((536, 538), 'limb development'),\n",
            "((538, 539), 'B'),\n",
            "((538, 539), 'BMP'),\n",
            "((538, 544), 'BMPs have been postulated to act'),\n",
            "((538, 551), 'BMPs have been postulated to act sequentially in multiple distinct aspects of patterning'),\n",
            "((538, 539), '##MP'),\n",
            "((540, 542), 'been post'),\n",
            "((541, 542), 'post'),\n",
            "((542, 544), 'to act'),\n",
            "((543, 544), 'act'),\n",
            "((550, 551), 'pattern'),\n",
            "((550, 551), 'patterning'),\n",
            "((551, 553), 'cell type'),\n",
            "((552, 553), 'type'),\n",
            "((562, 563), 'skeleton'),\n",
            "((562, 563), 'skeleton .'),\n",
            "((567, 568), 'limb'),\n",
            "((571, 572), 'B'),\n",
            "((571, 572), 'BMP'),\n",
            "((571, 572), '##MP'),\n",
            "((578, 579), 'establishment'),\n",
            "((581, 583), 'posterior limb'),\n",
            "((582, 583), 'limb'),\n",
            "((584, 585), 'Di'),\n",
            "((584, 585), 'Difference'),\n",
            "((586, 588), 'posterior pattern'),\n",
            "((587, 588), 'pattern'),\n",
            "((590, 608), 'as a graded response to Sonic Hedghog ( SHH ) signaling emanating from the posterior margin of the limb bud'),\n",
            "((592, 594), 'graded response'),\n",
            "((592, 608), 'graded response to Sonic Hedghog ( SHH ) signaling emanating from the posterior margin of the limb bud'),\n",
            "((595, 596), 'Sonic'),\n",
            "((595, 597), 'Sonic Hedghog'),\n",
            "((595, 608), 'Sonic Hedghog ( SHH ) signaling emanating from the posterior margin of the limb bud'),\n",
            "((596, 597), 'Hed'),\n",
            "((596, 597), 'Hedghog'),\n",
            "((596, 597), '##gh'),\n",
            "((596, 597), '##ghog'),\n",
            "((596, 597), '##og'),\n",
            "((597, 598), 'SHH'),\n",
            "((597, 600), 'SHH ) signaling emana'),\n",
            "((597, 600), 'SHH ) signaling emanating'),\n",
            "((597, 608), 'SHH ) signaling emanating from the posterior margin of the limb bud'),\n",
            "((599, 600), 'em'),\n",
            "((599, 600), 'emana'),\n",
            "((599, 600), '##ana'),\n",
            "((601, 608), 'the posterior margin of the limb bud'),\n",
            "((607, 608), 'b'),\n",
            "((607, 608), 'bud'),\n",
            "((607, 608), '##ud'),\n",
            "((608, 609), '5 ]'),\n",
            "((608, 609), ']'),\n",
            "((609, 610), 'It'),\n",
            "((613, 614), 'however ,'),\n",
            "((615, 617), 'this response'),\n",
            "((621, 622), 'If'),\n",
            "((621, 623), 'If indeed'),\n",
            "((623, 625), 'the long'),\n",
            "((627, 628), 'SH'),\n",
            "((627, 628), 'SHH'),\n",
            "((627, 634), 'SHH are indirectly mediated by local production'),\n",
            "((627, 628), '##H'),\n",
            "((632, 634), 'local production'),\n",
            "((633, 634), 'production'),\n",
            "((647, 648), 'family'),\n",
            "((647, 648), 'family ,'),\n",
            "((648, 649), 'BMP'),\n",
            "((650, 651), 'B'),\n",
            "((650, 651), 'BMP'),\n",
            "((650, 651), '##MP'),\n",
            "((659, 660), 'SH'),\n",
            "((659, 660), 'SHH'),\n",
            "((659, 666), 'SHH in the early posterior limb bud'),\n",
            "((659, 667), 'SHH in the early posterior limb bud mesenchyme'),\n",
            "((659, 670), 'SHH in the early posterior limb bud mesenchyme [ 6 , 7 ] , although BMP'),\n",
            "((665, 666), 'b'),\n",
            "((665, 666), 'bud'),\n",
            "((665, 666), '##ud'),\n",
            "((666, 667), '##chyme'),\n",
            "((669, 670), 'B'),\n",
            "((669, 670), 'BMP'),\n",
            "((669, 670), '##MP'),\n",
            "((682, 683), 'b'),\n",
            "((682, 683), 'bud'),\n",
            "((683, 684), '##chyme'),\n",
            "((684, 685), 'B'),\n",
            "((684, 694), 'BMP2 [ 8 ] and BMP7 [ 7 ] can be induced by ectop'),\n",
            "((684, 685), '##MP2'),\n",
            "((684, 685), '##2'),\n",
            "((685, 694), '] and BMP7 [ 7 ] can be induced by ectop'),\n",
            "((687, 688), 'B'),\n",
            "((687, 688), 'BMP'),\n",
            "((687, 694), 'BMP7 [ 7 ] can be induced by ectop'),\n",
            "((687, 688), '##MP'),\n",
            "((689, 694), 'can be induced by ectop'),\n",
            "((693, 694), 'ectop'),\n",
            "((693, 694), '##ct'),\n",
            "((693, 694), '##ctop'),\n",
            "((693, 694), '##op'),\n",
            "((694, 695), 'SH'),\n",
            "((694, 695), 'SHH'),\n",
            "((705, 706), 'SH'),\n",
            "((705, 706), 'SHH'),\n",
            "((708, 709), 'BMP'),\n",
            "((710, 711), 'B'),\n",
            "((710, 711), 'BMP'),\n",
            "((710, 711), '##MP'),\n",
            "((713, 715), 'secondary signals'),\n",
            "((714, 715), 'signals'),\n",
            "((716, 718), 'in response'),\n",
            "((719, 720), 'SH'),\n",
            "((719, 720), 'SHH'),\n",
            "((722, 723), 'B'),\n",
            "((722, 723), 'BMP'),\n",
            "((730, 731), 'polarize'),\n",
            "((730, 735), 'polarize the limb in ectop'),\n",
            "((730, 747), 'polarize the limb in ectopic grafting experiments [ 10 ] , an activity enhanced by prior low - level exposure to SHH'),\n",
            "((731, 733), 'the limb'),\n",
            "((732, 733), 'limb'),\n",
            "((734, 735), 'e'),\n",
            "((734, 735), 'ectop'),\n",
            "((734, 735), '##ct'),\n",
            "((734, 735), '##ctop'),\n",
            "((734, 735), '##op'),\n",
            "((735, 736), 'graft'),\n",
            "((735, 736), '##raft'),\n",
            "((737, 738), '[ 10'),\n",
            "((737, 747), '[ 10 ] , an activity enhanced by prior low - level exposure to SHH'),\n",
            "((739, 740), 'activity'),\n",
            "((739, 747), 'activity enhanced by prior low - level exposure to SHH'),\n",
            "((743, 744), 'level'),\n",
            "((746, 747), 'SH'),\n",
            "((746, 747), 'SHH'),\n",
            "((746, 747), '##H'),\n",
            "((747, 748), '[ 11'),\n",
            "((747, 748), '11'),\n",
            "((747, 748), ']'),\n",
            "((747, 748), '] .'),\n",
            "((749, 751), 'remains unclear'),\n",
            "((749, 760), 'remains unclear , however , whether BMP2 and BMP7 activity is required endogen'),\n",
            "((753, 754), 'BMP'),\n",
            "((755, 756), 'B'),\n",
            "((755, 756), 'BMP'),\n",
            "((755, 760), 'BMP7 activity is required endogen'),\n",
            "((755, 756), '##MP'),\n",
            "((759, 760), 'end'),\n",
            "((759, 760), 'endogen'),\n",
            "((759, 760), '##ogen'),\n",
            "((763, 764), 'pattern'),\n",
            "((763, 764), 'patterning'),\n",
            "((765, 766), 'SHH'),\n",
            "((766, 767), 'Bmp'),\n",
            "((766, 769), 'Bmp2 mutant embryo'),\n",
            "((766, 770), 'Bmp2 mutant embryos die'),\n",
            "((766, 776), 'Bmp2 mutant embryos die too early to assess their limb'),\n",
            "((766, 767), '##mp'),\n",
            "((768, 769), 'em'),\n",
            "((768, 769), 'emb'),\n",
            "((768, 769), '##b'),\n",
            "((768, 769), '##s'),\n",
            "((768, 770), '##s die'),\n",
            "((775, 776), 'limb'),\n",
            "((779, 780), 'deleti'),\n",
            "((779, 782), 'deletion of Bmp'),\n",
            "((779, 782), 'deletion of Bmp7'),\n",
            "((779, 787), 'deletion of Bmp7 has been made , and Bmp'),\n",
            "((779, 788), 'deletion of Bmp7 has been made , and Bmp7 - deficient embryos'),\n",
            "((779, 790), 'deletion of Bmp7 has been made , and Bmp7 - deficient embryos display hindlimb'),\n",
            "((779, 791), 'deletion of Bmp7 has been made , and Bmp7 - deficient embryos display hindlimb poly'),\n",
            "((779, 791), 'deletion of Bmp7 has been made , and Bmp7 - deficient embryos display hindlimb polydact'),\n",
            "((781, 782), 'B'),\n",
            "((781, 782), 'Bmp'),\n",
            "((781, 782), '##mp'),\n",
            "((786, 787), 'B'),\n",
            "((786, 787), 'Bmp'),\n",
            "((786, 787), '##mp'),\n",
            "((787, 788), 'emb'),\n",
            "((789, 790), '##lim'),\n",
            "((789, 790), '##limb'),\n",
            "((790, 791), 'poly'),\n",
            "((790, 791), '##oly'),\n",
            "((790, 791), '##dact'),\n",
            "((790, 791), '##yly'),\n",
            "((790, 794), '##yly with incomplete penetrance'),\n",
            "((790, 791), '##y'),\n",
            "((793, 794), 'pen'),\n",
            "((793, 794), 'penet'),\n",
            "((793, 794), 'penetrance'),\n",
            "((793, 794), '##et'),\n",
            "((796, 797), 'phen'),\n",
            "((799, 800), '[ 12'),\n",
            "((801, 802), 'B'),\n",
            "((801, 802), 'Bmp'),\n",
            "((801, 802), '##mp'),\n",
            "((802, 804), 'knockout mice'),\n",
            "((811, 812), 'polarity'),\n",
            "((818, 819), 'pattern'),\n",
            "((818, 819), 'patterning'),\n",
            "((818, 821), 'patterning with BMP2'),\n",
            "((820, 821), 'B'),\n",
            "((820, 821), 'BMP2'),\n",
            "((820, 821), '##MP'),\n",
            "((820, 821), '##MP2'),\n",
            "((822, 824), 'a possibility'),\n",
            "((827, 828), 'B'),\n",
            "((827, 828), 'BMP'),\n",
            "((827, 828), '##MP'),\n",
            "((829, 830), 'B'),\n",
            "((829, 830), 'BMP'),\n",
            "((829, 830), '##MP'),\n",
            "((831, 833), 'third member'),\n",
            "((841, 842), 'B'),\n",
            "((841, 842), 'BMP'),\n",
            "((842, 843), 'BMP'),\n",
            "((842, 843), '##MP'),\n",
            "((850, 851), 'bud'),\n",
            "((852, 853), 'B'),\n",
            "((852, 853), 'BMP'),\n",
            "((852, 867), 'BMP7 , it is expressed in both the anterior and posterior margins of the limb bud'),\n",
            "((852, 868), 'BMP7 , it is expressed in both the anterior and posterior margins of the limb bud mesenchyme'),\n",
            "((852, 853), '##MP'),\n",
            "((852, 854), ', it'),\n",
            "((866, 867), 'b'),\n",
            "((866, 867), 'bud'),\n",
            "((866, 867), '##ud'),\n",
            "((867, 868), '##chyme'),\n",
            "((868, 869), '[ 4'),\n",
            "((868, 869), ']'),\n",
            "((868, 869), '] ;'),\n",
            "((868, 874), '] ; however , it does not appear'),\n",
            "((868, 885), '] ; however , it does not appear to be induced by SHH signaling , nor does its expression change'),\n",
            "((872, 874), 'not appear'),\n",
            "((878, 879), 'SH'),\n",
            "((878, 879), 'SHH'),\n",
            "((883, 885), 'expression change'),\n",
            "((886, 887), 'SH'),\n",
            "((886, 887), 'SHH'),\n",
            "((886, 887), 'deficient'),\n",
            "((888, 889), 'b'),\n",
            "((890, 891), 'B'),\n",
            "((890, 891), '##MP'),\n",
            "((890, 891), '##MP4'),\n",
            "((901, 902), 'SHH'),\n",
            "((904, 905), 'pattern'),\n",
            "((904, 905), 'patterning'),\n",
            "((911, 912), '##MP2'),\n",
            "((912, 913), 'B'),\n",
            "((912, 913), 'BMP'),\n",
            "((914, 915), 'B'),\n",
            "((914, 915), 'BMP'),\n",
            "((914, 927), 'BMP7 , have been suggested to act in a second distinct phase of limb'),\n",
            "((914, 915), '##MP'),\n",
            "((918, 920), 'to act'),\n",
            "((919, 920), 'act'),\n",
            "((925, 927), 'of limb'),\n",
            "((926, 927), 'limb'),\n",
            "((927, 928), 'pattern'),\n",
            "((927, 928), 'patterning'),\n",
            "((927, 928), '##ing'),\n",
            "((928, 930), 'when digit'),\n",
            "((929, 930), 'digit'),\n",
            "((934, 936), 'of earlier'),\n",
            "((936, 937), 'pattern'),\n",
            "((936, 937), 'patterning'),\n",
            "((940, 941), 'verte'),\n",
            "((940, 941), '##rte'),\n",
            "((940, 942), '##te limb'),\n",
            "((941, 942), 'limb'),\n",
            "((941, 952), ', each digit can be uniquely identified based on its size'),\n",
            "((942, 944), 'each digit'),\n",
            "((943, 944), 'digit'),\n",
            "((944, 946), 'can be'),\n",
            "((944, 952), 'can be uniquely identified based on its size'),\n",
            "((950, 952), 'its size'),\n",
            "((951, 952), 'size'),\n",
            "((952, 953), 'length'),\n",
            "((955, 956), 'p'),\n",
            "((955, 956), 'phala'),\n",
            "((955, 956), '##hala'),\n",
            "((960, 961), 'auto'),\n",
            "((960, 961), 'autopod'),\n",
            "((960, 961), '##po'),\n",
            "((960, 961), '##pod'),\n",
            "((960, 961), '##d'),\n",
            "((962, 964), 'a consequence'),\n",
            "((966, 968), 'initial establishment'),\n",
            "((969, 970), 'anterior -'),\n",
            "((970, 972), 'positioned information'),\n",
            "((973, 975), 'the limb'),\n",
            "((974, 975), 'limb'),\n",
            "((976, 977), 'SH'),\n",
            "((976, 977), 'SHH'),\n",
            "((976, 983), 'SHH and / or BMP signaling , the interdigital mesenchyme'),\n",
            "((976, 987), 'SHH and / or BMP signaling , the interdigital mesenchyme of the hand plate'),\n",
            "((976, 993), 'SHH and / or BMP signaling , the interdigital mesenchyme of the hand plate becomes specified in a graded manner'),\n",
            "((978, 979), 'BMP'),\n",
            "((981, 982), '##digit'),\n",
            "((981, 983), '##digital mesenchyme'),\n",
            "((982, 983), 'me'),\n",
            "((982, 983), 'mesen'),\n",
            "((982, 983), '##chyme'),\n",
            "((985, 986), 'hand'),\n",
            "((985, 987), 'hand plate'),\n",
            "((986, 987), 'plate'),\n",
            "((991, 993), 'graded manner'),\n",
            "((993, 994), 'Graf'),\n",
            "((993, 1010), 'Grafting and extirpation experiments have shown that it is this polarized interdigital tissue which directs digit morphology'),\n",
            "((995, 996), 'extirpation'),\n",
            "((995, 999), 'extirpation experiments have shown'),\n",
            "((995, 1010), 'extirpation experiments have shown that it is this polarized interdigital tissue which directs digit morphology'),\n",
            "((995, 996), '##ti'),\n",
            "((995, 996), '##tirp'),\n",
            "((995, 996), '##rp'),\n",
            "((997, 999), 'have shown'),\n",
            "((1003, 1004), 'polarized'),\n",
            "((1003, 1010), 'polarized interdigital tissue which directs digit morphology'),\n",
            "((1004, 1005), '##di'),\n",
            "((1004, 1005), '##digit'),\n",
            "((1004, 1010), '##digital tissue which directs digit morphology'),\n",
            "((1008, 1010), 'digit morphology'),\n",
            "((1011, 1012), '##MP2'),\n",
            "((1012, 1013), 'B'),\n",
            "((1012, 1013), 'BMP'),\n",
            "((1014, 1015), 'B'),\n",
            "((1014, 1015), 'BMP'),\n",
            "((1014, 1015), '##MP'),\n",
            "((1020, 1021), 'interdigital'),\n",
            "((1020, 1021), '##di'),\n",
            "((1020, 1021), '##digit'),\n",
            "((1020, 1021), '##git'),\n",
            "((1021, 1022), 'mesen'),\n",
            "((1021, 1022), '##chy'),\n",
            "((1021, 1022), '##chyme'),\n",
            "((1022, 1023), '[ 4'),\n",
            "((1022, 1023), ', 14'),\n",
            "((1026, 1027), 'B'),\n",
            "((1026, 1027), 'BMP'),\n",
            "((1030, 1031), 'tissue'),\n",
            "((1036, 1037), 'B'),\n",
            "((1036, 1037), 'BMP'),\n",
            "((1036, 1049), 'BMPs in the interdigital mesenchyme might be the relevant factor directing digit morphology'),\n",
            "((1039, 1049), 'interdigital mesenchyme might be the relevant factor directing digit morphology'),\n",
            "((1039, 1040), '##di'),\n",
            "((1039, 1040), '##digit'),\n",
            "((1039, 1041), '##digital mesenchyme'),\n",
            "((1039, 1049), '##digital mesenchyme might be the relevant factor directing digit morphology'),\n",
            "((1040, 1041), 'mesen'),\n",
            "((1040, 1041), '##chyme'),\n",
            "((1045, 1046), 'factor'),\n",
            "((1047, 1048), 'digit'),\n",
            "((1047, 1049), 'digit morphology'),\n",
            "((1048, 1049), 'morphology'),\n",
            "((1049, 1050), '[ 15'),\n",
            "((1053, 1054), 'B'),\n",
            "((1053, 1054), 'BMP'),\n",
            "((1053, 1054), '##MP'),\n",
            "((1054, 1055), 'em'),\n",
            "((1054, 1055), 'emb'),\n",
            "((1054, 1055), '##b'),\n",
            "((1064, 1065), 'deleti'),\n",
            "((1064, 1082), 'deletion of Bmp4 in the limb bud mesenchyme also do not show evidence of anterior digit transformation [ 16'),\n",
            "((1064, 1065), '##on'),\n",
            "((1066, 1067), 'B'),\n",
            "((1066, 1067), 'Bmp'),\n",
            "((1066, 1081), 'Bmp4 in the limb bud mesenchyme also do not show evidence of anterior digit transformation'),\n",
            "((1066, 1082), 'Bmp4 in the limb bud mesenchyme also do not show evidence of anterior digit transformation [ 16'),\n",
            "((1066, 1067), '##mp'),\n",
            "((1070, 1071), 'b'),\n",
            "((1070, 1071), 'bud'),\n",
            "((1071, 1072), 'mesen'),\n",
            "((1071, 1072), '##chyme'),\n",
            "((1071, 1072), '##me'),\n",
            "((1079, 1080), 'digit'),\n",
            "((1079, 1081), 'digit transformation'),\n",
            "((1081, 1082), '[ 16'),\n",
            "((1081, 1082), '16'),\n",
            "((1088, 1089), 'B'),\n",
            "((1088, 1089), 'BMP'),\n",
            "((1088, 1089), '##MP'),\n",
            "((1092, 1093), '##digit'),\n",
            "((1095, 1096), 'digit'),\n",
            "((1095, 1097), 'digit morphology'),\n",
            "((1096, 1097), 'morphology'),\n",
            "((1103, 1105), 'it would'),\n",
            "((1113, 1114), '##gital'),\n",
            "((1114, 1115), 'B'),\n",
            "((1114, 1132), 'BMP signal are responsible for establishing digit identity , although redundancy between BMP2 , BMP4 , and BMP7 in this role'),\n",
            "((1114, 1115), '##MP'),\n",
            "((1114, 1116), '##MP signal'),\n",
            "((1114, 1132), '##MP signal are responsible for establishing digit identity , although redundancy between BMP2 , BMP4 , and BMP7 in this role'),\n",
            "((1125, 1132), 'BMP2 , BMP4 , and BMP7 in this role'),\n",
            "((1125, 1126), '##MP2'),\n",
            "((1126, 1127), 'BMP'),\n",
            "((1128, 1129), 'BMP'),\n",
            "((1128, 1129), '##MP'),\n",
            "((1130, 1132), 'this role'),\n",
            "((1131, 1132), 'role'),\n",
            "((1133, 1135), 'a possibility'),\n",
            "((1139, 1140), 'limb'),\n",
            "((1139, 1141), 'limb pattern'),\n",
            "((1140, 1141), 'pattern'),\n",
            "((1143, 1144), 'BMP'),\n",
            "((1144, 1145), 'B'),\n",
            "((1144, 1145), 'BMP'),\n",
            "((1146, 1147), 'B'),\n",
            "((1146, 1147), 'BMP'),\n",
            "((1146, 1147), '##MP'),\n",
            "((1153, 1154), '##pop'),\n",
            "((1153, 1154), '##popto'),\n",
            "((1153, 1154), '##to'),\n",
            "((1157, 1158), '##digit'),\n",
            "((1157, 1159), '##al tissue'),\n",
            "((1158, 1159), 'tissue'),\n",
            "((1161, 1162), 'e'),\n",
            "((1161, 1162), 'ect'),\n",
            "((1161, 1162), 'ectop'),\n",
            "((1161, 1162), '##ct'),\n",
            "((1161, 1162), '##op'),\n",
            "((1164, 1165), 'B'),\n",
            "((1164, 1165), 'BMP'),\n",
            "((1165, 1166), 'antagonists'),\n",
            "((1165, 1182), 'antagonists demonstrates that BMP signaling is necessary for this process , and in its absence , webbing occurs [ 17'),\n",
            "((1168, 1169), 'B'),\n",
            "((1168, 1169), 'BMP'),\n",
            "((1168, 1169), '##MP'),\n",
            "((1179, 1180), 'web'),\n",
            "((1179, 1180), 'webbing'),\n",
            "((1181, 1182), '[ 17'),\n",
            "((1181, 1182), '17'),\n",
            "((1181, 1182), '– 19'),\n",
            "((1181, 1182), ']'),\n",
            "((1181, 1182), '] )'),\n",
            "((1181, 1182), ')'),\n",
            "((1182, 1183), 'B'),\n",
            "((1182, 1183), 'BMP'),\n",
            "((1190, 1191), 'limb'),\n",
            "((1190, 1192), 'limb pattern'),\n",
            "((1191, 1192), 'pattern'),\n",
            "((1199, 1200), 'loop'),\n",
            "((1201, 1202), 'SH'),\n",
            "((1201, 1202), 'SHH'),\n",
            "((1201, 1219), 'SHH production in the posterior limb bud and fibroblast growth factor production in the overlying apical ectodermal ridge'),\n",
            "((1207, 1208), 'b'),\n",
            "((1207, 1208), 'bud'),\n",
            "((1209, 1210), 'fibro'),\n",
            "((1217, 1218), 'e'),\n",
            "((1217, 1218), 'ect'),\n",
            "((1217, 1219), '##rmal ridge'),\n",
            "((1218, 1219), 'ridge'),\n",
            "((1219, 1220), '##ER )'),\n",
            "((1220, 1221), 'SHH'),\n",
            "((1228, 1229), 'B'),\n",
            "((1228, 1229), 'BMP'),\n",
            "((1230, 1231), 'Grem'),\n",
            "((1230, 1231), '##rem'),\n",
            "((1233, 1234), '##chyme'),\n",
            "((1234, 1235), '[ 20'),\n",
            "((1234, 1235), '21 ]'),\n",
            "((1237, 1250), 'turn , prevents BMPs from downregulating fibroblast growth factor ( FGF ) production in the AER'),\n",
            "((1239, 1240), 'B'),\n",
            "((1239, 1240), 'BMP'),\n",
            "((1239, 1250), 'BMPs from downregulating fibroblast growth factor ( FGF ) production in the AER'),\n",
            "((1239, 1240), '##MP'),\n",
            "((1241, 1242), '##re'),\n",
            "((1241, 1242), '##regu'),\n",
            "((1241, 1242), '##gu'),\n",
            "((1242, 1243), 'fi'),\n",
            "((1242, 1243), 'fibro'),\n",
            "((1242, 1245), 'fibroblast growth factor'),\n",
            "((1242, 1246), 'fibroblast growth factor ( FGF'),\n",
            "((1242, 1247), 'fibroblast growth factor ( FGF ) production'),\n",
            "((1242, 1250), 'fibroblast growth factor ( FGF ) production in the AER'),\n",
            "((1243, 1245), 'growth factor'),\n",
            "((1244, 1245), 'factor'),\n",
            "((1245, 1246), 'F'),\n",
            "((1245, 1246), '##G'),\n",
            "((1245, 1246), '##GF'),\n",
            "((1249, 1250), 'A'),\n",
            "((1249, 1250), 'AER'),\n",
            "((1250, 1251), '17'),\n",
            "((1257, 1258), 'A'),\n",
            "((1257, 1258), 'AER'),\n",
            "((1257, 1258), '##ER'),\n",
            "((1259, 1260), ']'),\n",
            "((1260, 1261), 'F'),\n",
            "((1260, 1261), 'FG'),\n",
            "((1260, 1261), '##F'),\n",
            "((1260, 1262), '##F signaling'),\n",
            "((1266, 1267), 'SH'),\n",
            "((1266, 1267), 'SHH'),\n",
            "((1266, 1272), 'SHH production in the posterior mesenchyme'),\n",
            "((1269, 1271), 'the posterior'),\n",
            "((1271, 1272), 'mesen'),\n",
            "((1271, 1272), 'mesenchyme'),\n",
            "((1271, 1272), '##chyme'),\n",
            "((1272, 1273), '[ 8'),\n",
            "((1277, 1278), 'B'),\n",
            "((1277, 1278), 'BMP'),\n",
            "((1277, 1283), 'BMP4 activity from the posterior limb'),\n",
            "((1277, 1278), '##MP'),\n",
            "((1281, 1283), 'posterior limb'),\n",
            "((1282, 1283), 'limb'),\n",
            "((1283, 1284), 'mesen'),\n",
            "((1283, 1284), '##chyme'),\n",
            "((1287, 1300), 'persistence of the AER , expanded SHH signaling , and consequent preaxial and postaxial polydactyly'),\n",
            "((1290, 1291), 'AER'),\n",
            "((1290, 1300), 'AER , expanded SHH signaling , and consequent preaxial and postaxial polydactyly'),\n",
            "((1292, 1293), 'SH'),\n",
            "((1292, 1293), 'SHH'),\n",
            "((1292, 1300), 'SHH signaling , and consequent preaxial and postaxial polydactyly'),\n",
            "((1295, 1296), 'conse'),\n",
            "((1296, 1297), 'preax'),\n",
            "((1296, 1300), 'preaxial and postaxial polydactyly'),\n",
            "((1298, 1299), 'postax'),\n",
            "((1299, 1300), 'poly'),\n",
            "((1299, 1300), 'polydactyly'),\n",
            "((1299, 1300), '##dact'),\n",
            "((1299, 1300), '##dactyly'),\n",
            "((1299, 1300), '##yl'),\n",
            "((1299, 1300), '##yly'),\n",
            "((1299, 1300), '##y'),\n",
            "((1300, 1301), '] .'),\n",
            "((1305, 1307), 'limb development'),\n",
            "((1307, 1308), 'B'),\n",
            "((1307, 1308), 'BMP'),\n",
            "((1307, 1318), 'BMP activity is also believed to play critical roles in skeleto'),\n",
            "((1308, 1309), 'activity'),\n",
            "((1308, 1310), 'activity is'),\n",
            "((1317, 1318), '##keleto'),\n",
            "((1318, 1319), 'Act'),\n",
            "((1318, 1319), 'Activation'),\n",
            "((1323, 1325), 'the chick'),\n",
            "((1331, 1332), 'B'),\n",
            "((1331, 1332), 'BMP'),\n",
            "((1331, 1332), '##MP'),\n",
            "((1331, 1332), 'IB'),\n",
            "((1338, 1339), 'cart'),\n",
            "((1341, 1342), 'chick'),\n",
            "((1347, 1348), 'B'),\n",
            "((1347, 1348), 'Bmp'),\n",
            "((1347, 1348), '##mp'),\n",
            "((1349, 1350), 'B'),\n",
            "((1349, 1350), 'Bmp'),\n",
            "((1352, 1353), 'ch'),\n",
            "((1352, 1353), 'chond'),\n",
            "((1352, 1353), '##rogenic'),\n",
            "((1358, 1359), 'b'),\n",
            "((1358, 1359), 'bud'),\n",
            "((1358, 1359), '##ud'),\n",
            "((1359, 1360), '] .'),\n",
            "((1362, 1363), 'no'),\n",
            "((1362, 1363), 'nogg'),\n",
            "((1362, 1363), '##gg'),\n",
            "((1365, 1366), 'B'),\n",
            "((1365, 1366), 'BMP'),\n",
            "((1365, 1380), 'BMP inhibitor , is introduced in early stage chick limb buds prior to skeletogenesis , mesenchymal condensation'),\n",
            "((1366, 1380), 'inhibitor , is introduced in early stage chick limb buds prior to skeletogenesis , mesenchymal condensation'),\n",
            "((1373, 1375), 'limb b'),\n",
            "((1374, 1375), 'b'),\n",
            "((1377, 1378), '##keleto'),\n",
            "((1377, 1380), '##keletogenesis , mesenchymal condensation'),\n",
            "((1377, 1378), '##eto'),\n",
            "((1377, 1378), '##genesis'),\n",
            "((1378, 1380), 'mesenchymal condensation'),\n",
            "((1379, 1380), 'con'),\n",
            "((1379, 1380), 'conden'),\n",
            "((1379, 1380), 'condensation'),\n",
            "((1379, 1380), '##sation'),\n",
            "((1382, 1384), 'take place'),\n",
            "((1384, 1385), '[ 27'),\n",
            "((1384, 1385), '] .'),\n",
            "((1385, 1386), 'Take'),\n",
            "((1385, 1386), 'Taken'),\n",
            "((1390, 1391), 'implica'),\n",
            "((1391, 1392), 'B'),\n",
            "((1391, 1392), 'BMP'),\n",
            "((1394, 1395), 'necessary'),\n",
            "((1397, 1398), 'con'),\n",
            "((1397, 1398), 'conden'),\n",
            "((1397, 1398), '##den'),\n",
            "((1402, 1403), 'ch'),\n",
            "((1402, 1403), 'chond'),\n",
            "((1402, 1403), '##rogen'),\n",
            "((1402, 1403), '##rogenesis'),\n",
            "((1402, 1403), '##esis'),\n",
            "((1403, 1404), 'However'),\n",
            "((1405, 1406), 'p'),\n",
            "((1405, 1406), 'phen'),\n",
            "((1418, 1419), 'ch'),\n",
            "((1421, 1422), 'gain -'),\n",
            "((1423, 1424), '- function'),\n",
            "((1423, 1424), 'function'),\n",
            "((1427, 1429), 'severe defects'),\n",
            "((1434, 1435), '##kel'),\n",
            "((1434, 1435), '##keleto'),\n",
            "((1434, 1448), '##keletogenesis preclude investigation of any specific roles for BMPs in later events in cartilage'),\n",
            "((1434, 1449), '##keletogenesis preclude investigation of any specific roles for BMPs in later events in cartilage differentiation'),\n",
            "((1434, 1451), '##keletogenesis preclude investigation of any specific roles for BMPs in later events in cartilage differentiation , bone formation'),\n",
            "((1435, 1436), 'prec'),\n",
            "((1442, 1443), 'B'),\n",
            "((1442, 1443), 'BMP'),\n",
            "((1442, 1443), '##MP'),\n",
            "((1447, 1448), 'cart'),\n",
            "((1447, 1448), '##ilage'),\n",
            "((1449, 1450), 'bone'),\n",
            "((1449, 1451), 'bone formation'),\n",
            "((1452, 1454), 'bone metabolism'),\n",
            "((1454, 1455), '29'),\n",
            "((1459, 1460), 'ligan'),\n",
            "((1462, 1463), 'B'),\n",
            "((1462, 1463), '##MP'),\n",
            "((1462, 1463), '##MP4'),\n",
            "((1465, 1466), 'B'),\n",
            "((1465, 1466), 'BMP'),\n",
            "((1465, 1467), 'BMP7 [ 12 , 13'),\n",
            "((1465, 1466), '##MP'),\n",
            "((1466, 1467), '[ 12'),\n",
            "((1466, 1467), ', 13'),\n",
            "((1466, 1467), '13'),\n",
            "((1478, 1479), '##ncy'),\n",
            "((1488, 1489), 'B'),\n",
            "((1488, 1489), 'BMP'),\n",
            "((1491, 1492), 'verte'),\n",
            "((1491, 1492), '##rte'),\n",
            "((1491, 1492), '##bra'),\n",
            "((1492, 1493), 'limb'),\n",
            "((1492, 1494), 'limb pattern'),\n",
            "((1493, 1494), 'pattern'),\n",
            "((1495, 1496), '##keleto'),\n",
            "((1495, 1496), '##eto'),\n",
            "((1496, 1498), 'we have'),\n",
            "((1502, 1503), 'BMP'),\n",
            "((1509, 1510), 'B'),\n",
            "((1509, 1510), 'BMP'),\n",
            "((1509, 1510), '##MP'),\n",
            "((1513, 1514), 'limb'),\n",
            "((1513, 1515), 'limb me'),\n",
            "((1514, 1515), '##chyme'),\n",
            "((1519, 1520), 'B'),\n",
            "((1519, 1520), '##mp'),\n",
            "((1519, 1520), '##mp2'),\n",
            "((1521, 1522), 'B'),\n",
            "((1521, 1522), 'Bmp'),\n",
            "((1522, 1523), 'mutants'),\n",
            "((1528, 1529), 'em'),\n",
            "((1528, 1529), 'emb'),\n",
            "((1528, 1529), '##b'),\n",
            "((1528, 1529), '##ryogenesis'),\n",
            "((1529, 1530), '[ 30'),\n",
            "((1529, 1530), '30'),\n",
            "((1529, 1530), '31'),\n",
            "((1533, 1534), 'allele'),\n",
            "((1533, 1534), '##ele'),\n",
            "((1540, 1541), '##ele'),\n",
            "((1540, 1541), '##eles'),\n",
            "((1545, 1546), 'limb'),\n",
            "((1545, 1547), 'limb development'),\n",
            "((1552, 1553), 'cre'),\n",
            "((1552, 1553), 'recomb'),\n",
            "((1560, 1561), 'Pr'),\n",
            "((1560, 1561), '##r'),\n",
            "((1560, 1561), '##x'),\n",
            "((1565, 1566), 'def'),\n",
            "((1565, 1566), 'deficient'),\n",
            "((1567, 1568), 'B'),\n",
            "((1567, 1568), 'BMP'),\n",
            "((1569, 1570), 'B'),\n",
            "((1569, 1570), 'BMP'),\n",
            "((1569, 1570), '##MP'),\n",
            "((1572, 1573), 'def'),\n",
            "((1572, 1573), 'deficient'),\n",
            "((1574, 1575), 'B'),\n",
            "((1574, 1575), 'BMP'),\n",
            "((1576, 1577), 'BMP'),\n",
            "((1576, 1577), '##MP'),\n",
            "((1580, 1582), 'of loss'),\n",
            "((1584, 1585), 'pattern'),\n",
            "((1584, 1585), 'patterning'),\n",
            "((1596, 1597), 'SH'),\n",
            "((1596, 1597), 'SHH'),\n",
            "((1596, 1605), 'SHH or acting as interdigital determinants of digit identity'),\n",
            "((1600, 1601), '##digit'),\n",
            "((1601, 1602), 'deter'),\n",
            "((1601, 1605), 'determinants of digit identity'),\n",
            "((1601, 1602), '##mina'),\n",
            "((1601, 1602), '##minants'),\n",
            "((1603, 1604), 'digit'),\n",
            "((1603, 1605), 'digit identity'),\n",
            "((1604, 1605), 'identity'),\n",
            "((1606, 1607), 'B'),\n",
            "((1606, 1613), 'Bmp2 / Bmp4 double mutants did display a loss'),\n",
            "((1606, 1607), '##mp'),\n",
            "((1606, 1607), '##mp2'),\n",
            "((1606, 1607), '##mp'),\n",
            "((1606, 1607), '##mp4'),\n",
            "((1608, 1609), 'mutants'),\n",
            "((1611, 1613), 'a loss'),\n",
            "((1620, 1621), 'hand'),\n",
            "((1620, 1622), 'hand plate'),\n",
            "((1621, 1622), 'plate'),\n",
            "((1629, 1630), 'con'),\n",
            "((1629, 1630), 'conden'),\n",
            "((1633, 1634), 'digit'),\n",
            "((1633, 1635), 'digit rays'),\n",
            "((1634, 1635), 'rays'),\n",
            "((1637, 1639), 'a change'),\n",
            "((1642, 1643), 'identity .'),\n",
            "((1651, 1652), 'BMP'),\n",
            "((1656, 1657), '##MP2'),\n",
            "((1658, 1659), 'B'),\n",
            "((1658, 1659), 'BMP'),\n",
            "((1662, 1663), 'ch'),\n",
            "((1662, 1663), '##rogenesis'),\n",
            "((1663, 1664), 'O'),\n",
            "((1663, 1664), '##ste'),\n",
            "((1663, 1664), '##steogen'),\n",
            "((1663, 1664), '##steogenesis'),\n",
            "((1663, 1668), '##steogenesis is also initiated properly'),\n",
            "((1663, 1664), '##ogen'),\n",
            "((1663, 1664), '##esis'),\n",
            "((1666, 1668), 'initiated properly'),\n",
            "((1674, 1676), 'of factors'),\n",
            "((1677, 1692), 'at later stages , the combined loss of BMP2 and BMP4 evidently becomes limiting , and osteogen'),\n",
            "((1681, 1683), 'combined loss'),\n",
            "((1681, 1692), 'combined loss of BMP2 and BMP4 evidently becomes limiting , and osteogen'),\n",
            "((1684, 1685), 'B'),\n",
            "((1684, 1685), 'BMP'),\n",
            "((1684, 1692), 'BMP2 and BMP4 evidently becomes limiting , and osteogen'),\n",
            "((1686, 1687), 'BMP'),\n",
            "((1688, 1692), 'becomes limiting , and osteogen'),\n",
            "((1691, 1692), 'osteogen'),\n",
            "((1691, 1692), '##steogen'),\n",
            "((1691, 1692), '##ogen'),\n",
            "((1697, 1698), 'manipulation'),\n",
            "((1700, 1701), 'B'),\n",
            "((1700, 1701), 'BMP'),\n",
            "((1700, 1701), '##MP'),\n",
            "((1703, 1705), 'skeletal development'),\n",
            "((1703, 1710), 'skeletal development either result in a block'),\n",
            "((1703, 1729), 'skeletal development either result in a block at the first stage of chondrogenesis or allow complete skeletal formation , this is the first demonstration of a requirement'),\n",
            "((1708, 1710), 'a block'),\n",
            "((1709, 1710), 'block'),\n",
            "((1711, 1721), 'the first stage of chondrogenesis or allow complete skeletal formation'),\n",
            "((1711, 1726), 'the first stage of chondrogenesis or allow complete skeletal formation , this is the first demonstration'),\n",
            "((1711, 1729), 'the first stage of chondrogenesis or allow complete skeletal formation , this is the first demonstration of a requirement'),\n",
            "((1715, 1716), 'ch'),\n",
            "((1715, 1716), 'chond'),\n",
            "((1719, 1721), 'skeletal formation'),\n",
            "((1724, 1726), 'first demonstration'),\n",
            "((1727, 1729), 'a requirement'),\n",
            "((1728, 1729), 'requirement'),\n",
            "((1730, 1731), 'B'),\n",
            "((1730, 1731), 'BMP'),\n",
            "((1731, 1732), 'activity'),\n",
            "((1733, 1734), 'o'),\n",
            "((1733, 1734), 'oste'),\n",
            "((1741, 1742), 'B'),\n",
            "((1741, 1742), 'BMP'),\n",
            "((1747, 1748), 'limb'),\n",
            "((1747, 1749), 'limb pattern'),\n",
            "((1750, 1751), '##keleto'),\n",
            "((1750, 1755), '##keletogenesis , we constructed a series'),\n",
            "((1750, 1751), '##genesis'),\n",
            "((1753, 1755), 'a series'),\n",
            "((1756, 1758), 'mice def'),\n",
            "((1757, 1758), 'def'),\n",
            "((1767, 1768), '##MP2'),\n",
            "((1768, 1769), 'BMP'),\n",
            "((1770, 1771), 'BMP'),\n",
            "((1770, 1771), '##MP'),\n",
            "((1771, 1772), 'BMP'),\n",
            "((1771, 1772), '##MP'),\n",
            "((1771, 1772), 'def'),\n",
            "((1771, 1772), 'deficient'),\n",
            "((1772, 1773), 'mice'),\n",
            "((1776, 1777), 'Dr'),\n",
            "((1777, 1779), 'Liz Robertson'),\n",
            "((1778, 1779), 'Robertson'),\n",
            "((1783, 1784), '##MP2'),\n",
            "((1785, 1786), 'B'),\n",
            "((1785, 1786), '##MP'),\n",
            "((1785, 1786), '##MP4'),\n",
            "((1790, 1791), 'viability'),\n",
            "((1793, 1794), 'em'),\n",
            "((1793, 1794), 'emb'),\n",
            "((1793, 1794), 'embryo'),\n",
            "((1793, 1796), 'embryonic development [ 30'),\n",
            "((1793, 1794), '##b'),\n",
            "((1793, 1794), '##ryo'),\n",
            "((1795, 1796), '[ 30'),\n",
            "((1795, 1796), '30'),\n",
            "((1795, 1796), '31'),\n",
            "((1801, 1802), 'allele'),\n",
            "((1803, 1804), '##mp2'),\n",
            "((1805, 1806), '##x'),\n",
            "((1805, 1806), '##xP'),\n",
            "((1805, 1806), '##P'),\n",
            "((1807, 1808), 'flank'),\n",
            "((1807, 1808), 'flanking'),\n",
            "((1808, 1809), 'exon'),\n",
            "((1809, 1810), '3'),\n",
            "((1814, 1815), 'allele'),\n",
            "((1814, 1815), '##ele'),\n",
            "((1816, 1817), 'B'),\n",
            "((1816, 1817), 'Bmp'),\n",
            "((1816, 1825), 'Bmp4 , in which exon 4 is flanked by loxP'),\n",
            "((1816, 1828), 'Bmp4 , in which exon 4 is flanked by loxP sites , from Dr'),\n",
            "((1816, 1829), 'Bmp4 , in which exon 4 is flanked by loxP sites , from Dr . Holge'),\n",
            "((1816, 1829), 'Bmp4 , in which exon 4 is flanked by loxP sites , from Dr . Holger'),\n",
            "((1816, 1817), '##mp'),\n",
            "((1819, 1820), 'ex'),\n",
            "((1819, 1820), 'exon'),\n",
            "((1824, 1825), 'lo'),\n",
            "((1824, 1825), 'loxP'),\n",
            "((1824, 1825), '##x'),\n",
            "((1824, 1825), '##xP'),\n",
            "((1824, 1825), '##P'),\n",
            "((1826, 1828), 'from Dr'),\n",
            "((1827, 1828), 'Dr'),\n",
            "((1828, 1829), 'Holge'),\n",
            "((1829, 1830), 'Ku'),\n",
            "((1829, 1830), 'Kuless'),\n",
            "((1829, 1830), 'Kulessa'),\n",
            "((1829, 1832), 'Kulessa and Dr .'),\n",
            "((1829, 1834), 'Kulessa and Dr . Brigid Hogan'),\n",
            "((1829, 1835), 'Kulessa and Dr . Brigid Hogan [ 16'),\n",
            "((1829, 1835), 'Kulessa and Dr . Brigid Hogan [ 16 ]'),\n",
            "((1829, 1830), '##less'),\n",
            "((1831, 1832), 'Dr'),\n",
            "((1831, 1832), 'Dr .'),\n",
            "((1832, 1833), 'Brig'),\n",
            "((1832, 1834), 'Brigid Hogan'),\n",
            "((1832, 1833), '##rig'),\n",
            "((1832, 1833), '##id'),\n",
            "((1832, 1834), '##id Hogan'),\n",
            "((1833, 1834), 'Hogan'),\n",
            "((1834, 1835), '[ 16'),\n",
            "((1834, 1835), ']'),\n",
            "((1836, 1837), 'of'),\n",
            "((1838, 1839), 'allele'),\n",
            "((1838, 1839), '##ele'),\n",
            "((1846, 1847), '##eles'),\n",
            "((1852, 1853), 'Method'),\n",
            "((1852, 1853), 'Methods'),\n",
            "((1857, 1858), 'inact'),\n",
            "((1857, 1858), '##act'),\n",
            "((1858, 1859), 'B'),\n",
            "((1858, 1864), 'Bmp2 and Bmp4 in the limb'),\n",
            "((1858, 1859), '##mp'),\n",
            "((1858, 1859), '##mp2'),\n",
            "((1860, 1861), 'B'),\n",
            "((1860, 1861), 'Bmp'),\n",
            "((1860, 1864), 'Bmp4 in the limb'),\n",
            "((1860, 1861), '##mp'),\n",
            "((1862, 1864), 'the limb'),\n",
            "((1863, 1864), 'limb'),\n",
            "((1864, 1865), 'we'),\n",
            "((1864, 1866), 'we used'),\n",
            "((1868, 1869), 'transgene'),\n",
            "((1871, 1872), 'cre'),\n",
            "((1871, 1872), 'recomb'),\n",
            "((1871, 1882), 'recombinase is expressed under the control of the Prx1 limb enhancer'),\n",
            "((1871, 1872), '##inase'),\n",
            "((1878, 1882), 'the Prx1 limb enhancer'),\n",
            "((1879, 1880), 'P'),\n",
            "((1879, 1880), 'Pr'),\n",
            "((1879, 1882), 'Prx1 limb enhancer'),\n",
            "((1879, 1880), '##r'),\n",
            "((1879, 1880), '##x'),\n",
            "((1879, 1880), '##x1'),\n",
            "((1879, 1882), '##x1 limb enhancer'),\n",
            "((1881, 1882), 'enhancer'),\n",
            "((1881, 1882), '##r'),\n",
            "((1882, 1883), '32 ]'),\n",
            "((1884, 1885), 'trans'),\n",
            "((1884, 1885), 'transgene'),\n",
            "((1886, 1887), 'c'),\n",
            "((1886, 1887), 'cre'),\n",
            "((1886, 1887), '##re'),\n",
            "((1890, 1891), 'limb'),\n",
            "((1890, 1892), 'limb development'),\n",
            "((1895, 1896), 'recomb'),\n",
            "((1895, 1898), 'recombination of flox'),\n",
            "((1897, 1898), 'fl'),\n",
            "((1897, 1898), 'flox'),\n",
            "((1897, 1898), '##ox'),\n",
            "((1898, 1899), 'allele'),\n",
            "((1898, 1899), '##ele'),\n",
            "((1902, 1903), 'b'),\n",
            "((1902, 1903), 'bud'),\n",
            "((1909, 1910), 'P'),\n",
            "((1909, 1910), 'Pr'),\n",
            "((1909, 1910), '##x'),\n",
            "((1909, 1910), '##x1'),\n",
            "((1909, 1910), 'c'),\n",
            "((1909, 1910), 'cre'),\n",
            "((1911, 1912), 'recomb'),\n",
            "((1914, 1915), 'B'),\n",
            "((1914, 1915), 'Bmp'),\n",
            "((1914, 1915), '##mp'),\n",
            "((1916, 1917), 'Bmp'),\n",
            "((1916, 1917), '##mp'),\n",
            "((1917, 1918), 'allele'),\n",
            "((1917, 1918), '##ele'),\n",
            "((1921, 1922), 'b'),\n",
            "((1921, 1922), 'bud'),\n",
            "((1921, 1922), '##ud'),\n",
            "((1925, 1926), 'situ'),\n",
            "((1926, 1927), 'hybridization'),\n",
            "((1927, 1928), 'B'),\n",
            "((1927, 1928), 'Bmp'),\n",
            "((1927, 1928), 'Bmp2'),\n",
            "((1927, 1938), 'Bmp2 is first expressed in the limb mesenchyme at embryonic day'),\n",
            "((1927, 1928), '##mp'),\n",
            "((1930, 1938), 'expressed in the limb mesenchyme at embryonic day'),\n",
            "((1932, 1934), 'the limb'),\n",
            "((1933, 1934), 'limb'),\n",
            "((1936, 1937), 'em'),\n",
            "((1936, 1937), 'emb'),\n",
            "((1936, 1938), 'embryonic day'),\n",
            "((1936, 1937), '##b'),\n",
            "((1936, 1938), '##nic day'),\n",
            "((1937, 1938), 'day'),\n",
            "((1938, 1939), 'E'),\n",
            "((1941, 1942), 'mouse'),\n",
            "((1942, 1944), 'Figure 1A'),\n",
            "((1944, 1945), 'aster'),\n",
            "((1944, 1945), '##ter'),\n",
            "((1944, 1945), '##isk )'),\n",
            "((1954, 1955), 'fl'),\n",
            "((1954, 1955), 'flox'),\n",
            "((1954, 1957), 'floxed Bmp2 allele'),\n",
            "((1954, 1955), '##ox'),\n",
            "((1955, 1956), 'Bmp'),\n",
            "((1955, 1956), '##mp'),\n",
            "((1956, 1957), 'allele'),\n",
            "((1956, 1957), '##ele'),\n",
            "((1964, 1965), 'limb'),\n",
            "((1965, 1966), '##chyme'),\n",
            "((1970, 1971), 'situ'),\n",
            "((1971, 1972), 'hybridization'),\n",
            "((1977, 1978), 'B'),\n",
            "((1977, 1978), 'Bmp'),\n",
            "((1979, 1980), 'Figure'),\n",
            "((1982, 1983), 'E10'),\n",
            "((1983, 1984), 'Bmp'),\n",
            "((1983, 1984), '##mp'),\n",
            "((1987, 1989), 'the mouse'),\n",
            "((1989, 1990), 'limb'),\n",
            "((1990, 1991), 'mesen'),\n",
            "((1990, 1991), '##chyme'),\n",
            "((2001, 2002), '1C'),\n",
            "((2001, 2002), '##C'),\n",
            "((2005, 2006), 'expression'),\n",
            "((2005, 2007), 'expression domains'),\n",
            "((2008, 2009), 'completely'),\n",
            "((2011, 2012), 'E10'),\n",
            "((2017, 2018), 'P'),\n",
            "((2017, 2018), 'Pr'),\n",
            "((2017, 2018), '##r'),\n",
            "((2017, 2018), '##x'),\n",
            "((2017, 2018), '##x1'),\n",
            "((2017, 2018), 'c'),\n",
            "((2017, 2018), 'cre'),\n",
            "((2018, 2019), 'transgene'),\n",
            "((2019, 2020), 'Figure'),\n",
            "((2019, 2021), 'Figure 1'),\n",
            "((2020, 2021), '##D )'),\n",
            "((2021, 2022), 'B'),\n",
            "((2021, 2022), 'Bmp2'),\n",
            "((2021, 2024), 'Bmp2 and Bmp4'),\n",
            "((2021, 2022), '##mp'),\n",
            "((2021, 2022), '##mp2'),\n",
            "((2021, 2022), '##2'),\n",
            "((2023, 2024), 'B'),\n",
            "((2023, 2024), '##mp'),\n",
            "((2023, 2024), '##mp4'),\n",
            "((2023, 2024), '##4'),\n",
            "((2029, 2030), 'A'),\n",
            "((2029, 2030), 'AER'),\n",
            "((2029, 2044), 'AER , where Prx1 : : cre is inactive , and these domains of expression are not affected ( Figure 1A – 1D'),\n",
            "((2031, 2032), 'P'),\n",
            "((2031, 2032), 'Pr'),\n",
            "((2031, 2044), 'Prx1 : : cre is inactive , and these domains of expression are not affected ( Figure 1A – 1D'),\n",
            "((2031, 2032), '##x'),\n",
            "((2031, 2032), '##x1'),\n",
            "((2031, 2044), '##x1 : : cre is inactive , and these domains of expression are not affected ( Figure 1A – 1D'),\n",
            "((2031, 2032), 'c'),\n",
            "((2031, 2032), 'cre'),\n",
            "((2031, 2044), 'cre is inactive , and these domains of expression are not affected ( Figure 1A – 1D'),\n",
            "((2031, 2032), '##re'),\n",
            "((2037, 2039), 'of expression'),\n",
            "((2038, 2039), 'expression'),\n",
            "((2042, 2043), 'Figure'),\n",
            "((2042, 2044), 'Figure 1A'),\n",
            "((2043, 2044), '1D'),\n",
            "((2043, 2044), '##D'),\n",
            "((2044, 2046), 'black arrows'),\n",
            "((2047, 2048), '##elic'),\n",
            "((2047, 2049), '##lic Series'),\n",
            "((2048, 2049), 'Series'),\n",
            "((2050, 2051), 'BMP'),\n",
            "((2050, 2051), 'De'),\n",
            "((2050, 2051), 'Deficient'),\n",
            "((2051, 2052), 'Lim'),\n",
            "((2052, 2053), 'Mi'),\n",
            "((2052, 2053), 'Mice'),\n",
            "((2052, 2058), 'Mice were generated with limbs def'),\n",
            "((2052, 2058), 'Mice were generated with limbs deficient'),\n",
            "((2052, 2060), 'Mice were generated with limbs deficient in BMP2'),\n",
            "((2052, 2061), 'Mice were generated with limbs deficient in BMP2 , BMP4'),\n",
            "((2052, 2065), 'Mice were generated with limbs deficient in BMP2 , BMP4 , or BMP7 , both BMP2'),\n",
            "((2052, 2067), 'Mice were generated with limbs deficient in BMP2 , BMP4 , or BMP7 , both BMP2 and BMP'),\n",
            "((2052, 2067), 'Mice were generated with limbs deficient in BMP2 , BMP4 , or BMP7 , both BMP2 and BMP4'),\n",
            "((2057, 2058), 'def'),\n",
            "((2059, 2060), 'BMP'),\n",
            "((2060, 2061), '##MP4'),\n",
            "((2062, 2063), 'B'),\n",
            "((2062, 2063), 'BMP'),\n",
            "((2062, 2063), '##MP'),\n",
            "((2064, 2065), 'BMP'),\n",
            "((2066, 2067), 'BMP'),\n",
            "((2069, 2070), 'B'),\n",
            "((2069, 2070), 'BMP'),\n",
            "((2071, 2072), 'B'),\n",
            "((2071, 2072), 'BMP'),\n",
            "((2071, 2072), '##MP'),\n",
            "((2075, 2077), 'initial indication'),\n",
            "((2078, 2080), 'the range'),\n",
            "((2081, 2082), 'p'),\n",
            "((2081, 2082), 'phen'),\n",
            "((2084, 2086), 'these animals'),\n",
            "((2091, 2092), 'skeletons'),\n",
            "((2094, 2095), 'animals'),\n",
            "((2094, 2095), 'animals .'),\n",
            "((2095, 2096), 'B'),\n",
            "((2095, 2096), 'BMP'),\n",
            "((2095, 2096), 'BMP2 - deficient'),\n",
            "((2095, 2098), 'BMP2 - deficient limbs appeared'),\n",
            "((2095, 2104), 'BMP2 - deficient limbs appeared remarkably normal , both in skeletal pattern'),\n",
            "((2095, 2112), 'BMP2 - deficient limbs appeared remarkably normal , both in skeletal pattern and in gross aspects of chondrogenesis and osteogen'),\n",
            "((2095, 2096), '##MP'),\n",
            "((2095, 2096), 'def'),\n",
            "((2095, 2096), 'deficient'),\n",
            "((2096, 2098), 'limbs appeared'),\n",
            "((2102, 2104), 'skeletal pattern'),\n",
            "((2103, 2104), 'pattern'),\n",
            "((2111, 2112), '##steogen'),\n",
            "((2111, 2112), '##ogen'),\n",
            "((2114, 2115), 'Al'),\n",
            "((2114, 2115), 'Alcian'),\n",
            "((2115, 2116), '##zar'),\n",
            "((2115, 2116), '##zarin'),\n",
            "((2117, 2118), 'stain'),\n",
            "((2117, 2118), 'staining'),\n",
            "((2118, 2120), 'The one'),\n",
            "((2124, 2125), 'append'),\n",
            "((2132, 2133), 'ma'),\n",
            "((2132, 2133), 'malf'),\n",
            "((2135, 2136), '##capula'),\n",
            "((2136, 2138), 'Figure 1'),\n",
            "((2140, 2141), 'B'),\n",
            "((2140, 2141), 'BMP'),\n",
            "((2140, 2150), 'BMP2 - deficient limbs also exhibit 3 / 4 soft - tissue syndactyly with variable penetrance'),\n",
            "((2140, 2141), '##MP'),\n",
            "((2140, 2141), 'def'),\n",
            "((2140, 2141), 'deficient'),\n",
            "((2145, 2150), 'soft - tissue syndactyly with variable penetrance'),\n",
            "((2145, 2150), '- tissue syndactyly with variable penetrance'),\n",
            "((2146, 2147), '##yn'),\n",
            "((2146, 2147), '##ynda'),\n",
            "((2146, 2150), '##yndactyly with variable penetrance'),\n",
            "((2146, 2147), '##da'),\n",
            "((2146, 2147), '##yly'),\n",
            "((2146, 2150), '##yly with variable penetrance'),\n",
            "((2148, 2150), 'variable penetrance'),\n",
            "((2149, 2150), 'pen'),\n",
            "((2149, 2150), 'penet'),\n",
            "((2149, 2150), 'penetrance'),\n",
            "((2149, 2150), '##et'),\n",
            "((2149, 2150), '##rance'),\n",
            "((2150, 2151), 'Figure'),\n",
            "((2150, 2152), 'Figure 2'),\n",
            "((2152, 2153), 'Mi'),\n",
            "((2152, 2153), 'Mice'),\n",
            "((2152, 2159), 'Mice with limbs deficient in BMP4 activity'),\n",
            "((2157, 2158), 'B'),\n",
            "((2157, 2158), 'BMP'),\n",
            "((2157, 2159), 'BMP4 activity'),\n",
            "((2157, 2158), '##MP'),\n",
            "((2157, 2159), '##4 activity'),\n",
            "((2158, 2159), 'activity'),\n",
            "((2163, 2164), 'B'),\n",
            "((2163, 2164), 'Bmp'),\n",
            "((2163, 2164), '##mp'),\n",
            "((2173, 2174), '[ 16'),\n",
            "((2173, 2174), ']'),\n",
            "((2176, 2185), 'absence of BMP4 activity , limbs display a variable penetrance'),\n",
            "((2176, 2187), 'absence of BMP4 activity , limbs display a variable penetrance of preaxial'),\n",
            "((2176, 2189), 'absence of BMP4 activity , limbs display a variable penetrance of preaxial and postaxial'),\n",
            "((2178, 2179), 'B'),\n",
            "((2178, 2179), 'BMP'),\n",
            "((2178, 2185), 'BMP4 activity , limbs display a variable penetrance'),\n",
            "((2178, 2179), '##MP'),\n",
            "((2179, 2180), 'activity ,'),\n",
            "((2179, 2185), 'activity , limbs display a variable penetrance'),\n",
            "((2184, 2185), 'penet'),\n",
            "((2184, 2185), '##et'),\n",
            "((2186, 2187), 'preax'),\n",
            "((2188, 2189), 'post'),\n",
            "((2188, 2189), 'postax'),\n",
            "((2189, 2190), 'poly'),\n",
            "((2189, 2190), '##dact'),\n",
            "((2189, 2190), '##yl'),\n",
            "((2189, 2190), '##yly'),\n",
            "((2189, 2190), '##y'),\n",
            "((2201, 2202), '1G'),\n",
            "((2203, 2204), '1O'),\n",
            "((2208, 2209), 'described ,'),\n",
            "((2208, 2217), 'described , mice homozygous for a null mutation in Bmp7'),\n",
            "((2208, 2221), 'described , mice homozygous for a null mutation in Bmp7 [ 12 ] have no defects'),\n",
            "((2208, 2228), 'described , mice homozygous for a null mutation in Bmp7 [ 12 ] have no defects in the formation of the normal append'),\n",
            "((2210, 2211), '##zygo'),\n",
            "((2210, 2211), '##go'),\n",
            "((2216, 2217), 'B'),\n",
            "((2216, 2217), 'Bmp'),\n",
            "((2216, 2217), '##mp'),\n",
            "((2217, 2218), '[ 12'),\n",
            "((2219, 2221), 'no defects'),\n",
            "((2227, 2228), 'append'),\n",
            "((2231, 2232), '1H'),\n",
            "((2233, 2234), '1P'),\n",
            "((2238, 2239), 'preax'),\n",
            "((2238, 2240), 'preaxial polydact'),\n",
            "((2239, 2240), 'poly'),\n",
            "((2239, 2240), '##oly'),\n",
            "((2239, 2240), '##da'),\n",
            "((2239, 2240), '##dact'),\n",
            "((2239, 2240), '##yly'),\n",
            "((2242, 2243), 'mutants'),\n",
            "((2243, 2244), 'Compo'),\n",
            "((2243, 2259), 'Compound heterozygous mice , with one functional copy each of Bmp2 and Bmp4 in the limb ( Bmp2'),\n",
            "((2244, 2245), '##zygo'),\n",
            "((2244, 2259), '##zygous mice , with one functional copy each of Bmp2 and Bmp4 in the limb ( Bmp2'),\n",
            "((2244, 2245), '##go'),\n",
            "((2244, 2246), '##us mice'),\n",
            "((2252, 2253), 'B'),\n",
            "((2252, 2253), 'Bmp'),\n",
            "((2252, 2253), 'Bmp2'),\n",
            "((2252, 2255), 'Bmp2 and Bmp4'),\n",
            "((2252, 2259), 'Bmp2 and Bmp4 in the limb ( Bmp2'),\n",
            "((2252, 2253), '##2'),\n",
            "((2254, 2255), 'B'),\n",
            "((2254, 2255), 'Bmp'),\n",
            "((2254, 2255), '##mp'),\n",
            "((2256, 2258), 'the limb'),\n",
            "((2257, 2258), 'limb'),\n",
            "((2258, 2259), '##mp'),\n",
            "((2258, 2259), '##mp2'),\n",
            "((2259, 2260), 'B'),\n",
            "((2259, 2260), '##mp'),\n",
            "((2259, 2260), '##mp4'),\n",
            "((2259, 2260), '/ C'),\n",
            "((2260, 2261), 'P'),\n",
            "((2260, 2261), 'Pr'),\n",
            "((2260, 2261), '##x1'),\n",
            "((2260, 2261), 'c'),\n",
            "((2260, 2261), 'cre'),\n",
            "((2266, 2267), 'limb'),\n",
            "((2266, 2268), 'limb pattern'),\n",
            "((2269, 2270), '##keleto'),\n",
            "((2271, 2272), 'data'),\n",
            "((2283, 2284), 'B'),\n",
            "((2283, 2284), 'Bmp'),\n",
            "((2283, 2300), 'Bmp4 gene and one copy of the Bmp2 gene have been conditionally removed in the limb ( Bmp2'),\n",
            "((2283, 2284), '##mp'),\n",
            "((2290, 2291), 'B'),\n",
            "((2290, 2291), 'Bmp'),\n",
            "((2290, 2300), 'Bmp2 gene have been conditionally removed in the limb ( Bmp2'),\n",
            "((2290, 2291), '##mp'),\n",
            "((2291, 2293), 'gene have'),\n",
            "((2294, 2295), 'conditionally'),\n",
            "((2294, 2300), 'conditionally removed in the limb ( Bmp2'),\n",
            "((2297, 2299), 'the limb'),\n",
            "((2298, 2299), 'limb'),\n",
            "((2299, 2300), 'B'),\n",
            "((2299, 2300), '##mp'),\n",
            "((2299, 2300), '##mp2'),\n",
            "((2300, 2301), 'B'),\n",
            "((2300, 2301), 'Bmp'),\n",
            "((2300, 2301), '##mp'),\n",
            "((2301, 2302), 'P'),\n",
            "((2301, 2302), 'Pr'),\n",
            "((2301, 2302), '##x1'),\n",
            "((2301, 2314), '##x1 : : cre ) are phenotypically normal other than exhibiting the variable penetrance preaxial and postaxial'),\n",
            "((2301, 2302), 'cre'),\n",
            "((2301, 2302), '##re'),\n",
            "((2303, 2304), 'phen'),\n",
            "((2310, 2311), 'pen'),\n",
            "((2310, 2311), 'penet'),\n",
            "((2310, 2311), 'penetrance'),\n",
            "((2310, 2312), 'penetrance preax'),\n",
            "((2310, 2312), 'penetrance preaxial'),\n",
            "((2310, 2314), 'penetrance preaxial and postaxial'),\n",
            "((2310, 2311), '##et'),\n",
            "((2311, 2312), 'preax'),\n",
            "((2311, 2312), '##ax'),\n",
            "((2313, 2314), 'postax'),\n",
            "((2314, 2315), 'poly'),\n",
            "((2314, 2315), '##da'),\n",
            "((2314, 2315), '##dact'),\n",
            "((2314, 2315), '##ct'),\n",
            "((2314, 2315), '##yl'),\n",
            "((2314, 2315), '##yly'),\n",
            "((2318, 2319), 'def'),\n",
            "((2320, 2321), 'B'),\n",
            "((2320, 2321), 'BMP'),\n",
            "((2320, 2321), '##MP'),\n",
            "((2324, 2325), '1J'),\n",
            "((2324, 2325), '##J'),\n",
            "((2335, 2336), 'B'),\n",
            "((2335, 2336), 'Bmp2'),\n",
            "((2335, 2336), '##mp'),\n",
            "((2335, 2336), '##mp2'),\n",
            "((2335, 2336), '##2'),\n",
            "((2337, 2339), 'one copy'),\n",
            "((2340, 2341), 'B'),\n",
            "((2340, 2341), 'Bmp'),\n",
            "((2340, 2341), 'Bmp4'),\n",
            "((2340, 2345), 'Bmp4 had been removed ( Bmp2'),\n",
            "((2340, 2347), 'Bmp4 had been removed ( Bmp2C / C ; Bmp4 + / C ; Prx1 :'),\n",
            "((2340, 2341), '##mp'),\n",
            "((2344, 2345), '##mp'),\n",
            "((2344, 2345), '##mp2'),\n",
            "((2345, 2346), 'B'),\n",
            "((2345, 2346), '##mp'),\n",
            "((2345, 2346), '##mp4'),\n",
            "((2345, 2346), '/ C'),\n",
            "((2346, 2347), 'P'),\n",
            "((2346, 2347), 'Pr'),\n",
            "((2346, 2347), '##x1'),\n",
            "((2346, 2347), 'c'),\n",
            "((2346, 2347), 'cre'),\n",
            "((2346, 2347), '##re'),\n",
            "((2352, 2354), 'including significantly'),\n",
            "((2355, 2356), 'skeletal'),\n",
            "((2355, 2357), 'skeletal elements'),\n",
            "((2358, 2360), 'the digit'),\n",
            "((2359, 2360), 'digit'),\n",
            "((2363, 2364), 'animals'),\n",
            "((2367, 2368), 'Figure'),\n",
            "((2367, 2369), 'Figure 1'),\n",
            "((2370, 2371), '##Q'),\n",
            "((2377, 2378), 'B'),\n",
            "((2377, 2378), 'Bmp'),\n",
            "((2379, 2380), 'B'),\n",
            "((2379, 2380), '##mp4'),\n",
            "((2380, 2382), 'were removed'),\n",
            "((2382, 2383), 'B'),\n",
            "((2382, 2383), '##mp'),\n",
            "((2382, 2383), '##mp2'),\n",
            "((2382, 2383), '/ C'),\n",
            "((2383, 2384), 'B'),\n",
            "((2383, 2384), 'Bmp'),\n",
            "((2383, 2384), '##mp'),\n",
            "((2383, 2384), '/ C'),\n",
            "((2384, 2385), 'P'),\n",
            "((2384, 2385), 'Pr'),\n",
            "((2384, 2385), '##x1'),\n",
            "((2384, 2385), 'c'),\n",
            "((2384, 2385), 'cre'),\n",
            "((2384, 2385), '##re'),\n",
            "((2387, 2388), 'ma'),\n",
            "((2387, 2388), 'malf'),\n",
            "((2387, 2388), '##lf'),\n",
            "((2389, 2391), 'Figure 1'),\n",
            "((2389, 2393), 'Figure 1K and 1S'),\n",
            "((2389, 2393), 'Figure 1K and 1S )'),\n",
            "((2392, 2393), '1'),\n",
            "((2392, 2393), '1S'),\n",
            "((2392, 2393), '##S'),\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGJ5JWDUddtQ",
        "outputId": "7f681ff1-d40c-4e8e-a88a-31ab0bdf6789"
      },
      "source": [
        "!zip -r /content/out.zip /content/coref/data/out "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/coref/data/out/ (stored 0%)\n",
            "  adding: content/coref/data/out/17465682_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/16611361_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15850489_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/16787536_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/16517939_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15615595_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15238161_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/15238161_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16026622_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15018652_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17503968_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15615595_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16026622_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17206865_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17201918_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15619330_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17201918_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/14675480_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/11604102_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17565376_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15615595_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15850489_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/14691534_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/15328538_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16800892_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15070402_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15070402_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16968134_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15882093_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/11604102_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/14675480_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/11319941_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17565376_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15018652_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/16968134_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/11604102_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16410827_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17206865_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/16027110_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15238161_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17029558_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16968134_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15560850_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/14675480_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/14691534_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/11604102_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/17206865_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17465682_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16517939_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16517939_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17565376_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16027110_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15619330_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/11319941_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16026622_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17677002_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15018652_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16800892_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15238161_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16787536_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/11319941_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16800892_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15615595_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15850489_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15018652_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15560850_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15784609_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17677002_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16787536_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15882093_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17503968_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15328538_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15784609_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15560850_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/14691534_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17503968_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/14691534_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16611361_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15615595_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/14691534_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17206865_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16787536_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15328538_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16968134_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16027110_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17503968_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/14624252_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/15619330_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/15018652_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17206865_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17029558_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17503968_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16410827_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17677002_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16027110_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16611361_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/14624252_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16517939_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17677002_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15070402_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17029558_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16787536_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15882093_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/17029558_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15619330_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17465682_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15560850_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17465682_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/14624252_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/11604102_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16517939_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16026622_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/17201918_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/11319941_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15070402_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16410827_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17201918_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15850489_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17201918_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17565376_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16611361_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16410827_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/14624252_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/14624252_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16027110_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/14675480_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/16968134_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/17677002_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15328538_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15328538_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15882093_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/15784609_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/16611361_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17565376_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15070402_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/16410827_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/16800892_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/15882093_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/15238161_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16800892_3.jsonlines (deflated 84%)\n",
            "  adding: content/coref/data/out/15850489_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15560850_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15784609_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/17029558_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/17465682_1.jsonlines (stored 0%)\n",
            "  adding: content/coref/data/out/14675480_2.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/11319941_0.jsonlines (deflated 82%)\n",
            "  adding: content/coref/data/out/15784609_1.jsonlines (deflated 83%)\n",
            "  adding: content/coref/data/out/16026622_4.jsonlines (deflated 85%)\n",
            "  adding: content/coref/data/out/15619330_3.jsonlines (deflated 84%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sX8IJG2Sd7aZ",
        "outputId": "9c031a42-3204-43d8-849b-01a71ce9d4c4"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/out.zip\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_93b34034-5bc1-4af4-9d31-3bfae8dea4fe\", \"out.zip\", 2223556)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}