{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook\n",
    "Nils Broman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## March 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 25 March (25-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Go through steps of onboarding EDAN70 section in wiki. Refresh git knowledge \n",
    "\n",
    "**Description:**\n",
    "\n",
    "Started the [\"Git Complete: The definitive, step-by-step guide to Git\"](https://www.udemy.com/course/git-complete/) course on Udemy, read lab rules, checked that the teams and planner work.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue with the git course, decide what NLP project to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturday 26 March (26-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Continue with git course\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Nearly finished the course.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Finish the course, decide on project, set up environment and git folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 29 March (29-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Finish git course\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Completed the git course. \n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Set up work environment and git repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday 30 March (30-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Set up work environment, learn more about transformers\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Created a new conda (v4.10.1) environment with python 3.10.4, tensorflow 2.8, cuda 11.2, cudnn 8.1.1\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday 31 March (31-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Read report of earlier project (\"Relation Extraction from medical literature using SciBERT\" by L. Axlin and K. Broman)\n",
    "* Set up new environment with PyTorch\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Realized that the project this builds upon uses pytorch rather than tensorflow. Created a new conda (v4.10.1) environment with python 3.9.11, pytorch 1.11.0 and cuda 11.3. Also created notebooks to check that the environments used the gpu correctly.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Finish reading report, download datasets and set up the SciBERT pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## April 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 1 April (01.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Read report on prior project (\"Relation Extraction from medical literature using SciBERT\" by L. Axlin and K. Broman)\n",
    "* Get familiarized with their code\n",
    "* Set up pipeline\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Previous project references to [Alexander Petter's github](https://github.com/Aitslab/nlp_2021_alexander_petter) for setting up the environment, where I learn that it's built on the older tensorflow version 1.15 and my current environments won't work. I tried following the setup, but being on the train with limited internet connection I ran into several problems. Read more about older pytorch and tensorflow versions and their compatibilities with different versions of CUDA/cuDNN, and realized that my desktop GPU may not be compatible with older versions. I'll have to look into this further when I get home. \n",
    "\n",
    "Read some more about NLP and SciBERT, including the [originial paper](https://arxiv.org/pdf/1903.10676.pdf).\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue to get familiarized with the code, investigate compatibility of tensorflow, cuda etc, and try to set up work environment and pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday 3 April (03.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Learn more about NLP, in particular relation extraction. \n",
    "\n",
    "**Description:**\n",
    "\n",
    "Continued reading and watching lectures on NLP and RE. Some worth mentioning:\n",
    "\n",
    "[2019 Stanford lecture on relation extraction](https://www.youtube.com/watch?v=pO3Jsr31s_Q&list=PLNTMtnglvwsP9WAJrohDazRXX7zBXGPDW&index=5) and [the updated series from 2021](https://www.youtube.com/watch?v=4AjieiJ1CXo&list=PLoROMvodv4rPt5D0zs3YhbWSZA8Q_DyiJ&index=44)\n",
    "\n",
    "[ChemProt article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013776/)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue to get familiarized with the code, investigate compatibility of tensorflow, cuda etc, and try to set up work environment and pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 5 April (05.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Download datasets and set up SciBERT pipeline \n",
    "\n",
    "**Description:**\n",
    "\n",
    "Had big struggles getting tensorflow to work properly due to older version being incompatable rtx30xx gpus (tf 1.15 only works with cuda 10 and the gpus with cuda 11). Found some potential workarounds but they only worked on linux and my linux boot is not stable atm and I'm most likely going to reinstall it again from scratch, which doesn't seem like a priority. After further investigation of the code, it appears that this part of the project mostly uses pytorch and tf is used for another part of the complete projekt, namely NER-tagging. I decided on letting tf run on cpu for now and instead focus on actually setting up the pipeline.\n",
    "\n",
    "Downloaded the [chremprot corpus](https://biocreative.bioinformatics.udel.edu/news/corpora/chemprot-corpus-biocreative-vi/) and processed it using [alexanders extract_relation](https://github.com/Aitslab/nlp_2021_alexander_petter/tree/master/utils/chemprot)\n",
    "\n",
    "Added the [scripts from lykke_klara](https://github.com/Aitslab/BioNLP/tree/master/lykke_klara) and tried to add custom labels/build the data sets, but ran in to some issues with getting the correct paths.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue setting up the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday 6 April (06.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Finish setting up the pipeline \n",
    "\n",
    "**Description:**\n",
    "\n",
    "The path issue was just a late night typo. Updated the config file for my paths, ran the custom labeling for all data sets. Ran the full pipeline on the sample set, specified encoding to the file opening in evaluation. Then trained the baseline model. Had some key error when running the plot script.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Fix plot script and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday 7 April (07.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Finish setting up the pipeline \n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Updated config file to use same keys as in the plot script.\n",
    "* **Changed the initial tokenizer in the finetuning to the pretrained scibert rather than pretrained bert-base.** This had a massive effect on performance, increasing the f1-score on the baseline model from 0.51 to 0.85. I'm a bit sceptical to whether I've misunderstood something or if the previous group missed this. I can't see any mentions in neither their report nor their log.\n",
    "* Updated config file and overall structure of saved output data, such that each run saves the models, metrics and plots in a collected folder.\n",
    "* Corrected the title from \"average training accuracy\" to \"average validation accuracy\" in the output metric from bert_finetune.\n",
    "* Corrected (swapped) the names of training and validation in the loss/accuracy plot\n",
    "* Updated the plot file such that it only saves the plots instead of displaying them, so one doesn't have to close each plot manually\n",
    "* Added timestamps for each script in main and a printed report of time taken in the end of main\n",
    "* Skimmed [ON THE STABILITY OF FINE-TUNING BERT: MISCONCEPTIONS, EXPLANATIONS, AND STRONG BASELINES](https://arxiv.org/pdf/2006.04884.pdf). We appear to be using roughly the same method, without the warmup. \n",
    "* Trained 3 baseline models and 2 oversampled models with initial scibert tokenizer. The oversampled suffered from substantially larger validation loss without any major changes in any other metric. I think I need to investigate the individual confusion matrices for each category and not just the averages. I'm also curious what loss function is used during the finetuning.\n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Investigate individual confusion matrices for the models. Perhaps write a script for better visualization. \n",
    "* Add the artificial construction to the pipeline. \n",
    "* Start adding references to the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 8 April (08.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Investigate loss and confusion matrices\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Tried to find what loss functioned is used. Couldn't find any specification of loss in bert_finetune, but from [class code of BertForSequenceClassification](https://github.com/huggingface/transformers/blob/198c335d219a5eb4d3f124fdd1ce1a9cd9f78a9b/src/transformers/models/bert/modeling_bert.py#L1582) it looks like it uses [BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) which is a BCE loss with combined sigmoid layer. I'm a little curious as to why we do multi label classification since the relations.\n",
    "* After thorough investigation of the evaluation script, I realized that the use of multi label confusion matrices had me falsely believe it was a multi label problem, but it is in fact multi class.\\* \n",
    "* Updated json dump of metrics from eval to be more readable (added indent and linebreaks)\n",
    "* Updated eval to also include micro and weighted averages, as well as confusion matrices (not binary).\n",
    "\n",
    "\\* I couldn't get the confusion matrices to add upp to the scores correctly either, but it was because I was reading them wrong. I'm more used to the binary confusion matrices to have a different shape, see tables below \n",
    "\n",
    "<table>\n",
    "<tr><th> What I'm used to </th><th> sklearn format</th></tr>\n",
    "<tr><td>\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|TP|FP|\n",
    "|FN|TN|\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|TN|FP|\n",
    "|TN|TP|\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Update plot to include the newly added metrics\n",
    "* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday 11 April (11.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Update plots to include new metrics\n",
    "* Train a model for more epochs\n",
    "* Investigate the effects of longer training\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Started updating the plot script, but due to the ammount of metrics I decided to do a new notebook for plots, so one can more easily do single plots and tweaks.\n",
    "* The notebook became quite messy since I based it heavily on the old script that was built to run with the main script. Might have to clean it up and tweak it later. It can not plot all listed metrics and confusion matrices.\n",
    "* Trained a baseline model for 20 epochs. \n",
    "* Noticed a large dip performance on all fronts (**for both data sets**) after epoch 12, and a mostly steady increase again after, though never reaching the same performance as in epoch 12. This is not the simple case of overtraining, since it affected the training set just as much as the developement set. I'm curious as to what happens if trained for even longer and if it can reach the same performance again, or posibly even outperform it. I find it unlikely since the training set reached close to perfect score (>0.99), but still worth exploring.\n",
    "\n",
    "*Maybe add a figure here*\n",
    "\n",
    "![title](log-media/f1-score-baseline-20-v2.png)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Train a model for even more epochs, maybe 40.\n",
    "* Start implementing the artificiall building of corpora.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 12 April (12.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Train a model for 40 epochs and evaluate\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Trained a model for 40 epochs\n",
    "* Noticed a strange trend of drastic drop in all scores, for both datasets, and appaer to have a frequency of  11-13 epochs. I find it really strange that it looks like it's \n",
    "* Updated the plot notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](log-media/f1-score-baseline-40-v2.png)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Implement construction of artificiall corpora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturday 16 April (16.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Implement construction of artificiall corpora\n",
    "\n",
    "**Description:**\n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday 17 April (17.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Implement construction of artificiall corpora\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Downloaded the [building blocks](https://drive.google.com/drive/folders/1REtDAAx6rfL2JkO0FLCg3xIQOT9xJCkS) and constructed an artificial dev and train set\n",
    "* Updated plotting notebook to be independant of the config.json, and instead handle paths within the notebook.\n",
    "* Wrote a quick function (in plotting notebook) to extract the best scores and at what epoch they were achieved, and compared the models from 40 and 20 epochs and came to realize a couple of things\n",
    "    * While the scores for the train set seem to peak after around 7-10 epochs, the score on the dev set do increase, albeit little (0.5-1 pp) and with high variance and with continued increase in loss. \n",
    "    * Due to the high variance (could drop up to around 2-3 pp) I'd say this improvement is an unreliable source, most likely caused by the stochastic nature of the optimization, and picking a later model will most likely just result in an overfit to the dev set, with no additional benefit to other uses. One must be careful of ones own bias.\n",
    "    * Since we do multiclass (not multilabel) classification, there won't be any overlapp so the micro average for f1-score, recall and precision is simply the same as accuracy, and give no more information.\n",
    "\n",
    ".\n",
    "\n",
    "* I still can't figure out what causes the performance drops later in training. \n",
    "* Thought some about with the idea of using an ensamble approach.\n",
    "\n",
    ".\n",
    "\n",
    "* Updated entry of Monday and Tuesday to include an image of f1-score.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Train a few models, using different combinations of the datasets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday 18 April (18.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Train and evaluate models on the artificial sets\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Trained a network on the artificial training set (with all classes having support 10000 so 50000 in total)\n",
    "* Finetuning went fine but the evaluation crashed and raised a JSONDecodeError \n",
    "~~~python\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "~~~\n",
    "* Turns out the artificial constructor ends the sets with an empty line, which causes the crash cause it expects a dictionary. Quite ironic that almost two hours of debugging ended up with the problem being \"nothing\". Manually removed the empty lines for now, but might fix the constructor later \n",
    "* Ran evaluation, and it has perfect accuracy already after the first epoch. Since the artificial training set is so large (50000 compared to the just under 6500 of the chemprot training set), each epoch has more than 7 times the training, so just training for 1 epoch here is more comparable to 7 epochs for chemprot, which is around the peak for the other models. On top of this, all the artificial examples share the same structure, for both the training and development set, so one can expect it to perform much worse on the chemprot data.\n",
    "* Ran evaluation of the artificial model on the chemprot data, and as expected it performed much worse. We do however see an improvement of almost 5 pp for both sets (38-42 for train and 40-45 for dev) for the fifth epoch compared to the first, so longer training might actually allow for even more improvement. \n",
    "* Started evaluation of the artificial sets on the models from the baseline of 40 epochs. This will probably take all night, since we'll evaluate 40 models on 55000 sentences. \n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Create plots for the new evaluations and continue experimenting with combinations of the artificial and chemprot corpora.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78535e8465fcbd3302648d6980beb684db0b529edb1b5f591d2edb62135f7fe5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
