{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook\n",
    "Nils Broman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## March 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 25 March (25-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Go through steps of onboarding EDAN70 section in wiki. Refresh git knowledge \n",
    "\n",
    "**Description:**\n",
    "\n",
    "Started the [\"Git Complete: The definitive, step-by-step guide to Git\"](https://www.udemy.com/course/git-complete/) course on Udemy, read lab rules, checked that the teams and planner work.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue with the git course, decide what NLP project to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturday 26 March (26-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Continue with git course\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Nearly finished the course.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Finish the course, decide on project, set up environment and git folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 29 March (29-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Finish git course\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Completed the git course. \n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Set up work environment and git repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday 30 March (30-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Set up work environment, learn more about transformers\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Created a new conda (v4.10.1) environment with python 3.10.4, tensorflow 2.8, cuda 11.2, cudnn 8.1.1\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday 31 March (31-03-22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Read report of earlier project (\"Relation Extraction from medical literature using SciBERT\" by L. Axlin and K. Broman)\n",
    "* Set up new environment with PyTorch\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Realized that the project this builds upon uses pytorch rather than tensorflow. Created a new conda (v4.10.1) environment with python 3.9.11, pytorch 1.11.0 and cuda 11.3. Also created notebooks to check that the environments used the gpu correctly.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Finish reading report, download datasets and set up the SciBERT pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## April 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 1 April (01.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Read report on prior project (\"Relation Extraction from medical literature using SciBERT\" by L. Axlin and K. Broman)\n",
    "* Get familiarized with their code\n",
    "* Set up pipeline\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Previous project references to [Alexander Petter's github](https://github.com/Aitslab/nlp_2021_alexander_petter) for setting up the environment, where I learn that it's built on the older tensorflow version 1.15 and my current environments won't work. I tried following the setup, but being on the train with limited internet connection I ran into several problems. Read more about older pytorch and tensorflow versions and their compatibilities with different versions of CUDA/cuDNN, and realized that my desktop GPU may not be compatible with older versions. I'll have to look into this further when I get home. \n",
    "\n",
    "Read some more about NLP and SciBERT, including the [originial paper](https://arxiv.org/pdf/1903.10676.pdf).\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue to get familiarized with the code, investigate compatibility of tensorflow, cuda etc, and try to set up work environment and pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday 3 April (03.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Learn more about NLP, in particular relation extraction. \n",
    "\n",
    "**Description:**\n",
    "\n",
    "Continued reading and watching lectures on NLP and RE. Some worth mentioning:\n",
    "\n",
    "[2019 Stanford lecture on relation extraction](https://www.youtube.com/watch?v=pO3Jsr31s_Q&list=PLNTMtnglvwsP9WAJrohDazRXX7zBXGPDW&index=5) and [the updated series from 2021](https://www.youtube.com/watch?v=4AjieiJ1CXo&list=PLoROMvodv4rPt5D0zs3YhbWSZA8Q_DyiJ&index=44)\n",
    "\n",
    "[ChemProt article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013776/)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue to get familiarized with the code, investigate compatibility of tensorflow, cuda etc, and try to set up work environment and pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 5 April (05.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Download datasets and set up SciBERT pipeline \n",
    "\n",
    "**Description:**\n",
    "\n",
    "Had big struggles getting tensorflow to work properly due to older version being incompatable rtx30xx gpus (tf 1.15 only works with cuda 10 and the gpus with cuda 11). Found some potential workarounds but they only worked on linux and my linux boot is not stable atm and I'm most likely going to reinstall it again from scratch, which doesn't seem like a priority. After further investigation of the code, it appears that this part of the project mostly uses pytorch and tf is used for another part of the complete projekt, namely NER-tagging. I decided on letting tf run on cpu for now and instead focus on actually setting up the pipeline.\n",
    "\n",
    "Downloaded the [chremprot corpus](https://biocreative.bioinformatics.udel.edu/news/corpora/chemprot-corpus-biocreative-vi/) and processed it using [alexanders extract_relation](https://github.com/Aitslab/nlp_2021_alexander_petter/tree/master/utils/chemprot)\n",
    "\n",
    "Added the [scripts from lykke_klara](https://github.com/Aitslab/BioNLP/tree/master/lykke_klara) and tried to add custom labels/build the data sets, but ran in to some issues with getting the correct paths.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Continue setting up the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday 6 April (06.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Finish setting up the pipeline \n",
    "\n",
    "**Description:**\n",
    "\n",
    "The path issue was just a late night typo. Updated the config file for my paths, ran the custom labeling for all data sets. Ran the full pipeline on the sample set, specified encoding to the file opening in evaluation. Then trained the baseline model. Had some key error when running the plot script.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Fix plot script and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday 7 April (07.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Finish setting up the pipeline \n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Updated config file to use same keys as in the plot script.\n",
    "* **Changed the initial tokenizer in the finetuning to the pretrained scibert rather than pretrained bert-base.** This had a massive effect on performance, increasing the f1-score on the baseline model from 0.51 to 0.85. I'm a bit sceptical to whether I've misunderstood something or if the previous group missed this. I can't see any mentions in neither their report nor their log.\n",
    "* Updated config file and overall structure of saved output data, such that each run saves the models, metrics and plots in a collected folder.\n",
    "* Corrected the title from \"average training accuracy\" to \"average validation accuracy\" in the output metric from bert_finetune.\n",
    "* Corrected (swapped) the names of training and validation in the loss/accuracy plot\n",
    "* Updated the plot file such that it only saves the plots instead of displaying them, so one doesn't have to close each plot manually\n",
    "* Added timestamps for each script in main and a printed report of time taken in the end of main\n",
    "* Skimmed [ON THE STABILITY OF FINE-TUNING BERT: MISCONCEPTIONS, EXPLANATIONS, AND STRONG BASELINES](https://arxiv.org/pdf/2006.04884.pdf). We appear to be using roughly the same method, without the warmup. \n",
    "* Trained 3 baseline models and 2 oversampled models with initial scibert tokenizer. The oversampled suffered from substantially larger validation loss without any major changes in any other metric. I think I need to investigate the individual confusion matrices for each category and not just the averages. I'm also curious what loss function is used during the finetuning.\n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Investigate individual confusion matrices for the models. Perhaps write a script for better visualization. \n",
    "* Add the artificial construction to the pipeline. \n",
    "* Start adding references to the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 8 April (08.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Investigate loss and confusion matrices\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Tried to find what loss functioned is used. Couldn't find any specification of loss in bert_finetune, but from [class code of BertForSequenceClassification](https://github.com/huggingface/transformers/blob/198c335d219a5eb4d3f124fdd1ce1a9cd9f78a9b/src/transformers/models/bert/modeling_bert.py#L1582) it looks like it uses [BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) which is a BCE loss with combined sigmoid layer. I'm a little curious as to why we do multi label classification since the relations.\n",
    "* After thorough investigation of the evaluation script, I realized that the use of multi label confusion matrices had me falsely believe it was a multi label problem, but it is in fact multi class.\\* \n",
    "* Updated json dump of metrics from eval to be more readable (added indent and linebreaks)\n",
    "* Updated eval to also include micro and weighted averages, as well as confusion matrices (not binary).\n",
    "\n",
    "\\* I couldn't get the confusion matrices to add upp to the scores correctly either, but it was because I was reading them wrong. I'm more used to the binary confusion matrices to have a different shape, see tables below \n",
    "\n",
    "<table>\n",
    "<tr><th> What I'm used to </th><th> sklearn format</th></tr>\n",
    "<tr><td>\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|TP|FP|\n",
    "|FN|TN|\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|TN|FP|\n",
    "|TN|TP|\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Update plot to include the newly added metrics\n",
    "* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday 11 April (11.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Update plots to include new metrics\n",
    "* Train a model for more epochs\n",
    "* Investigate the effects of longer training\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Started updating the plot script, but due to the ammount of metrics I decided to do a new notebook for plots, so one can more easily do single plots and tweaks.\n",
    "* The notebook became quite messy since I based it heavily on the old script that was built to run with the main script. Might have to clean it up and tweak it later. It can not plot all listed metrics and confusion matrices.\n",
    "* Trained a baseline model for 20 epochs. \n",
    "* Noticed a large dip performance on all fronts (**for both data sets**) after epoch 12, and a mostly steady increase again after, though never reaching the same performance as in epoch 12. This is not the simple case of overtraining, since it affected the training set just as much as the developement set. I'm curious as to what happens if trained for even longer and if it can reach the same performance again, or posibly even outperform it. I find it unlikely since the training set reached close to perfect score (>0.99), but still worth exploring.\n",
    "\n",
    "*Maybe add a figure here*\n",
    "\n",
    "![title](log-media/f1-score-baseline-20-v2.png)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Train a model for even more epochs, maybe 40.\n",
    "* Start implementing the artificiall building of corpora.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 12 April (12.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Train a model for 40 epochs and evaluate\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Trained a model for 40 epochs\n",
    "* Noticed a strange trend of drastic drop in all scores, for both datasets, and appaer to have a frequency of  11-13 epochs. I find it really strange that it looks like it's \n",
    "* Updated the plot notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](log-media/f1-score-baseline-40-v2.png)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Implement construction of artificiall corpora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturday 16 April (16.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Implement construction of artificiall corpora\n",
    "\n",
    "**Description:**\n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday 17 April (17.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Implement construction of artificiall corpora\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Downloaded the [building blocks](https://drive.google.com/drive/folders/1REtDAAx6rfL2JkO0FLCg3xIQOT9xJCkS) and constructed an artificial dev and train set\n",
    "* Updated plotting notebook to be independant of the config.json, and instead handle paths within the notebook.\n",
    "* Wrote a quick function (in plotting notebook) to extract the best scores and at what epoch they were achieved, and compared the models from 40 and 20 epochs and came to realize a couple of things\n",
    "    * While the scores for the train set seem to peak after around 7-10 epochs, the score on the dev set do increase, albeit little (0.5-1 pp) and with high variance and with continued increase in loss. \n",
    "    * Due to the high variance (could drop up to around 2-3 pp) I'd say this improvement is an unreliable source, most likely caused by the stochastic nature of the optimization, and picking a later model will most likely just result in an overfit to the dev set, with no additional benefit to other uses. One must be careful of ones own bias.\n",
    "    * Since we do multiclass (not multilabel) classification, there won't be any overlapp so the micro average for f1-score, recall and precision is simply the same as accuracy, and give no more information.\n",
    "\n",
    ".\n",
    "\n",
    "* I still can't figure out what causes the performance drops later in training. \n",
    "* Thought some about with the idea of using an ensamble approach.\n",
    "\n",
    ".\n",
    "\n",
    "* Updated entry of Monday and Tuesday to include an image of f1-score.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Train a few models, using different combinations of the datasets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday 18 April (18.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Train and evaluate models on the artificial sets\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Trained a network on the artificial training set (with all classes having support 10000 so 50000 in total)\n",
    "* Finetuning went fine but the evaluation crashed and raised a JSONDecodeError \n",
    "~~~python\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "~~~\n",
    "* Turns out the artificial constructor ends the sets with an empty line, which causes the crash cause it expects a dictionary. Quite ironic that almost two hours of debugging ended up with the problem being \"nothing\". Manually removed the empty lines for now, but might fix the constructor later \n",
    "* Ran evaluation, and it has perfect accuracy already after the first epoch. Since the artificial training set is so large (50000 compared to the just under 6500 of the chemprot training set), each epoch has more than 7 times the training, so just training for 1 epoch here is more comparable to 7 epochs for chemprot, which is around the peak for the other models. On top of this, all the artificial examples share the same structure, for both the training and development set, so one can expect it to perform much worse on the chemprot data.\n",
    "* Ran evaluation of the artificial model on the chemprot data, and as expected it performed much worse. We do however see an improvement of almost 5 pp for both sets (38-42 for train and 40-45 for dev) for the fifth epoch compared to the first, so longer training might actually allow for even more improvement. \n",
    "* Started evaluation of the artificial sets on the models from the baseline of 40 epochs. This will probably take all night, since we'll evaluate 40 models on 55000 sentences. \n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Create plots for the new evaluations and continue experimenting with combinations of the artificial and chemprot corpora.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday 20 April (20.04.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Construct a spreadsheet with model metric summaries and plots\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* I want to automate the process such that the information of the model, evaluation metrics and plots were written to an xlsx-file directly. \n",
    "* Found that pandas has has a class [ExcelWriter](https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html) that can do this.\n",
    "* Since the most commonly used engine appeared to be [XlsxWriter ](https://xlsxwriter.readthedocs.io/index.html) and most of what I have isn't in pandas dataframes, I looked closer at the XlsxWriter module itself.\n",
    "* After starting to get the hang of how to use it, I realized with great disheartenment that this module can't open or edit existing files, only create new ones....\n",
    "* Found another module [OpenPyExcel](https://openpyxl.readthedocs.io/en/stable/index.html) that might be able to do what I'm looking for. I'll leave it for now though.\n",
    "\n",
    ".\n",
    "\n",
    "* Plotted and looked at the results from the evaluation of the baseline model on the artificial corpora and found that it performed quite terribly from start to finish, with around 50% accuary and no obvious improvement for models trained longer on the chemprot set. \n",
    "* This has me believe that the artificial set isn't a very good representation of how the texts in real article is structured. \n",
    "* The same drop in performance at some later epochs was noticable here as well, in particular the one at epoch 13. I'm very curious as to what could be causing this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](log-media/f1-score-baseline-40-art-data.png)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* Look for a better way to put together the summary of models. Might need to manually create and update the spreadsheet. \n",
    "* Train models on combination of artificial and chemprot data.\n",
    "* Consider ways to improve the artificial construction of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## May 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday 5 May (05.05.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "Go through log, freshen up on what has been done so far and start considering what to add to the report\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Since the biggest revelation that has come from my work so far was changing the tokenizer I figured it best to make sure that I have a correct understanding of their use, so I read the following\n",
    "\n",
    "\n",
    "[How to Build WordPiece Tokenizer for Bert](https://towardsdatascience.com/how-to-build-a-wordpiece-tokenizer-for-bert-f505d97dddbb)\n",
    "\n",
    "[Paper on WordPiece](https://arxiv.org/abs/1609.08144v2)\n",
    "\n",
    "[HuggingFace Tokenizer Summary](https://huggingface.co/docs/transformers/tokenizer_summary)\n",
    "\n",
    "**Next Steps:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday 9 May (09.05.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Create a sketch for the structure of the report/presentation and start adding things to the document\n",
    "* Get familiarized with the IEEE class in LaTex. \n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Made the sketch.\n",
    "* Added a few plots with temporary captions to document.\n",
    "* Added packages (graphicx, subcaptions and stfloats) for handling figures \n",
    "* Added lipsum package for generating text to be able to see that the figures were formattted correctly (e.g. cross columns).  \n",
    "\n",
    "\n",
    "**Next Steps:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday 12 May (12.05.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Extract chemicals from chemprot data\n",
    "* Build artificial corpora including said chemicals\n",
    "* Mix new artificial and chemprot corpora and train new model.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* Created script (extract relations.py) for extracting chemical names from chemprot_training_entities.tsv, saving them in a .txt-file \n",
    "* Updated build_art_corpus.py to use one chemical and one protein rather than two proteins\n",
    "* Created a new artificial train and dev sets, this time with roughly the same size as chemprot (5000/2500 for artificial and 6436/3556 for chemprot)\n",
    "* Trained a model on new artificial chemical-protein set with similar results as the old protein-protein set, i.e. (near) perfect score already after the first epoch on both train and dev, even with the much smaller train and larger dev (5000/2500 compared to 50000/500). However, the performance on the chemprot set was lower, which suggests either that the protein-protein configuration works better or, what I find more likely, that the larger size of the set improved the performance. \n",
    "* **Perhaps training on a larger artificial set for more epochs could improve the results. I settled for 5 since it had perfect scores on it's own dev set, but it's more interesting how it performs on the chemprot dev set**\n",
    "* Both artificial models had particularly large struggles with the \"PART-OF\" class for the chemprot data.\n",
    "* Created train/dev protein-protein sets of size 5000/2500 and trained for better comparison.\n",
    "*\n",
    "\n",
    "**Next Steps:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday 17 May (17.05.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Write script that creates mixed training sets \n",
    "* Start training mixed models\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* \n",
    "\n",
    "*NOTES:* \n",
    "* \n",
    "\n",
    "**Next Steps:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday 25 May (25.05.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Summarize the work last couple of weeks\n",
    "* Commit and push to github\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* I've been very inconsistent with the log lately, as well as with pushing to github. \n",
    "\n",
    "*NOTES:* \n",
    "* \n",
    "\n",
    "**Next Steps:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## June 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday 06 June (06.06.22)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Project:**\n",
    "\n",
    "Biomedical relation extraction with deep neural networks \n",
    "\n",
    "**Aim:**\n",
    "\n",
    "* Summarize the work last couple of weeks\n",
    "* Commit and push to github\n",
    "\n",
    "**Description:**\n",
    "\n",
    "* I've been very inconsistent with the log lately, as well as with pushing to github. \n",
    "\n",
    "*NOTES:* \n",
    "* \n",
    "\n",
    "**Next Steps:**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d015c87ff6c5bfb68a6381703a272f0b34137c3ddec8b8cb11f0b5aef30c56e8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('BioNLP-3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
