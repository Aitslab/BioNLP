Fri Apr 21 23:30:21 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:4E:00.0 Off |                    0 |
| N/A   27C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
***************************************************
You have loaded an anaconda module
***************************************************

JUST LOADING THIS MODULE DOES *NOT* CHANGE THE PYTHON VERSION, NOR ENABLES ANY
EXTRA PYTHON MODULES.

This module makes available the 'conda' command, with which users can create
named anaconda environments and then activate them.

To create and use a customized environment use 'conda create ...' and
then 'conda activate ...' (see example below).

---------------------------------------------------------------------------------------------------
NOTE: NSC strongly advices against placing 'conda activate' (with or without
arguments)
      in your shell initialization files, (e.g. '.bashrc' or '.bash_profile')
since this
      severly alters the environment for running software in ways that cause
unpredictable
      issues that can be difficult to diagnose.
---------------------------------------------------------------------------------------------------

Example usage:

  * Setting up a customized Anaconda environment and run a Python program in
it:

    conda create -n myenv python=3.8 scipy=1.5.2
    conda activate myenv
    python my_scipy_python_program.py

  * To run the python program in the same environment when logging in the next
time:

    conda activate myenv
    python my_scipy_python_program.py

More details on Anaconda environment management here:


https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html



../../mosesdecoder
500 samples in ../../data/BC5CDR/raw/train.json has been processed with 0 samples has no relations extracted.
500 samples in ../../data/BC5CDR/raw/valid.json has been processed with 0 samples has no relations extracted.
500 samples in ../../data/BC5CDR/raw/test.json has been processed with 0 samples has no relations extracted.
Preprocessing train
Tokenizer Version 1.1
Language: en
Number of threads: 8
Tokenizer Version 1.1
Language: en
Number of threads: 8
Loading codes from ../../data/BC5CDR/raw/bpecodes ...
Read 40000 codes from the codes file.
Loading vocabulary from ../../data/BC5CDR/raw/relis_train.tok.x ...
Read 111669 words (10611 unique) from text file.
Applying BPE to ../../data/BC5CDR/raw/relis_train.tok.x ...
Modified 111669 words from text file.
Loading codes from ../../data/BC5CDR/raw/bpecodes ...
Read 40000 codes from the codes file.
Loading vocabulary from ../../data/BC5CDR/raw/relis_train.tok.y ...
Read 9982 words (1218 unique) from text file.
Applying BPE to ../../data/BC5CDR/raw/relis_train.tok.y ...
Modified 9982 words from text file.
Preprocessing valid
Tokenizer Version 1.1
Language: en
Number of threads: 8
Tokenizer Version 1.1
Language: en
Number of threads: 8
Loading codes from ../../data/BC5CDR/raw/bpecodes ...
Read 40000 codes from the codes file.
Loading vocabulary from ../../data/BC5CDR/raw/relis_valid.tok.x ...
Read 110758 words (10466 unique) from text file.
Applying BPE to ../../data/BC5CDR/raw/relis_valid.tok.x ...
Modified 110758 words from text file.
Loading codes from ../../data/BC5CDR/raw/bpecodes ...
Read 40000 codes from the codes file.
Loading vocabulary from ../../data/BC5CDR/raw/relis_valid.tok.y ...
Read 9399 words (1102 unique) from text file.
Applying BPE to ../../data/BC5CDR/raw/relis_valid.tok.y ...
Modified 9399 words from text file.
Preprocessing test
Tokenizer Version 1.1
Language: en
Number of threads: 8
Tokenizer Version 1.1
Language: en
Number of threads: 8
Loading codes from ../../data/BC5CDR/raw/bpecodes ...
Read 40000 codes from the codes file.
Loading vocabulary from ../../data/BC5CDR/raw/relis_test.tok.x ...
Read 117143 words (10961 unique) from text file.
Applying BPE to ../../data/BC5CDR/raw/relis_test.tok.x ...
Modified 117143 words from text file.
Loading codes from ../../data/BC5CDR/raw/bpecodes ...
Read 40000 codes from the codes file.
Loading vocabulary from ../../data/BC5CDR/raw/relis_test.tok.y ...
Read 9772 words (1081 unique) from text file.
Applying BPE to ../../data/BC5CDR/raw/relis_test.tok.y ...
Modified 9772 words from text file.
2023-04-21 23:30:25 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='x', target_lang='y', trainpref='../../data/BC5CDR/raw/relis_train.tok.bpe', validpref='../../data/BC5CDR/raw/relis_valid.tok.bpe', testpref='../../data/BC5CDR/raw/relis_test.tok.bpe', align_suffix=None, destdir='../../data/BC5CDR/relis-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../../data/BC5CDR/raw/dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8, dict_only=False)
2023-04-21 23:30:25 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types
2023-04-21 23:30:25 | INFO | fairseq_cli.preprocess | [x] ../../data/BC5CDR/raw/relis_train.tok.bpe.x: 500 sents, 127539 tokens, 0.0% replaced (by <unk>)
2023-04-21 23:30:25 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [x] ../../data/BC5CDR/raw/relis_valid.tok.bpe.x: 500 sents, 126727 tokens, 0.0% replaced (by <unk>)
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [x] ../../data/BC5CDR/raw/relis_test.tok.bpe.x: 500 sents, 134570 tokens, 0.0% replaced (by <unk>)
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [y] ../../data/BC5CDR/raw/relis_train.tok.bpe.y: 500 sents, 11478 tokens, 0.0% replaced (by <unk>)
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [y] ../../data/BC5CDR/raw/relis_valid.tok.bpe.y: 500 sents, 10803 tokens, 0.0% replaced (by <unk>)
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | [y] ../../data/BC5CDR/raw/relis_test.tok.bpe.y: 500 sents, 11218 tokens, 0.0% replaced (by <unk>)
2023-04-21 23:30:26 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../../data/BC5CDR/relis-bin
START TRAINING...
2023-04-21 23:30:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../src', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/RE-BC5CDR-BioGPT', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '../../checkpoints/Pre-trained-BioGPT/checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_prompt_biogpt', 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': True, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': 1024, 'tpu': False}, 'task': {'_name': 'language_modeling_prompt', 'data': '../../data/BC5CDR/relis-bin', 'sample_break_mode': none, 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 1024, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'source_lang': None, 'target_lang': None, 'max_source_positions': 640, 'manual_prompt': None, 'learned_prompt': 9, 'learned_prompt_pattern': 'learned', 'prefix': False, 'sep_token': '<seqsep>'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 100, 'warmup_init_lr': 1e-07, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-04-21 23:30:30 | INFO | src.language_modeling_prompt | dictionary: 42384 types
2023-04-21 23:30:33 | INFO | fairseq_cli.train | TransformerLanguageModelPrompt(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(42393, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (12): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (13): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (14): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (15): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (16): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (17): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (18): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (19): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (20): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (21): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (22): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (23): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=42393, bias=False)
  )
)
2023-04-21 23:30:33 | INFO | fairseq_cli.train | task: LanguageModelingPromptTask
2023-04-21 23:30:33 | INFO | fairseq_cli.train | model: TransformerLanguageModelPrompt
2023-04-21 23:30:33 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2023-04-21 23:30:33 | INFO | fairseq_cli.train | num. shared model params: 346,772,480 (num. trained: 346,772,480)
2023-04-21 23:30:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-04-21 23:30:33 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../../data/BC5CDR/relis-bin/valid.x-y.x
2023-04-21 23:30:33 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../../data/BC5CDR/relis-bin/valid.x-y.y
2023-04-21 23:30:34 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-04-21 23:30:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-04-21 23:30:34 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-04-21 23:30:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-04-21 23:30:34 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-04-21 23:30:34 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = None
2023-04-21 23:30:34 | INFO | fairseq.trainer | Preparing to load checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint_last.pt
2023-04-21 23:30:36 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2023-04-21 23:30:37 | INFO | fairseq.trainer | Loaded checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint_last.pt (epoch 2 @ 6 updates)
2023-04-21 23:30:37 | INFO | fairseq.trainer | loading train data for epoch 2
2023-04-21 23:30:37 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../../data/BC5CDR/relis-bin/train.x-y.x
2023-04-21 23:30:37 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../../data/BC5CDR/relis-bin/train.x-y.y
2023-04-21 23:30:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:30:37 | INFO | fairseq.trainer | begin training epoch 2
2023-04-21 23:30:37 | INFO | fairseq_cli.train | Start iterating over samples
/home/x_jackr/.conda/envs/biogpt/lib/python3.10/site-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2023-04-21 23:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:31:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.499 | ppl 22.6 | wps 16897.6 | wpb 857.5 | bsz 3 | num_updates 12 | best_loss 4.499
2023-04-21 23:31:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 12 updates
2023-04-21 23:31:12 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint2.pt
2023-04-21 23:31:18 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint2.pt
2023-04-21 23:31:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint2.pt (epoch 2 @ 12 updates, score 4.499) (writing took 25.017922903993167 seconds)
2023-04-21 23:31:37 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-04-21 23:31:37 | INFO | train | epoch 002 | loss 4.672 | ppl 25.49 | wps 2151.2 | ups 0.09 | wpb 23829.8 | bsz 83.3 | num_updates 12 | lr 1.288e-06 | gnorm 3.644 | train_wall 26 | gb_free 31.1 | wall 63
2023-04-21 23:31:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:31:37 | INFO | fairseq.trainer | begin training epoch 3
2023-04-21 23:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:32:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:32:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.348 | ppl 20.37 | wps 16959.8 | wpb 857.5 | bsz 3 | num_updates 18 | best_loss 4.348
2023-04-21 23:32:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 18 updates
2023-04-21 23:32:10 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint3.pt
2023-04-21 23:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint3.pt
2023-04-21 23:32:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint3.pt (epoch 3 @ 18 updates, score 4.348) (writing took 25.799670380016323 seconds)
2023-04-21 23:32:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-04-21 23:32:36 | INFO | train | epoch 003 | loss 4.548 | ppl 23.4 | wps 2432.7 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 18 | lr 1.882e-06 | gnorm 3.292 | train_wall 24 | gb_free 31.1 | wall 122
2023-04-21 23:32:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:32:36 | INFO | fairseq.trainer | begin training epoch 4
2023-04-21 23:32:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:33:09 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.167 | ppl 17.97 | wps 16946.9 | wpb 857.5 | bsz 3 | num_updates 24 | best_loss 4.167
2023-04-21 23:33:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 24 updates
2023-04-21 23:33:09 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint4.pt
2023-04-21 23:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint4.pt
2023-04-21 23:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint4.pt (epoch 4 @ 24 updates, score 4.167) (writing took 25.9725690150226 seconds)
2023-04-21 23:33:35 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-04-21 23:33:35 | INFO | train | epoch 004 | loss 4.389 | ppl 20.96 | wps 2423.9 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 24 | lr 2.476e-06 | gnorm 2.94 | train_wall 24 | gb_free 30.6 | wall 180
2023-04-21 23:33:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:33:35 | INFO | fairseq.trainer | begin training epoch 5
2023-04-21 23:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:34:08 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.941 | ppl 15.36 | wps 16970.7 | wpb 857.5 | bsz 3 | num_updates 30 | best_loss 3.941
2023-04-21 23:34:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 30 updates
2023-04-21 23:34:08 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint5.pt
2023-04-21 23:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint5.pt
2023-04-21 23:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint5.pt (epoch 5 @ 30 updates, score 3.941) (writing took 27.36091716500232 seconds)
2023-04-21 23:34:35 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-04-21 23:34:35 | INFO | train | epoch 005 | loss 4.205 | ppl 18.44 | wps 2369 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 30 | lr 3.07e-06 | gnorm 2.909 | train_wall 24 | gb_free 31.1 | wall 241
2023-04-21 23:34:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:34:35 | INFO | fairseq.trainer | begin training epoch 6
2023-04-21 23:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:35:08 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.692 | ppl 12.93 | wps 16960.9 | wpb 857.5 | bsz 3 | num_updates 36 | best_loss 3.692
2023-04-21 23:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 36 updates
2023-04-21 23:35:08 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint6.pt
2023-04-21 23:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint6.pt
2023-04-21 23:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint6.pt (epoch 6 @ 36 updates, score 3.692) (writing took 25.932888069015462 seconds)
2023-04-21 23:35:35 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-04-21 23:35:35 | INFO | train | epoch 006 | loss 3.974 | ppl 15.72 | wps 2382.1 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 36 | lr 3.664e-06 | gnorm 2.711 | train_wall 24 | gb_free 30.8 | wall 301
2023-04-21 23:35:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:35:35 | INFO | fairseq.trainer | begin training epoch 7
2023-04-21 23:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:36:10 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.505 | ppl 11.35 | wps 13064.3 | wpb 857.5 | bsz 3 | num_updates 42 | best_loss 3.505
2023-04-21 23:36:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 42 updates
2023-04-21 23:36:10 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint7.pt
2023-04-21 23:36:19 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint7.pt
2023-04-21 23:36:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint7.pt (epoch 7 @ 42 updates, score 3.505) (writing took 29.118094788020244 seconds)
2023-04-21 23:36:41 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-04-21 23:36:41 | INFO | train | epoch 007 | loss 3.758 | ppl 13.53 | wps 2175 | ups 0.09 | wpb 23829.8 | bsz 83.3 | num_updates 42 | lr 4.258e-06 | gnorm 2.018 | train_wall 24 | gb_free 31.1 | wall 367
2023-04-21 23:36:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:36:41 | INFO | fairseq.trainer | begin training epoch 8
2023-04-21 23:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:37:14 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.318 | ppl 9.97 | wps 16985.2 | wpb 857.5 | bsz 3 | num_updates 48 | best_loss 3.318
2023-04-21 23:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 48 updates
2023-04-21 23:37:14 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint8.pt
2023-04-21 23:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint8.pt
2023-04-21 23:37:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint8.pt (epoch 8 @ 48 updates, score 3.318) (writing took 29.219515585020417 seconds)
2023-04-21 23:37:44 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-04-21 23:37:44 | INFO | train | epoch 008 | loss 3.584 | ppl 11.99 | wps 2247.6 | ups 0.09 | wpb 23829.8 | bsz 83.3 | num_updates 48 | lr 4.852e-06 | gnorm 2.013 | train_wall 24 | gb_free 31.4 | wall 430
2023-04-21 23:37:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:37:44 | INFO | fairseq.trainer | begin training epoch 9
2023-04-21 23:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:38:17 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.127 | ppl 8.74 | wps 16972.7 | wpb 857.5 | bsz 3 | num_updates 54 | best_loss 3.127
2023-04-21 23:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 54 updates
2023-04-21 23:38:17 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint9.pt
2023-04-21 23:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint9.pt
2023-04-21 23:38:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint9.pt (epoch 9 @ 54 updates, score 3.127) (writing took 27.523155103001045 seconds)
2023-04-21 23:38:46 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-04-21 23:38:46 | INFO | train | epoch 009 | loss 3.403 | ppl 10.58 | wps 2325.4 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 54 | lr 5.446e-06 | gnorm 1.688 | train_wall 24 | gb_free 31.5 | wall 492
2023-04-21 23:38:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:38:46 | INFO | fairseq.trainer | begin training epoch 10
2023-04-21 23:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:39:19 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.032 | ppl 8.18 | wps 16946.9 | wpb 857.5 | bsz 3 | num_updates 60 | best_loss 3.032
2023-04-21 23:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 60 updates
2023-04-21 23:39:19 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint10.pt
2023-04-21 23:39:25 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint10.pt
2023-04-21 23:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint10.pt (epoch 10 @ 60 updates, score 3.032) (writing took 26.925620149995666 seconds)
2023-04-21 23:39:46 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-04-21 23:39:46 | INFO | train | epoch 010 | loss 3.209 | ppl 9.25 | wps 2354.4 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 60 | lr 6.04e-06 | gnorm 1.393 | train_wall 24 | gb_free 31.1 | wall 552
2023-04-21 23:39:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:39:46 | INFO | fairseq.trainer | begin training epoch 11
2023-04-21 23:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:40:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 2.98 | ppl 7.89 | wps 16963.9 | wpb 857.5 | bsz 3 | num_updates 66 | best_loss 2.98
2023-04-21 23:40:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 66 updates
2023-04-21 23:40:19 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint11.pt
2023-04-21 23:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint11.pt
2023-04-21 23:40:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint11.pt (epoch 11 @ 66 updates, score 2.98) (writing took 26.94871119799791 seconds)
2023-04-21 23:40:47 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-04-21 23:40:47 | INFO | train | epoch 011 | loss 3.089 | ppl 8.51 | wps 2356.5 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 66 | lr 6.634e-06 | gnorm 1.137 | train_wall 24 | gb_free 31.2 | wall 613
2023-04-21 23:40:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:40:47 | INFO | fairseq.trainer | begin training epoch 12
2023-04-21 23:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:41:20 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 2.939 | ppl 7.67 | wps 16956.3 | wpb 857.5 | bsz 3 | num_updates 72 | best_loss 2.939
2023-04-21 23:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 72 updates
2023-04-21 23:41:20 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint12.pt
2023-04-21 23:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint12.pt
2023-04-21 23:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint12.pt (epoch 12 @ 72 updates, score 2.939) (writing took 25.730035915999906 seconds)
2023-04-21 23:41:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-04-21 23:41:47 | INFO | train | epoch 012 | loss 2.998 | ppl 7.99 | wps 2389.4 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 72 | lr 7.228e-06 | gnorm 0.989 | train_wall 24 | gb_free 31.1 | wall 673
2023-04-21 23:41:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:41:47 | INFO | fairseq.trainer | begin training epoch 13
2023-04-21 23:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:42:20 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 2.903 | ppl 7.48 | wps 16961.2 | wpb 857.5 | bsz 3 | num_updates 78 | best_loss 2.903
2023-04-21 23:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 78 updates
2023-04-21 23:42:20 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint13.pt
2023-04-21 23:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint13.pt
2023-04-21 23:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint13.pt (epoch 13 @ 78 updates, score 2.903) (writing took 26.509010078007123 seconds)
2023-04-21 23:42:48 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-04-21 23:42:48 | INFO | train | epoch 013 | loss 2.935 | ppl 7.65 | wps 2361.3 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 78 | lr 7.822e-06 | gnorm 0.921 | train_wall 24 | gb_free 31.1 | wall 734
2023-04-21 23:42:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:42:48 | INFO | fairseq.trainer | begin training epoch 14
2023-04-21 23:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:43:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:43:21 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 2.874 | ppl 7.33 | wps 16981 | wpb 857.5 | bsz 3 | num_updates 84 | best_loss 2.874
2023-04-21 23:43:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 84 updates
2023-04-21 23:43:21 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint14.pt
2023-04-21 23:43:27 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint14.pt
2023-04-21 23:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint14.pt (epoch 14 @ 84 updates, score 2.874) (writing took 27.541256808006437 seconds)
2023-04-21 23:43:49 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-04-21 23:43:49 | INFO | train | epoch 014 | loss 2.869 | ppl 7.31 | wps 2320.7 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 84 | lr 8.416e-06 | gnorm 0.907 | train_wall 24 | gb_free 31 | wall 795
2023-04-21 23:43:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:43:49 | INFO | fairseq.trainer | begin training epoch 15
2023-04-21 23:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:44:22 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 2.853 | ppl 7.22 | wps 16971.4 | wpb 857.5 | bsz 3 | num_updates 90 | best_loss 2.853
2023-04-21 23:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 90 updates
2023-04-21 23:44:22 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint15.pt
2023-04-21 23:44:29 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint15.pt
2023-04-21 23:44:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint15.pt (epoch 15 @ 90 updates, score 2.853) (writing took 27.280196678009816 seconds)
2023-04-21 23:44:50 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-04-21 23:44:50 | INFO | train | epoch 015 | loss 2.809 | ppl 7.01 | wps 2333 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 90 | lr 9.01e-06 | gnorm 0.843 | train_wall 24 | gb_free 31.4 | wall 856
2023-04-21 23:44:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:44:50 | INFO | fairseq.trainer | begin training epoch 16
2023-04-21 23:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:45:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 2.837 | ppl 7.14 | wps 16949 | wpb 857.5 | bsz 3 | num_updates 96 | best_loss 2.837
2023-04-21 23:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 96 updates
2023-04-21 23:45:23 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint16.pt
2023-04-21 23:45:30 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint16.pt
2023-04-21 23:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint16.pt (epoch 16 @ 96 updates, score 2.837) (writing took 26.972474765003426 seconds)
2023-04-21 23:45:51 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-04-21 23:45:51 | INFO | train | epoch 016 | loss 2.754 | ppl 6.75 | wps 2342.2 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 96 | lr 9.604e-06 | gnorm 0.822 | train_wall 24 | gb_free 30.7 | wall 917
2023-04-21 23:45:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:45:51 | INFO | fairseq.trainer | begin training epoch 17
2023-04-21 23:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:46:10 | INFO | train_inner | epoch 017:      4 / 6 loss=3.506, ppl=11.36, wps=2400.1, ups=0.1, wpb=23959.3, bsz=83.8, num_updates=100, lr=1e-05, gnorm=1.832, train_wall=385, gb_free=31, wall=936
2023-04-21 23:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:46:25 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 2.826 | ppl 7.09 | wps 16940.7 | wpb 857.5 | bsz 3 | num_updates 102 | best_loss 2.826
2023-04-21 23:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 102 updates
2023-04-21 23:46:25 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint17.pt
2023-04-21 23:46:31 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint17.pt
2023-04-21 23:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint17.pt (epoch 17 @ 102 updates, score 2.826) (writing took 26.503924645017833 seconds)
2023-04-21 23:46:52 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-04-21 23:46:52 | INFO | train | epoch 017 | loss 2.705 | ppl 6.52 | wps 2359.8 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 102 | lr 9.90148e-06 | gnorm 0.799 | train_wall 24 | gb_free 31.4 | wall 978
2023-04-21 23:46:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:46:52 | INFO | fairseq.trainer | begin training epoch 18
2023-04-21 23:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:47:25 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 2.819 | ppl 7.06 | wps 16965.6 | wpb 857.5 | bsz 3 | num_updates 108 | best_loss 2.819
2023-04-21 23:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 108 updates
2023-04-21 23:47:25 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint18.pt
2023-04-21 23:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint18.pt
2023-04-21 23:47:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint18.pt (epoch 18 @ 108 updates, score 2.819) (writing took 26.894855126010953 seconds)
2023-04-21 23:47:53 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-04-21 23:47:53 | INFO | train | epoch 018 | loss 2.654 | ppl 6.29 | wps 2347.2 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 108 | lr 9.6225e-06 | gnorm 0.79 | train_wall 24 | gb_free 31.3 | wall 1039
2023-04-21 23:47:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:47:53 | INFO | fairseq.trainer | begin training epoch 19
2023-04-21 23:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:48:26 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 2.814 | ppl 7.03 | wps 16891 | wpb 857.5 | bsz 3 | num_updates 114 | best_loss 2.814
2023-04-21 23:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 114 updates
2023-04-21 23:48:26 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint19.pt
2023-04-21 23:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint19.pt
2023-04-21 23:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint19.pt (epoch 19 @ 114 updates, score 2.814) (writing took 26.7492156639928 seconds)
2023-04-21 23:48:54 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-04-21 23:48:54 | INFO | train | epoch 019 | loss 2.611 | ppl 6.11 | wps 2349 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 114 | lr 9.36586e-06 | gnorm 0.79 | train_wall 24 | gb_free 31.1 | wall 1100
2023-04-21 23:48:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:48:54 | INFO | fairseq.trainer | begin training epoch 20
2023-04-21 23:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:49:27 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 2.811 | ppl 7.02 | wps 16948.3 | wpb 857.5 | bsz 3 | num_updates 120 | best_loss 2.811
2023-04-21 23:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 120 updates
2023-04-21 23:49:27 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint20.pt
2023-04-21 23:49:33 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint20.pt
2023-04-21 23:49:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint20.pt (epoch 20 @ 120 updates, score 2.811) (writing took 26.162256048992276 seconds)
2023-04-21 23:49:54 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-04-21 23:49:54 | INFO | train | epoch 020 | loss 2.564 | ppl 5.91 | wps 2383.6 | ups 0.1 | wpb 23829.8 | bsz 83.3 | num_updates 120 | lr 9.12871e-06 | gnorm 0.793 | train_wall 24 | gb_free 31.4 | wall 1160
2023-04-21 23:49:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:49:54 | INFO | fairseq.trainer | begin training epoch 21
2023-04-21 23:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:50:27 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 2.812 | ppl 7.02 | wps 16958.4 | wpb 857.5 | bsz 3 | num_updates 126 | best_loss 2.811
2023-04-21 23:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 126 updates
2023-04-21 23:50:27 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint21.pt
2023-04-21 23:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint21.pt
2023-04-21 23:50:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint21.pt (epoch 21 @ 126 updates, score 2.812) (writing took 16.80898183499812 seconds)
2023-04-21 23:50:45 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-04-21 23:50:45 | INFO | train | epoch 021 | loss 2.525 | ppl 5.76 | wps 2808.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 126 | lr 8.90871e-06 | gnorm 0.804 | train_wall 24 | gb_free 31.1 | wall 1211
2023-04-21 23:50:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:50:45 | INFO | fairseq.trainer | begin training epoch 22
2023-04-21 23:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:51:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:51:18 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 2.812 | ppl 7.02 | wps 16964 | wpb 857.5 | bsz 3 | num_updates 132 | best_loss 2.811
2023-04-21 23:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 132 updates
2023-04-21 23:51:18 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint22.pt
2023-04-21 23:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint22.pt
2023-04-21 23:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint22.pt (epoch 22 @ 132 updates, score 2.812) (writing took 17.36829023298924 seconds)
2023-04-21 23:51:36 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-04-21 23:51:36 | INFO | train | epoch 022 | loss 2.486 | ppl 5.6 | wps 2775.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 132 | lr 8.70388e-06 | gnorm 0.796 | train_wall 24 | gb_free 31.5 | wall 1262
2023-04-21 23:51:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:51:36 | INFO | fairseq.trainer | begin training epoch 23
2023-04-21 23:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:52:09 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 2.812 | ppl 7.02 | wps 16971 | wpb 857.5 | bsz 3 | num_updates 138 | best_loss 2.811
2023-04-21 23:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 138 updates
2023-04-21 23:52:09 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint23.pt
2023-04-21 23:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint23.pt
2023-04-21 23:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint23.pt (epoch 23 @ 138 updates, score 2.812) (writing took 16.939415428991197 seconds)
2023-04-21 23:52:27 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-04-21 23:52:27 | INFO | train | epoch 023 | loss 2.448 | ppl 5.46 | wps 2805.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 138 | lr 8.51257e-06 | gnorm 0.794 | train_wall 24 | gb_free 31.3 | wall 1313
2023-04-21 23:52:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:52:27 | INFO | fairseq.trainer | begin training epoch 24
2023-04-21 23:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:53:00 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.816 | ppl 7.04 | wps 16977 | wpb 857.5 | bsz 3 | num_updates 144 | best_loss 2.811
2023-04-21 23:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 144 updates
2023-04-21 23:53:00 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint24.pt
2023-04-21 23:53:07 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint24.pt
2023-04-21 23:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint24.pt (epoch 24 @ 144 updates, score 2.816) (writing took 16.227523612993537 seconds)
2023-04-21 23:53:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-04-21 23:53:17 | INFO | train | epoch 024 | loss 2.414 | ppl 5.33 | wps 2847.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 144 | lr 8.33333e-06 | gnorm 0.793 | train_wall 24 | gb_free 30.7 | wall 1363
2023-04-21 23:53:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:53:17 | INFO | fairseq.trainer | begin training epoch 25
2023-04-21 23:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:53:50 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.82 | ppl 7.06 | wps 16977.4 | wpb 857.5 | bsz 3 | num_updates 150 | best_loss 2.811
2023-04-21 23:53:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 150 updates
2023-04-21 23:53:50 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint25.pt
2023-04-21 23:53:57 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint25.pt
2023-04-21 23:54:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint25.pt (epoch 25 @ 150 updates, score 2.82) (writing took 16.575928396981908 seconds)
2023-04-21 23:54:08 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-04-21 23:54:08 | INFO | train | epoch 025 | loss 2.376 | ppl 5.19 | wps 2822.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 150 | lr 8.16497e-06 | gnorm 0.792 | train_wall 24 | gb_free 31.2 | wall 1414
2023-04-21 23:54:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:54:08 | INFO | fairseq.trainer | begin training epoch 26
2023-04-21 23:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:54:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:54:41 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.823 | ppl 7.08 | wps 17032.5 | wpb 857.5 | bsz 3 | num_updates 156 | best_loss 2.811
2023-04-21 23:54:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 156 updates
2023-04-21 23:54:41 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint26.pt
2023-04-21 23:54:47 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint26.pt
2023-04-21 23:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint26.pt (epoch 26 @ 156 updates, score 2.823) (writing took 16.300461567996535 seconds)
2023-04-21 23:54:58 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-04-21 23:54:58 | INFO | train | epoch 026 | loss 2.343 | ppl 5.07 | wps 2855.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 156 | lr 8.00641e-06 | gnorm 0.785 | train_wall 24 | gb_free 30.9 | wall 1464
2023-04-21 23:54:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:54:58 | INFO | fairseq.trainer | begin training epoch 27
2023-04-21 23:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:55:31 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.826 | ppl 7.09 | wps 16941.6 | wpb 857.5 | bsz 3 | num_updates 162 | best_loss 2.811
2023-04-21 23:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 162 updates
2023-04-21 23:55:31 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint27.pt
2023-04-21 23:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint27.pt
2023-04-21 23:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint27.pt (epoch 27 @ 162 updates, score 2.826) (writing took 16.603595280990703 seconds)
2023-04-21 23:55:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-04-21 23:55:49 | INFO | train | epoch 027 | loss 2.315 | ppl 4.98 | wps 2827 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 162 | lr 7.85674e-06 | gnorm 0.784 | train_wall 24 | gb_free 31 | wall 1515
2023-04-21 23:55:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:55:49 | INFO | fairseq.trainer | begin training epoch 28
2023-04-21 23:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:56:22 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.834 | ppl 7.13 | wps 16952.8 | wpb 857.5 | bsz 3 | num_updates 168 | best_loss 2.811
2023-04-21 23:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 168 updates
2023-04-21 23:56:22 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint28.pt
2023-04-21 23:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint28.pt
2023-04-21 23:56:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint28.pt (epoch 28 @ 168 updates, score 2.834) (writing took 16.63628661201801 seconds)
2023-04-21 23:56:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-04-21 23:56:39 | INFO | train | epoch 028 | loss 2.277 | ppl 4.85 | wps 2821.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 168 | lr 7.71517e-06 | gnorm 0.806 | train_wall 24 | gb_free 31.5 | wall 1565
2023-04-21 23:56:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:56:39 | INFO | fairseq.trainer | begin training epoch 29
2023-04-21 23:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:57:12 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.84 | ppl 7.16 | wps 16964 | wpb 857.5 | bsz 3 | num_updates 174 | best_loss 2.811
2023-04-21 23:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 174 updates
2023-04-21 23:57:12 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint29.pt
2023-04-21 23:57:19 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint29.pt
2023-04-21 23:57:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint29.pt (epoch 29 @ 174 updates, score 2.84) (writing took 17.146466403995873 seconds)
2023-04-21 23:57:31 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-04-21 23:57:31 | INFO | train | epoch 029 | loss 2.244 | ppl 4.74 | wps 2787.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 174 | lr 7.58098e-06 | gnorm 0.812 | train_wall 24 | gb_free 31 | wall 1617
2023-04-21 23:57:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:57:31 | INFO | fairseq.trainer | begin training epoch 30
2023-04-21 23:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:58:04 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.844 | ppl 7.18 | wps 16950.8 | wpb 857.5 | bsz 3 | num_updates 180 | best_loss 2.811
2023-04-21 23:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 180 updates
2023-04-21 23:58:04 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint30.pt
2023-04-21 23:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint30.pt
2023-04-21 23:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint30.pt (epoch 30 @ 180 updates, score 2.844) (writing took 16.892435996007407 seconds)
2023-04-21 23:58:22 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-04-21 23:58:22 | INFO | train | epoch 030 | loss 2.214 | ppl 4.64 | wps 2810.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 180 | lr 7.45356e-06 | gnorm 0.804 | train_wall 24 | gb_free 31.4 | wall 1668
2023-04-21 23:58:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:58:22 | INFO | fairseq.trainer | begin training epoch 31
2023-04-21 23:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:58:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:58:55 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.849 | ppl 7.21 | wps 16957.6 | wpb 857.5 | bsz 3 | num_updates 186 | best_loss 2.811
2023-04-21 23:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 186 updates
2023-04-21 23:58:55 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint31.pt
2023-04-21 23:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint31.pt
2023-04-21 23:59:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint31.pt (epoch 31 @ 186 updates, score 2.849) (writing took 16.887035413004924 seconds)
2023-04-21 23:59:13 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-04-21 23:59:13 | INFO | train | epoch 031 | loss 2.186 | ppl 4.55 | wps 2804.4 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 186 | lr 7.33236e-06 | gnorm 0.809 | train_wall 24 | gb_free 31.2 | wall 1719
2023-04-21 23:59:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-21 23:59:13 | INFO | fairseq.trainer | begin training epoch 32
2023-04-21 23:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-21 23:59:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-21 23:59:46 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.857 | ppl 7.24 | wps 16888.3 | wpb 857.5 | bsz 3 | num_updates 192 | best_loss 2.811
2023-04-21 23:59:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 192 updates
2023-04-21 23:59:46 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint32.pt
2023-04-21 23:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint32.pt
2023-04-22 00:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint32.pt (epoch 32 @ 192 updates, score 2.857) (writing took 17.133416068012593 seconds)
2023-04-22 00:00:04 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-04-22 00:00:04 | INFO | train | epoch 032 | loss 2.153 | ppl 4.45 | wps 2804.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 192 | lr 7.21688e-06 | gnorm 0.802 | train_wall 24 | gb_free 30.8 | wall 1770
2023-04-22 00:00:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:00:04 | INFO | fairseq.trainer | begin training epoch 33
2023-04-22 00:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:00:37 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.862 | ppl 7.27 | wps 16959.8 | wpb 857.5 | bsz 3 | num_updates 198 | best_loss 2.811
2023-04-22 00:00:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 198 updates
2023-04-22 00:00:37 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint33.pt
2023-04-22 00:00:43 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint33.pt
2023-04-22 00:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint33.pt (epoch 33 @ 198 updates, score 2.862) (writing took 16.605365380004514 seconds)
2023-04-22 00:00:54 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-04-22 00:00:54 | INFO | train | epoch 033 | loss 2.126 | ppl 4.37 | wps 2826.3 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 198 | lr 7.10669e-06 | gnorm 0.812 | train_wall 24 | gb_free 31 | wall 1820
2023-04-22 00:00:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:00:54 | INFO | fairseq.trainer | begin training epoch 34
2023-04-22 00:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:01:04 | INFO | train_inner | epoch 034:      2 / 6 loss=2.37, ppl=5.17, wps=2661.1, ups=0.11, wpb=23778.1, bsz=83.1, num_updates=200, lr=7.07107e-06, gnorm=0.8, train_wall=404, gb_free=30.6, wall=1830
2023-04-22 00:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:01:27 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.87 | ppl 7.31 | wps 16939.5 | wpb 857.5 | bsz 3 | num_updates 204 | best_loss 2.811
2023-04-22 00:01:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 204 updates
2023-04-22 00:01:27 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint34.pt
2023-04-22 00:01:34 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint34.pt
2023-04-22 00:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint34.pt (epoch 34 @ 204 updates, score 2.87) (writing took 16.8861574199982 seconds)
2023-04-22 00:01:45 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-04-22 00:01:45 | INFO | train | epoch 034 | loss 2.096 | ppl 4.28 | wps 2807.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 204 | lr 7.0014e-06 | gnorm 0.802 | train_wall 24 | gb_free 31 | wall 1871
2023-04-22 00:01:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:01:45 | INFO | fairseq.trainer | begin training epoch 35
2023-04-22 00:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:02:18 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.877 | ppl 7.35 | wps 16948 | wpb 857.5 | bsz 3 | num_updates 210 | best_loss 2.811
2023-04-22 00:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 210 updates
2023-04-22 00:02:18 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint35.pt
2023-04-22 00:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint35.pt
2023-04-22 00:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint35.pt (epoch 35 @ 210 updates, score 2.877) (writing took 16.85354926297441 seconds)
2023-04-22 00:02:36 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-04-22 00:02:36 | INFO | train | epoch 035 | loss 2.07 | ppl 4.2 | wps 2799.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 210 | lr 6.90066e-06 | gnorm 0.83 | train_wall 24 | gb_free 31.1 | wall 1922
2023-04-22 00:02:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:02:36 | INFO | fairseq.trainer | begin training epoch 36
2023-04-22 00:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:03:09 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.885 | ppl 7.39 | wps 16953.4 | wpb 857.5 | bsz 3 | num_updates 216 | best_loss 2.811
2023-04-22 00:03:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 216 updates
2023-04-22 00:03:09 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint36.pt
2023-04-22 00:03:16 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint36.pt
2023-04-22 00:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint36.pt (epoch 36 @ 216 updates, score 2.885) (writing took 18.49242518999381 seconds)
2023-04-22 00:03:29 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-04-22 00:03:29 | INFO | train | epoch 036 | loss 2.045 | ppl 4.13 | wps 2696.2 | ups 0.11 | wpb 23829.8 | bsz 83.3 | num_updates 216 | lr 6.80414e-06 | gnorm 0.829 | train_wall 24 | gb_free 30.7 | wall 1975
2023-04-22 00:03:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:03:29 | INFO | fairseq.trainer | begin training epoch 37
2023-04-22 00:03:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:04:02 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 2.893 | ppl 7.43 | wps 16994 | wpb 857.5 | bsz 3 | num_updates 222 | best_loss 2.811
2023-04-22 00:04:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 222 updates
2023-04-22 00:04:02 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint37.pt
2023-04-22 00:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint37.pt
2023-04-22 00:04:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint37.pt (epoch 37 @ 222 updates, score 2.893) (writing took 16.873710340994876 seconds)
2023-04-22 00:04:20 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-04-22 00:04:20 | INFO | train | epoch 037 | loss 2.017 | ppl 4.05 | wps 2811.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 222 | lr 6.71156e-06 | gnorm 0.831 | train_wall 24 | gb_free 31.2 | wall 2026
2023-04-22 00:04:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:04:20 | INFO | fairseq.trainer | begin training epoch 38
2023-04-22 00:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:04:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 2.901 | ppl 7.47 | wps 16950.7 | wpb 857.5 | bsz 3 | num_updates 228 | best_loss 2.811
2023-04-22 00:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 228 updates
2023-04-22 00:04:53 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint38.pt
2023-04-22 00:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint38.pt
2023-04-22 00:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint38.pt (epoch 38 @ 228 updates, score 2.901) (writing took 16.77202756999759 seconds)
2023-04-22 00:05:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-04-22 00:05:11 | INFO | train | epoch 038 | loss 1.992 | ppl 3.98 | wps 2812.4 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 228 | lr 6.62266e-06 | gnorm 0.827 | train_wall 24 | gb_free 31.1 | wall 2077
2023-04-22 00:05:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:05:11 | INFO | fairseq.trainer | begin training epoch 39
2023-04-22 00:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:05:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:05:44 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 2.908 | ppl 7.51 | wps 16960.5 | wpb 857.5 | bsz 3 | num_updates 234 | best_loss 2.811
2023-04-22 00:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 234 updates
2023-04-22 00:05:44 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint39.pt
2023-04-22 00:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint39.pt
2023-04-22 00:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint39.pt (epoch 39 @ 234 updates, score 2.908) (writing took 16.39679355500266 seconds)
2023-04-22 00:06:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-04-22 00:06:01 | INFO | train | epoch 039 | loss 1.966 | ppl 3.91 | wps 2839.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 234 | lr 6.5372e-06 | gnorm 0.831 | train_wall 24 | gb_free 31.4 | wall 2127
2023-04-22 00:06:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:06:01 | INFO | fairseq.trainer | begin training epoch 40
2023-04-22 00:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:06:34 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 2.915 | ppl 7.54 | wps 16865.6 | wpb 857.5 | bsz 3 | num_updates 240 | best_loss 2.811
2023-04-22 00:06:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 240 updates
2023-04-22 00:06:34 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint40.pt
2023-04-22 00:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint40.pt
2023-04-22 00:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint40.pt (epoch 40 @ 240 updates, score 2.915) (writing took 16.64620210501016 seconds)
2023-04-22 00:06:52 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-04-22 00:06:52 | INFO | train | epoch 040 | loss 1.94 | ppl 3.84 | wps 2820.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 240 | lr 6.45497e-06 | gnorm 0.832 | train_wall 24 | gb_free 31 | wall 2178
2023-04-22 00:06:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:06:52 | INFO | fairseq.trainer | begin training epoch 41
2023-04-22 00:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:07:25 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 2.922 | ppl 7.58 | wps 16906.6 | wpb 857.5 | bsz 3 | num_updates 246 | best_loss 2.811
2023-04-22 00:07:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 246 updates
2023-04-22 00:07:25 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint41.pt
2023-04-22 00:07:32 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint41.pt
2023-04-22 00:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint41.pt (epoch 41 @ 246 updates, score 2.922) (writing took 17.31016320901108 seconds)
2023-04-22 00:07:43 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-04-22 00:07:43 | INFO | train | epoch 041 | loss 1.916 | ppl 3.77 | wps 2786.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 246 | lr 6.37577e-06 | gnorm 0.841 | train_wall 24 | gb_free 31.4 | wall 2229
2023-04-22 00:07:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:07:43 | INFO | fairseq.trainer | begin training epoch 42
2023-04-22 00:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:08:16 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 2.93 | ppl 7.62 | wps 16981.6 | wpb 857.5 | bsz 3 | num_updates 252 | best_loss 2.811
2023-04-22 00:08:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 252 updates
2023-04-22 00:08:16 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint42.pt
2023-04-22 00:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint42.pt
2023-04-22 00:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint42.pt (epoch 42 @ 252 updates, score 2.93) (writing took 16.68082689997391 seconds)
2023-04-22 00:08:34 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-04-22 00:08:34 | INFO | train | epoch 042 | loss 1.893 | ppl 3.71 | wps 2824.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 252 | lr 6.29941e-06 | gnorm 0.838 | train_wall 24 | gb_free 31.5 | wall 2280
2023-04-22 00:08:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:08:34 | INFO | fairseq.trainer | begin training epoch 43
2023-04-22 00:08:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:09:07 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 2.938 | ppl 7.66 | wps 16950.9 | wpb 857.5 | bsz 3 | num_updates 258 | best_loss 2.811
2023-04-22 00:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 258 updates
2023-04-22 00:09:07 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint43.pt
2023-04-22 00:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint43.pt
2023-04-22 00:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint43.pt (epoch 43 @ 258 updates, score 2.938) (writing took 16.87902603400289 seconds)
2023-04-22 00:09:25 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-04-22 00:09:25 | INFO | train | epoch 043 | loss 1.866 | ppl 3.65 | wps 2810.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 258 | lr 6.22573e-06 | gnorm 0.843 | train_wall 24 | gb_free 31.3 | wall 2331
2023-04-22 00:09:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:09:25 | INFO | fairseq.trainer | begin training epoch 44
2023-04-22 00:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:09:58 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 2.947 | ppl 7.71 | wps 16971.7 | wpb 857.5 | bsz 3 | num_updates 264 | best_loss 2.811
2023-04-22 00:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 264 updates
2023-04-22 00:09:58 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint44.pt
2023-04-22 00:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint44.pt
2023-04-22 00:10:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint44.pt (epoch 44 @ 264 updates, score 2.947) (writing took 16.78618045602343 seconds)
2023-04-22 00:10:15 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-04-22 00:10:15 | INFO | train | epoch 044 | loss 1.841 | ppl 3.58 | wps 2825.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 264 | lr 6.15457e-06 | gnorm 0.858 | train_wall 24 | gb_free 31.3 | wall 2381
2023-04-22 00:10:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:10:15 | INFO | fairseq.trainer | begin training epoch 45
2023-04-22 00:10:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:10:48 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 2.953 | ppl 7.74 | wps 16933.1 | wpb 857.5 | bsz 3 | num_updates 270 | best_loss 2.811
2023-04-22 00:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 270 updates
2023-04-22 00:10:48 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint45.pt
2023-04-22 00:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint45.pt
2023-04-22 00:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint45.pt (epoch 45 @ 270 updates, score 2.953) (writing took 16.17361097302637 seconds)
2023-04-22 00:11:05 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-04-22 00:11:05 | INFO | train | epoch 045 | loss 1.822 | ppl 3.53 | wps 2853.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 270 | lr 6.08581e-06 | gnorm 0.852 | train_wall 24 | gb_free 31.5 | wall 2431
2023-04-22 00:11:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:11:05 | INFO | fairseq.trainer | begin training epoch 46
2023-04-22 00:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:11:38 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 2.957 | ppl 7.76 | wps 16947.4 | wpb 857.5 | bsz 3 | num_updates 276 | best_loss 2.811
2023-04-22 00:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 276 updates
2023-04-22 00:11:38 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint46.pt
2023-04-22 00:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint46.pt
2023-04-22 00:11:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint46.pt (epoch 46 @ 276 updates, score 2.957) (writing took 16.51967504201457 seconds)
2023-04-22 00:11:56 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-04-22 00:11:56 | INFO | train | epoch 046 | loss 1.8 | ppl 3.48 | wps 2825.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 276 | lr 6.01929e-06 | gnorm 0.84 | train_wall 24 | gb_free 31.1 | wall 2482
2023-04-22 00:11:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:11:56 | INFO | fairseq.trainer | begin training epoch 47
2023-04-22 00:11:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:12:29 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 2.964 | ppl 7.81 | wps 16962.1 | wpb 857.5 | bsz 3 | num_updates 282 | best_loss 2.811
2023-04-22 00:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 282 updates
2023-04-22 00:12:29 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint47.pt
2023-04-22 00:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint47.pt
2023-04-22 00:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint47.pt (epoch 47 @ 282 updates, score 2.964) (writing took 16.762410333001753 seconds)
2023-04-22 00:12:47 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-04-22 00:12:47 | INFO | train | epoch 047 | loss 1.781 | ppl 3.44 | wps 2791.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 282 | lr 5.95491e-06 | gnorm 0.849 | train_wall 24 | gb_free 31.1 | wall 2533
2023-04-22 00:12:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:12:47 | INFO | fairseq.trainer | begin training epoch 48
2023-04-22 00:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:13:20 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 2.972 | ppl 7.85 | wps 16958.3 | wpb 857.5 | bsz 3 | num_updates 288 | best_loss 2.811
2023-04-22 00:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 288 updates
2023-04-22 00:13:20 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint48.pt
2023-04-22 00:13:27 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint48.pt
2023-04-22 00:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint48.pt (epoch 48 @ 288 updates, score 2.972) (writing took 16.637118011014536 seconds)
2023-04-22 00:13:38 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-04-22 00:13:38 | INFO | train | epoch 048 | loss 1.758 | ppl 3.38 | wps 2822.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 288 | lr 5.89256e-06 | gnorm 0.854 | train_wall 24 | gb_free 31 | wall 2584
2023-04-22 00:13:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:13:38 | INFO | fairseq.trainer | begin training epoch 49
2023-04-22 00:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:14:11 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 2.98 | ppl 7.89 | wps 16954.2 | wpb 857.5 | bsz 3 | num_updates 294 | best_loss 2.811
2023-04-22 00:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 294 updates
2023-04-22 00:14:11 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint49.pt
2023-04-22 00:14:17 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint49.pt
2023-04-22 00:14:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint49.pt (epoch 49 @ 294 updates, score 2.98) (writing took 16.00398173800204 seconds)
2023-04-22 00:14:28 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-04-22 00:14:28 | INFO | train | epoch 049 | loss 1.739 | ppl 3.34 | wps 2856.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 294 | lr 5.83212e-06 | gnorm 0.844 | train_wall 24 | gb_free 31 | wall 2634
2023-04-22 00:14:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:14:28 | INFO | fairseq.trainer | begin training epoch 50
2023-04-22 00:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:14:52 | INFO | train_inner | epoch 050:      6 / 6 loss=1.893, ppl=3.71, wps=2866.5, ups=0.12, wpb=23759.8, bsz=83.1, num_updates=300, lr=5.7735e-06, gnorm=0.841, train_wall=404, gb_free=31.6, wall=2658
2023-04-22 00:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:15:01 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 2.985 | ppl 7.92 | wps 17039.2 | wpb 857.5 | bsz 3 | num_updates 300 | best_loss 2.811
2023-04-22 00:15:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 300 updates
2023-04-22 00:15:01 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint50.pt
2023-04-22 00:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint50.pt
2023-04-22 00:15:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint50.pt (epoch 50 @ 300 updates, score 2.985) (writing took 17.860187607002445 seconds)
2023-04-22 00:15:20 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-04-22 00:15:20 | INFO | train | epoch 050 | loss 1.716 | ppl 3.28 | wps 2769.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 300 | lr 5.7735e-06 | gnorm 0.847 | train_wall 24 | gb_free 31.6 | wall 2686
2023-04-22 00:15:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:15:20 | INFO | fairseq.trainer | begin training epoch 51
2023-04-22 00:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:15:53 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 2.993 | ppl 7.96 | wps 16938.8 | wpb 857.5 | bsz 3 | num_updates 306 | best_loss 2.811
2023-04-22 00:15:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 306 updates
2023-04-22 00:15:53 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint51.pt
2023-04-22 00:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint51.pt
2023-04-22 00:16:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint51.pt (epoch 51 @ 306 updates, score 2.993) (writing took 15.67461651598569 seconds)
2023-04-22 00:16:09 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-04-22 00:16:09 | INFO | train | epoch 051 | loss 1.696 | ppl 3.24 | wps 2879.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 306 | lr 5.71662e-06 | gnorm 0.863 | train_wall 24 | gb_free 31 | wall 2735
2023-04-22 00:16:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:16:09 | INFO | fairseq.trainer | begin training epoch 52
2023-04-22 00:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:16:42 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.002 | ppl 8.01 | wps 16953 | wpb 857.5 | bsz 3 | num_updates 312 | best_loss 2.811
2023-04-22 00:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 312 updates
2023-04-22 00:16:42 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint52.pt
2023-04-22 00:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint52.pt
2023-04-22 00:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint52.pt (epoch 52 @ 312 updates, score 3.002) (writing took 16.80106015599449 seconds)
2023-04-22 00:17:00 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-04-22 00:17:00 | INFO | train | epoch 052 | loss 1.68 | ppl 3.2 | wps 2811.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 312 | lr 5.66139e-06 | gnorm 0.866 | train_wall 24 | gb_free 31.4 | wall 2786
2023-04-22 00:17:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:17:00 | INFO | fairseq.trainer | begin training epoch 53
2023-04-22 00:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:17:33 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 3.007 | ppl 8.04 | wps 16964.3 | wpb 857.5 | bsz 3 | num_updates 318 | best_loss 2.811
2023-04-22 00:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 318 updates
2023-04-22 00:17:33 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint53.pt
2023-04-22 00:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint53.pt
2023-04-22 00:17:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint53.pt (epoch 53 @ 318 updates, score 3.007) (writing took 16.507589105982333 seconds)
2023-04-22 00:17:51 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-04-22 00:17:51 | INFO | train | epoch 053 | loss 1.655 | ppl 3.15 | wps 2829.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 318 | lr 5.60772e-06 | gnorm 0.841 | train_wall 24 | gb_free 31.2 | wall 2837
2023-04-22 00:17:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:17:51 | INFO | fairseq.trainer | begin training epoch 54
2023-04-22 00:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:18:24 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.014 | ppl 8.08 | wps 16946.9 | wpb 857.5 | bsz 3 | num_updates 324 | best_loss 2.811
2023-04-22 00:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 324 updates
2023-04-22 00:18:24 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint54.pt
2023-04-22 00:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint54.pt
2023-04-22 00:18:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint54.pt (epoch 54 @ 324 updates, score 3.014) (writing took 16.860076028009644 seconds)
2023-04-22 00:18:41 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-04-22 00:18:41 | INFO | train | epoch 054 | loss 1.637 | ppl 3.11 | wps 2808.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 324 | lr 5.55556e-06 | gnorm 0.868 | train_wall 24 | gb_free 31.5 | wall 2887
2023-04-22 00:18:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:18:41 | INFO | fairseq.trainer | begin training epoch 55
2023-04-22 00:18:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:19:14 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 3.021 | ppl 8.12 | wps 16940.5 | wpb 857.5 | bsz 3 | num_updates 330 | best_loss 2.811
2023-04-22 00:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 330 updates
2023-04-22 00:19:14 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint55.pt
2023-04-22 00:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint55.pt
2023-04-22 00:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint55.pt (epoch 55 @ 330 updates, score 3.021) (writing took 16.235681405989453 seconds)
2023-04-22 00:19:32 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-04-22 00:19:32 | INFO | train | epoch 055 | loss 1.623 | ppl 3.08 | wps 2837 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 330 | lr 5.50482e-06 | gnorm 0.871 | train_wall 24 | gb_free 30.7 | wall 2938
2023-04-22 00:19:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:19:32 | INFO | fairseq.trainer | begin training epoch 56
2023-04-22 00:19:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:20:05 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 3.026 | ppl 8.15 | wps 16957.7 | wpb 857.5 | bsz 3 | num_updates 336 | best_loss 2.811
2023-04-22 00:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 336 updates
2023-04-22 00:20:05 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint56.pt
2023-04-22 00:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint56.pt
2023-04-22 00:20:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint56.pt (epoch 56 @ 336 updates, score 3.026) (writing took 16.78550419997191 seconds)
2023-04-22 00:20:23 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2023-04-22 00:20:23 | INFO | train | epoch 056 | loss 1.598 | ppl 3.03 | wps 2822 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 336 | lr 5.45545e-06 | gnorm 0.868 | train_wall 24 | gb_free 31 | wall 2989
2023-04-22 00:20:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:20:23 | INFO | fairseq.trainer | begin training epoch 57
2023-04-22 00:20:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:20:56 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 3.034 | ppl 8.19 | wps 16970.4 | wpb 857.5 | bsz 3 | num_updates 342 | best_loss 2.811
2023-04-22 00:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 342 updates
2023-04-22 00:20:56 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint57.pt
2023-04-22 00:21:02 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint57.pt
2023-04-22 00:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint57.pt (epoch 57 @ 342 updates, score 3.034) (writing took 16.67586421899614 seconds)
2023-04-22 00:21:13 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2023-04-22 00:21:13 | INFO | train | epoch 057 | loss 1.584 | ppl 3 | wps 2819.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 342 | lr 5.40738e-06 | gnorm 0.871 | train_wall 24 | gb_free 30.8 | wall 3039
2023-04-22 00:21:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:21:13 | INFO | fairseq.trainer | begin training epoch 58
2023-04-22 00:21:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:21:46 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 3.04 | ppl 8.22 | wps 16943.6 | wpb 857.5 | bsz 3 | num_updates 348 | best_loss 2.811
2023-04-22 00:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 348 updates
2023-04-22 00:21:46 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint58.pt
2023-04-22 00:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint58.pt
2023-04-22 00:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint58.pt (epoch 58 @ 348 updates, score 3.04) (writing took 16.550094951991923 seconds)
2023-04-22 00:22:04 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2023-04-22 00:22:04 | INFO | train | epoch 058 | loss 1.567 | ppl 2.96 | wps 2825.4 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 348 | lr 5.36056e-06 | gnorm 0.855 | train_wall 24 | gb_free 31.4 | wall 3090
2023-04-22 00:22:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:22:04 | INFO | fairseq.trainer | begin training epoch 59
2023-04-22 00:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:22:37 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 3.046 | ppl 8.26 | wps 16944.7 | wpb 857.5 | bsz 3 | num_updates 354 | best_loss 2.811
2023-04-22 00:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 354 updates
2023-04-22 00:22:37 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint59.pt
2023-04-22 00:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint59.pt
2023-04-22 00:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint59.pt (epoch 59 @ 354 updates, score 3.046) (writing took 18.352670528984163 seconds)
2023-04-22 00:22:56 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2023-04-22 00:22:56 | INFO | train | epoch 059 | loss 1.551 | ppl 2.93 | wps 2729.9 | ups 0.11 | wpb 23829.8 | bsz 83.3 | num_updates 354 | lr 5.31494e-06 | gnorm 0.852 | train_wall 24 | gb_free 30.7 | wall 3142
2023-04-22 00:22:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:22:56 | INFO | fairseq.trainer | begin training epoch 60
2023-04-22 00:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:23:29 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 3.054 | ppl 8.31 | wps 16945.3 | wpb 857.5 | bsz 3 | num_updates 360 | best_loss 2.811
2023-04-22 00:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 360 updates
2023-04-22 00:23:29 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint60.pt
2023-04-22 00:23:36 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint60.pt
2023-04-22 00:23:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint60.pt (epoch 60 @ 360 updates, score 3.054) (writing took 16.615395443019224 seconds)
2023-04-22 00:23:47 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2023-04-22 00:23:47 | INFO | train | epoch 060 | loss 1.531 | ppl 2.89 | wps 2823.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 360 | lr 5.27046e-06 | gnorm 0.855 | train_wall 24 | gb_free 31.4 | wall 3193
2023-04-22 00:23:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:23:47 | INFO | fairseq.trainer | begin training epoch 61
2023-04-22 00:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:24:20 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 3.059 | ppl 8.34 | wps 16938.6 | wpb 857.5 | bsz 3 | num_updates 366 | best_loss 2.811
2023-04-22 00:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 366 updates
2023-04-22 00:24:20 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint61.pt
2023-04-22 00:24:26 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint61.pt
2023-04-22 00:24:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint61.pt (epoch 61 @ 366 updates, score 3.059) (writing took 17.0093806880177 seconds)
2023-04-22 00:24:38 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2023-04-22 00:24:38 | INFO | train | epoch 061 | loss 1.514 | ppl 2.86 | wps 2799.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 366 | lr 5.22708e-06 | gnorm 0.854 | train_wall 24 | gb_free 31.1 | wall 3244
2023-04-22 00:24:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:24:38 | INFO | fairseq.trainer | begin training epoch 62
2023-04-22 00:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:25:11 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 3.066 | ppl 8.37 | wps 16976.1 | wpb 857.5 | bsz 3 | num_updates 372 | best_loss 2.811
2023-04-22 00:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 372 updates
2023-04-22 00:25:11 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint62.pt
2023-04-22 00:25:18 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint62.pt
2023-04-22 00:25:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint62.pt (epoch 62 @ 372 updates, score 3.066) (writing took 17.036457118025282 seconds)
2023-04-22 00:25:29 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2023-04-22 00:25:29 | INFO | train | epoch 062 | loss 1.498 | ppl 2.82 | wps 2808.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 372 | lr 5.18476e-06 | gnorm 0.868 | train_wall 24 | gb_free 31 | wall 3295
2023-04-22 00:25:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:25:29 | INFO | fairseq.trainer | begin training epoch 63
2023-04-22 00:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:25:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:26:02 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 3.072 | ppl 8.41 | wps 16956.9 | wpb 857.5 | bsz 3 | num_updates 378 | best_loss 2.811
2023-04-22 00:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 378 updates
2023-04-22 00:26:02 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint63.pt
2023-04-22 00:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint63.pt
2023-04-22 00:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint63.pt (epoch 63 @ 378 updates, score 3.072) (writing took 16.633290329016745 seconds)
2023-04-22 00:26:19 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2023-04-22 00:26:19 | INFO | train | epoch 063 | loss 1.484 | ppl 2.8 | wps 2826.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 378 | lr 5.14344e-06 | gnorm 0.862 | train_wall 24 | gb_free 31.6 | wall 3345
2023-04-22 00:26:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:26:19 | INFO | fairseq.trainer | begin training epoch 64
2023-04-22 00:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:26:52 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 3.077 | ppl 8.44 | wps 16986.2 | wpb 857.5 | bsz 3 | num_updates 384 | best_loss 2.811
2023-04-22 00:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 384 updates
2023-04-22 00:26:52 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint64.pt
2023-04-22 00:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint64.pt
2023-04-22 00:27:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint64.pt (epoch 64 @ 384 updates, score 3.077) (writing took 16.9883456180105 seconds)
2023-04-22 00:27:10 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2023-04-22 00:27:10 | INFO | train | epoch 064 | loss 1.467 | ppl 2.76 | wps 2805.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 384 | lr 5.1031e-06 | gnorm 0.866 | train_wall 24 | gb_free 31.4 | wall 3396
2023-04-22 00:27:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:27:10 | INFO | fairseq.trainer | begin training epoch 65
2023-04-22 00:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:27:43 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 3.083 | ppl 8.47 | wps 16982.7 | wpb 857.5 | bsz 3 | num_updates 390 | best_loss 2.811
2023-04-22 00:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 390 updates
2023-04-22 00:27:43 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint65.pt
2023-04-22 00:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint65.pt
2023-04-22 00:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint65.pt (epoch 65 @ 390 updates, score 3.083) (writing took 16.718767405982362 seconds)
2023-04-22 00:28:01 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2023-04-22 00:28:01 | INFO | train | epoch 065 | loss 1.452 | ppl 2.74 | wps 2819.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 390 | lr 5.0637e-06 | gnorm 0.851 | train_wall 24 | gb_free 31.2 | wall 3447
2023-04-22 00:28:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:28:01 | INFO | fairseq.trainer | begin training epoch 66
2023-04-22 00:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:28:34 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 3.09 | ppl 8.52 | wps 16966.6 | wpb 857.5 | bsz 3 | num_updates 396 | best_loss 2.811
2023-04-22 00:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 396 updates
2023-04-22 00:28:34 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint66.pt
2023-04-22 00:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint66.pt
2023-04-22 00:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint66.pt (epoch 66 @ 396 updates, score 3.09) (writing took 17.63804047400481 seconds)
2023-04-22 00:28:53 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2023-04-22 00:28:53 | INFO | train | epoch 066 | loss 1.434 | ppl 2.7 | wps 2761 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 396 | lr 5.02519e-06 | gnorm 0.856 | train_wall 24 | gb_free 31.1 | wall 3499
2023-04-22 00:28:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:28:53 | INFO | fairseq.trainer | begin training epoch 67
2023-04-22 00:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:29:12 | INFO | train_inner | epoch 067:      4 / 6 loss=1.554, ppl=2.94, wps=2789.4, ups=0.12, wpb=23967.1, bsz=83.8, num_updates=400, lr=5e-06, gnorm=0.856, train_wall=408, gb_free=30.6, wall=3518
2023-04-22 00:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:29:26 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 3.097 | ppl 8.56 | wps 16964.8 | wpb 857.5 | bsz 3 | num_updates 402 | best_loss 2.811
2023-04-22 00:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 402 updates
2023-04-22 00:29:26 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint67.pt
2023-04-22 00:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint67.pt
2023-04-22 00:29:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint67.pt (epoch 67 @ 402 updates, score 3.097) (writing took 16.864438383985544 seconds)
2023-04-22 00:29:44 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2023-04-22 00:29:44 | INFO | train | epoch 067 | loss 1.421 | ppl 2.68 | wps 2809.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 402 | lr 4.98755e-06 | gnorm 0.872 | train_wall 24 | gb_free 31.2 | wall 3550
2023-04-22 00:29:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:29:44 | INFO | fairseq.trainer | begin training epoch 68
2023-04-22 00:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:30:17 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 3.102 | ppl 8.59 | wps 16947.7 | wpb 857.5 | bsz 3 | num_updates 408 | best_loss 2.811
2023-04-22 00:30:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 408 updates
2023-04-22 00:30:17 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint68.pt
2023-04-22 00:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint68.pt
2023-04-22 00:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint68.pt (epoch 68 @ 408 updates, score 3.102) (writing took 16.535375908977585 seconds)
2023-04-22 00:30:34 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2023-04-22 00:30:34 | INFO | train | epoch 068 | loss 1.407 | ppl 2.65 | wps 2840.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 408 | lr 4.95074e-06 | gnorm 0.858 | train_wall 24 | gb_free 31.6 | wall 3600
2023-04-22 00:30:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:30:34 | INFO | fairseq.trainer | begin training epoch 69
2023-04-22 00:30:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:31:07 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 3.107 | ppl 8.62 | wps 16900.4 | wpb 857.5 | bsz 3 | num_updates 414 | best_loss 2.811
2023-04-22 00:31:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 414 updates
2023-04-22 00:31:07 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint69.pt
2023-04-22 00:31:13 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint69.pt
2023-04-22 00:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint69.pt (epoch 69 @ 414 updates, score 3.107) (writing took 16.544907788018463 seconds)
2023-04-22 00:31:25 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2023-04-22 00:31:25 | INFO | train | epoch 069 | loss 1.39 | ppl 2.62 | wps 2828.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 414 | lr 4.91473e-06 | gnorm 0.865 | train_wall 24 | gb_free 31.2 | wall 3651
2023-04-22 00:31:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:31:25 | INFO | fairseq.trainer | begin training epoch 70
2023-04-22 00:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:31:58 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 3.114 | ppl 8.66 | wps 16977.2 | wpb 857.5 | bsz 3 | num_updates 420 | best_loss 2.811
2023-04-22 00:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 420 updates
2023-04-22 00:31:58 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint70.pt
2023-04-22 00:32:04 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint70.pt
2023-04-22 00:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint70.pt (epoch 70 @ 420 updates, score 3.114) (writing took 16.662649878009688 seconds)
2023-04-22 00:32:15 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2023-04-22 00:32:15 | INFO | train | epoch 070 | loss 1.376 | ppl 2.59 | wps 2822.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 420 | lr 4.8795e-06 | gnorm 0.856 | train_wall 24 | gb_free 31.1 | wall 3701
2023-04-22 00:32:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:32:15 | INFO | fairseq.trainer | begin training epoch 71
2023-04-22 00:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:32:48 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 3.123 | ppl 8.71 | wps 16961.1 | wpb 857.5 | bsz 3 | num_updates 426 | best_loss 2.811
2023-04-22 00:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 426 updates
2023-04-22 00:32:48 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint71.pt
2023-04-22 00:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint71.pt
2023-04-22 00:33:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint71.pt (epoch 71 @ 426 updates, score 3.123) (writing took 16.618504398997175 seconds)
2023-04-22 00:33:06 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2023-04-22 00:33:06 | INFO | train | epoch 071 | loss 1.362 | ppl 2.57 | wps 2821.4 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 426 | lr 4.84502e-06 | gnorm 0.86 | train_wall 24 | gb_free 31.3 | wall 3752
2023-04-22 00:33:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:33:06 | INFO | fairseq.trainer | begin training epoch 72
2023-04-22 00:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:33:39 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 3.128 | ppl 8.74 | wps 16939.8 | wpb 857.5 | bsz 3 | num_updates 432 | best_loss 2.811
2023-04-22 00:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 432 updates
2023-04-22 00:33:39 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint72.pt
2023-04-22 00:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint72.pt
2023-04-22 00:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint72.pt (epoch 72 @ 432 updates, score 3.128) (writing took 16.84089282399509 seconds)
2023-04-22 00:33:57 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2023-04-22 00:33:57 | INFO | train | epoch 072 | loss 1.351 | ppl 2.55 | wps 2813.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 432 | lr 4.81125e-06 | gnorm 0.887 | train_wall 24 | gb_free 31.1 | wall 3803
2023-04-22 00:33:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:33:57 | INFO | fairseq.trainer | begin training epoch 73
2023-04-22 00:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:34:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:34:30 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 3.131 | ppl 8.76 | wps 16974.2 | wpb 857.5 | bsz 3 | num_updates 438 | best_loss 2.811
2023-04-22 00:34:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 438 updates
2023-04-22 00:34:30 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint73.pt
2023-04-22 00:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint73.pt
2023-04-22 00:34:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint73.pt (epoch 73 @ 438 updates, score 3.131) (writing took 16.686365872010356 seconds)
2023-04-22 00:34:48 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2023-04-22 00:34:48 | INFO | train | epoch 073 | loss 1.332 | ppl 2.52 | wps 2820.3 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 438 | lr 4.77818e-06 | gnorm 0.865 | train_wall 24 | gb_free 31.1 | wall 3854
2023-04-22 00:34:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:34:48 | INFO | fairseq.trainer | begin training epoch 74
2023-04-22 00:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:35:21 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 3.135 | ppl 8.79 | wps 16963.5 | wpb 857.5 | bsz 3 | num_updates 444 | best_loss 2.811
2023-04-22 00:35:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 444 updates
2023-04-22 00:35:21 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint74.pt
2023-04-22 00:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint74.pt
2023-04-22 00:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint74.pt (epoch 74 @ 444 updates, score 3.135) (writing took 16.342982561996905 seconds)
2023-04-22 00:35:38 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2023-04-22 00:35:38 | INFO | train | epoch 074 | loss 1.323 | ppl 2.5 | wps 2842.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 444 | lr 4.74579e-06 | gnorm 0.855 | train_wall 24 | gb_free 31.1 | wall 3904
2023-04-22 00:35:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:35:38 | INFO | fairseq.trainer | begin training epoch 75
2023-04-22 00:35:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:36:11 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 3.14 | ppl 8.81 | wps 16959.6 | wpb 857.5 | bsz 3 | num_updates 450 | best_loss 2.811
2023-04-22 00:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 450 updates
2023-04-22 00:36:11 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint75.pt
2023-04-22 00:36:17 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint75.pt
2023-04-22 00:36:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint75.pt (epoch 75 @ 450 updates, score 3.14) (writing took 16.59170592200826 seconds)
2023-04-22 00:36:29 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2023-04-22 00:36:29 | INFO | train | epoch 075 | loss 1.309 | ppl 2.48 | wps 2812.4 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 450 | lr 4.71405e-06 | gnorm 0.866 | train_wall 24 | gb_free 31.2 | wall 3955
2023-04-22 00:36:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:36:29 | INFO | fairseq.trainer | begin training epoch 76
2023-04-22 00:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:37:02 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 3.147 | ppl 8.86 | wps 16959.4 | wpb 857.5 | bsz 3 | num_updates 456 | best_loss 2.811
2023-04-22 00:37:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 456 updates
2023-04-22 00:37:02 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint76.pt
2023-04-22 00:37:08 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint76.pt
2023-04-22 00:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint76.pt (epoch 76 @ 456 updates, score 3.147) (writing took 16.00808311998844 seconds)
2023-04-22 00:37:19 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2023-04-22 00:37:19 | INFO | train | epoch 076 | loss 1.295 | ppl 2.45 | wps 2854.3 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 456 | lr 4.68293e-06 | gnorm 0.872 | train_wall 24 | gb_free 31.6 | wall 4005
2023-04-22 00:37:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:37:19 | INFO | fairseq.trainer | begin training epoch 77
2023-04-22 00:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:37:52 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 3.154 | ppl 8.9 | wps 16952.2 | wpb 857.5 | bsz 3 | num_updates 462 | best_loss 2.811
2023-04-22 00:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 462 updates
2023-04-22 00:37:52 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint77.pt
2023-04-22 00:37:58 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint77.pt
2023-04-22 00:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint77.pt (epoch 77 @ 462 updates, score 3.154) (writing took 16.420916396018583 seconds)
2023-04-22 00:38:09 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2023-04-22 00:38:09 | INFO | train | epoch 077 | loss 1.283 | ppl 2.43 | wps 2832.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 462 | lr 4.65242e-06 | gnorm 0.864 | train_wall 24 | gb_free 31.5 | wall 4055
2023-04-22 00:38:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:38:09 | INFO | fairseq.trainer | begin training epoch 78
2023-04-22 00:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:38:42 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 3.158 | ppl 8.93 | wps 16962.3 | wpb 857.5 | bsz 3 | num_updates 468 | best_loss 2.811
2023-04-22 00:38:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 468 updates
2023-04-22 00:38:42 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint78.pt
2023-04-22 00:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint78.pt
2023-04-22 00:38:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint78.pt (epoch 78 @ 468 updates, score 3.158) (writing took 16.03151003300445 seconds)
2023-04-22 00:38:59 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2023-04-22 00:38:59 | INFO | train | epoch 078 | loss 1.269 | ppl 2.41 | wps 2859.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 468 | lr 4.6225e-06 | gnorm 0.878 | train_wall 24 | gb_free 31.1 | wall 4105
2023-04-22 00:38:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:38:59 | INFO | fairseq.trainer | begin training epoch 79
2023-04-22 00:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:39:32 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 3.163 | ppl 8.96 | wps 16970.8 | wpb 857.5 | bsz 3 | num_updates 474 | best_loss 2.811
2023-04-22 00:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 474 updates
2023-04-22 00:39:32 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint79.pt
2023-04-22 00:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint79.pt
2023-04-22 00:39:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint79.pt (epoch 79 @ 474 updates, score 3.163) (writing took 16.741221457981737 seconds)
2023-04-22 00:39:50 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2023-04-22 00:39:50 | INFO | train | epoch 079 | loss 1.258 | ppl 2.39 | wps 2817.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 474 | lr 4.59315e-06 | gnorm 0.871 | train_wall 24 | gb_free 31.2 | wall 4156
2023-04-22 00:39:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:39:50 | INFO | fairseq.trainer | begin training epoch 80
2023-04-22 00:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:40:23 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 3.169 | ppl 8.99 | wps 16927.8 | wpb 857.5 | bsz 3 | num_updates 480 | best_loss 2.811
2023-04-22 00:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 480 updates
2023-04-22 00:40:23 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint80.pt
2023-04-22 00:40:29 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint80.pt
2023-04-22 00:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint80.pt (epoch 80 @ 480 updates, score 3.169) (writing took 15.910258022980997 seconds)
2023-04-22 00:40:40 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2023-04-22 00:40:40 | INFO | train | epoch 080 | loss 1.242 | ppl 2.37 | wps 2870.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 480 | lr 4.56435e-06 | gnorm 0.853 | train_wall 24 | gb_free 31.3 | wall 4206
2023-04-22 00:40:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:40:40 | INFO | fairseq.trainer | begin training epoch 81
2023-04-22 00:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:41:13 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 3.176 | ppl 9.04 | wps 16972.4 | wpb 857.5 | bsz 3 | num_updates 486 | best_loss 2.811
2023-04-22 00:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 486 updates
2023-04-22 00:41:13 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint81.pt
2023-04-22 00:41:18 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint81.pt
2023-04-22 00:41:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint81.pt (epoch 81 @ 486 updates, score 3.176) (writing took 15.067784679995384 seconds)
2023-04-22 00:41:29 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2023-04-22 00:41:29 | INFO | train | epoch 081 | loss 1.233 | ppl 2.35 | wps 2909.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 486 | lr 4.53609e-06 | gnorm 0.869 | train_wall 24 | gb_free 31.2 | wall 4255
2023-04-22 00:41:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:41:29 | INFO | fairseq.trainer | begin training epoch 82
2023-04-22 00:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:42:02 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 3.181 | ppl 9.07 | wps 17032.9 | wpb 857.5 | bsz 3 | num_updates 492 | best_loss 2.811
2023-04-22 00:42:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 492 updates
2023-04-22 00:42:02 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint82.pt
2023-04-22 00:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint82.pt
2023-04-22 00:42:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint82.pt (epoch 82 @ 492 updates, score 3.181) (writing took 14.566418553004041 seconds)
2023-04-22 00:42:18 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2023-04-22 00:42:18 | INFO | train | epoch 082 | loss 1.224 | ppl 2.34 | wps 2936.1 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 492 | lr 4.50835e-06 | gnorm 0.854 | train_wall 24 | gb_free 31.1 | wall 4304
2023-04-22 00:42:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:42:18 | INFO | fairseq.trainer | begin training epoch 83
2023-04-22 00:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:42:51 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 3.184 | ppl 9.09 | wps 16984.6 | wpb 857.5 | bsz 3 | num_updates 498 | best_loss 2.811
2023-04-22 00:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 498 updates
2023-04-22 00:42:51 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint83.pt
2023-04-22 00:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint83.pt
2023-04-22 00:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint83.pt (epoch 83 @ 498 updates, score 3.184) (writing took 15.312260673992569 seconds)
2023-04-22 00:43:07 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2023-04-22 00:43:07 | INFO | train | epoch 083 | loss 1.209 | ppl 2.31 | wps 2887.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 498 | lr 4.48111e-06 | gnorm 0.869 | train_wall 24 | gb_free 31.2 | wall 4353
2023-04-22 00:43:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:43:07 | INFO | fairseq.trainer | begin training epoch 84
2023-04-22 00:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:43:17 | INFO | train_inner | epoch 084:      2 / 6 loss=1.303, ppl=2.47, wps=2812.8, ups=0.12, wpb=23765, bsz=83.1, num_updates=500, lr=4.47214e-06, gnorm=0.868, train_wall=404, gb_free=30.7, wall=4363
2023-04-22 00:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:43:40 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 3.188 | ppl 9.11 | wps 16995.8 | wpb 857.5 | bsz 3 | num_updates 504 | best_loss 2.811
2023-04-22 00:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 504 updates
2023-04-22 00:43:40 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint84.pt
2023-04-22 00:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint84.pt
2023-04-22 00:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint84.pt (epoch 84 @ 504 updates, score 3.188) (writing took 14.546000570000615 seconds)
2023-04-22 00:43:56 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2023-04-22 00:43:56 | INFO | train | epoch 084 | loss 1.198 | ppl 2.29 | wps 2932.3 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 504 | lr 4.45435e-06 | gnorm 0.876 | train_wall 24 | gb_free 30.9 | wall 4402
2023-04-22 00:43:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:43:56 | INFO | fairseq.trainer | begin training epoch 85
2023-04-22 00:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:44:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:44:29 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 3.194 | ppl 9.15 | wps 17037.7 | wpb 857.5 | bsz 3 | num_updates 510 | best_loss 2.811
2023-04-22 00:44:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 510 updates
2023-04-22 00:44:29 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint85.pt
2023-04-22 00:44:34 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint85.pt
2023-04-22 00:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint85.pt (epoch 85 @ 510 updates, score 3.194) (writing took 15.296735217008973 seconds)
2023-04-22 00:44:45 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2023-04-22 00:44:45 | INFO | train | epoch 085 | loss 1.187 | ppl 2.28 | wps 2902.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 510 | lr 4.42807e-06 | gnorm 0.873 | train_wall 24 | gb_free 31.1 | wall 4451
2023-04-22 00:44:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:44:45 | INFO | fairseq.trainer | begin training epoch 86
2023-04-22 00:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:45:18 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 3.2 | ppl 9.19 | wps 16988 | wpb 857.5 | bsz 3 | num_updates 516 | best_loss 2.811
2023-04-22 00:45:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 516 updates
2023-04-22 00:45:18 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint86.pt
2023-04-22 00:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint86.pt
2023-04-22 00:45:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint86.pt (epoch 86 @ 516 updates, score 3.2) (writing took 14.611300512013258 seconds)
2023-04-22 00:45:34 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2023-04-22 00:45:34 | INFO | train | epoch 086 | loss 1.173 | ppl 2.26 | wps 2953.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 516 | lr 4.40225e-06 | gnorm 0.848 | train_wall 24 | gb_free 30.7 | wall 4500
2023-04-22 00:45:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:45:34 | INFO | fairseq.trainer | begin training epoch 87
2023-04-22 00:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:46:07 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 3.204 | ppl 9.21 | wps 17044.4 | wpb 857.5 | bsz 3 | num_updates 522 | best_loss 2.811
2023-04-22 00:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 522 updates
2023-04-22 00:46:07 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint87.pt
2023-04-22 00:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint87.pt
2023-04-22 00:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint87.pt (epoch 87 @ 522 updates, score 3.204) (writing took 15.244830441981321 seconds)
2023-04-22 00:46:23 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2023-04-22 00:46:23 | INFO | train | epoch 087 | loss 1.161 | ppl 2.24 | wps 2911.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 522 | lr 4.37688e-06 | gnorm 0.871 | train_wall 24 | gb_free 31.6 | wall 4549
2023-04-22 00:46:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:46:23 | INFO | fairseq.trainer | begin training epoch 88
2023-04-22 00:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:46:56 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 3.21 | ppl 9.25 | wps 16951.5 | wpb 857.5 | bsz 3 | num_updates 528 | best_loss 2.811
2023-04-22 00:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 528 updates
2023-04-22 00:46:56 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint88.pt
2023-04-22 00:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint88.pt
2023-04-22 00:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint88.pt (epoch 88 @ 528 updates, score 3.21) (writing took 14.456029733992182 seconds)
2023-04-22 00:47:11 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2023-04-22 00:47:11 | INFO | train | epoch 088 | loss 1.151 | ppl 2.22 | wps 2952.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 528 | lr 4.35194e-06 | gnorm 0.851 | train_wall 24 | gb_free 31.1 | wall 4597
2023-04-22 00:47:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:47:11 | INFO | fairseq.trainer | begin training epoch 89
2023-04-22 00:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:47:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:47:44 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 3.212 | ppl 9.27 | wps 17042.8 | wpb 857.5 | bsz 3 | num_updates 534 | best_loss 2.811
2023-04-22 00:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 534 updates
2023-04-22 00:47:44 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint89.pt
2023-04-22 00:47:50 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint89.pt
2023-04-22 00:48:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint89.pt (epoch 89 @ 534 updates, score 3.212) (writing took 15.3589933559997 seconds)
2023-04-22 00:48:01 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2023-04-22 00:48:01 | INFO | train | epoch 089 | loss 1.143 | ppl 2.21 | wps 2890.8 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 534 | lr 4.32742e-06 | gnorm 0.855 | train_wall 24 | gb_free 31.5 | wall 4647
2023-04-22 00:48:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:48:01 | INFO | fairseq.trainer | begin training epoch 90
2023-04-22 00:48:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:48:34 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 3.219 | ppl 9.31 | wps 16987.5 | wpb 857.5 | bsz 3 | num_updates 540 | best_loss 2.811
2023-04-22 00:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 540 updates
2023-04-22 00:48:34 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint90.pt
2023-04-22 00:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint90.pt
2023-04-22 00:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint90.pt (epoch 90 @ 540 updates, score 3.219) (writing took 14.54286867598421 seconds)
2023-04-22 00:48:49 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2023-04-22 00:48:49 | INFO | train | epoch 090 | loss 1.132 | ppl 2.19 | wps 2951.7 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 540 | lr 4.30331e-06 | gnorm 0.863 | train_wall 24 | gb_free 31.3 | wall 4695
2023-04-22 00:48:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:48:49 | INFO | fairseq.trainer | begin training epoch 91
2023-04-22 00:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:49:22 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 3.223 | ppl 9.34 | wps 16981.9 | wpb 857.5 | bsz 3 | num_updates 546 | best_loss 2.811
2023-04-22 00:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 546 updates
2023-04-22 00:49:22 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint91.pt
2023-04-22 00:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint91.pt
2023-04-22 00:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint91.pt (epoch 91 @ 546 updates, score 3.223) (writing took 15.397380217997124 seconds)
2023-04-22 00:49:38 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2023-04-22 00:49:38 | INFO | train | epoch 091 | loss 1.121 | ppl 2.17 | wps 2896 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 546 | lr 4.2796e-06 | gnorm 0.845 | train_wall 24 | gb_free 30.7 | wall 4744
2023-04-22 00:49:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:49:38 | INFO | fairseq.trainer | begin training epoch 92
2023-04-22 00:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:50:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:50:11 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 3.229 | ppl 9.37 | wps 17041.8 | wpb 857.5 | bsz 3 | num_updates 552 | best_loss 2.811
2023-04-22 00:50:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 552 updates
2023-04-22 00:50:11 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint92.pt
2023-04-22 00:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint92.pt
2023-04-22 00:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint92.pt (epoch 92 @ 552 updates, score 3.229) (writing took 14.814886180014582 seconds)
2023-04-22 00:50:27 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2023-04-22 00:50:27 | INFO | train | epoch 092 | loss 1.109 | ppl 2.16 | wps 2944.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 552 | lr 4.25628e-06 | gnorm 0.842 | train_wall 24 | gb_free 31.2 | wall 4793
2023-04-22 00:50:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:50:27 | INFO | fairseq.trainer | begin training epoch 93
2023-04-22 00:50:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:51:00 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 3.234 | ppl 9.41 | wps 16973.2 | wpb 857.5 | bsz 3 | num_updates 558 | best_loss 2.811
2023-04-22 00:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 558 updates
2023-04-22 00:51:00 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint93.pt
2023-04-22 00:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint93.pt
2023-04-22 00:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint93.pt (epoch 93 @ 558 updates, score 3.234) (writing took 15.239014210994355 seconds)
2023-04-22 00:51:16 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2023-04-22 00:51:16 | INFO | train | epoch 093 | loss 1.097 | ppl 2.14 | wps 2910.5 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 558 | lr 4.23334e-06 | gnorm 0.842 | train_wall 24 | gb_free 31.1 | wall 4842
2023-04-22 00:51:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:51:16 | INFO | fairseq.trainer | begin training epoch 94
2023-04-22 00:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:51:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:51:49 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 3.242 | ppl 9.46 | wps 16985 | wpb 857.5 | bsz 3 | num_updates 564 | best_loss 2.811
2023-04-22 00:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 564 updates
2023-04-22 00:51:49 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint94.pt
2023-04-22 00:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint94.pt
2023-04-22 00:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint94.pt (epoch 94 @ 564 updates, score 3.242) (writing took 14.654834987974027 seconds)
2023-04-22 00:52:05 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2023-04-22 00:52:05 | INFO | train | epoch 094 | loss 1.092 | ppl 2.13 | wps 2931.6 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 564 | lr 4.21076e-06 | gnorm 0.843 | train_wall 24 | gb_free 31.3 | wall 4891
2023-04-22 00:52:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:52:05 | INFO | fairseq.trainer | begin training epoch 95
2023-04-22 00:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:52:38 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 3.244 | ppl 9.47 | wps 16988.9 | wpb 857.5 | bsz 3 | num_updates 570 | best_loss 2.811
2023-04-22 00:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 570 updates
2023-04-22 00:52:38 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint95.pt
2023-04-22 00:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint95.pt
2023-04-22 00:52:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint95.pt (epoch 95 @ 570 updates, score 3.244) (writing took 15.369011234986829 seconds)
2023-04-22 00:52:54 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2023-04-22 00:52:54 | INFO | train | epoch 095 | loss 1.077 | ppl 2.11 | wps 2901.3 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 570 | lr 4.18854e-06 | gnorm 0.855 | train_wall 24 | gb_free 31.5 | wall 4940
2023-04-22 00:52:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:52:54 | INFO | fairseq.trainer | begin training epoch 96
2023-04-22 00:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:53:27 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 3.248 | ppl 9.5 | wps 16982.4 | wpb 857.5 | bsz 3 | num_updates 576 | best_loss 2.811
2023-04-22 00:53:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 576 updates
2023-04-22 00:53:27 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint96.pt
2023-04-22 00:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint96.pt
2023-04-22 00:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint96.pt (epoch 96 @ 576 updates, score 3.248) (writing took 14.654650457989192 seconds)
2023-04-22 00:53:43 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2023-04-22 00:53:43 | INFO | train | epoch 096 | loss 1.069 | ppl 2.1 | wps 2927.2 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 576 | lr 4.16667e-06 | gnorm 0.841 | train_wall 24 | gb_free 31.1 | wall 4989
2023-04-22 00:53:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:53:43 | INFO | fairseq.trainer | begin training epoch 97
2023-04-22 00:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:54:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:54:16 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 3.255 | ppl 9.54 | wps 16966.2 | wpb 857.5 | bsz 3 | num_updates 582 | best_loss 2.811
2023-04-22 00:54:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 582 updates
2023-04-22 00:54:16 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint97.pt
2023-04-22 00:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint97.pt
2023-04-22 00:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint97.pt (epoch 97 @ 582 updates, score 3.255) (writing took 15.298681188985938 seconds)
2023-04-22 00:54:32 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2023-04-22 00:54:32 | INFO | train | epoch 097 | loss 1.059 | ppl 2.08 | wps 2902.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 582 | lr 4.14513e-06 | gnorm 0.839 | train_wall 24 | gb_free 31.4 | wall 5038
2023-04-22 00:54:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:54:32 | INFO | fairseq.trainer | begin training epoch 98
2023-04-22 00:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:55:05 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 3.259 | ppl 9.57 | wps 16978.1 | wpb 857.5 | bsz 3 | num_updates 588 | best_loss 2.811
2023-04-22 00:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 588 updates
2023-04-22 00:55:05 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint98.pt
2023-04-22 00:55:11 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint98.pt
2023-04-22 00:55:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint98.pt (epoch 98 @ 588 updates, score 3.259) (writing took 14.682785035984125 seconds)
2023-04-22 00:55:21 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2023-04-22 00:55:21 | INFO | train | epoch 098 | loss 1.048 | ppl 2.07 | wps 2947 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 588 | lr 4.12393e-06 | gnorm 0.87 | train_wall 24 | gb_free 31.4 | wall 5087
2023-04-22 00:55:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:55:21 | INFO | fairseq.trainer | begin training epoch 99
2023-04-22 00:55:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:55:54 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 3.26 | ppl 9.58 | wps 16971.4 | wpb 857.5 | bsz 3 | num_updates 594 | best_loss 2.811
2023-04-22 00:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 594 updates
2023-04-22 00:55:54 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint99.pt
2023-04-22 00:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint99.pt
2023-04-22 00:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint99.pt (epoch 99 @ 594 updates, score 3.26) (writing took 15.156113800010644 seconds)
2023-04-22 00:56:10 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2023-04-22 00:56:10 | INFO | train | epoch 099 | loss 1.041 | ppl 2.06 | wps 2907.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 594 | lr 4.10305e-06 | gnorm 0.848 | train_wall 24 | gb_free 31.1 | wall 5136
2023-04-22 00:56:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6
2023-04-22 00:56:10 | INFO | fairseq.trainer | begin training epoch 100
2023-04-22 00:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-04-22 00:56:34 | INFO | train_inner | epoch 100:      6 / 6 loss=1.109, ppl=2.16, wps=2977.6, ups=0.13, wpb=23757.5, bsz=83.1, num_updates=600, lr=4.08248e-06, gnorm=0.855, train_wall=404, gb_free=31.1, wall=5160
2023-04-22 00:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-04-22 00:56:43 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 3.268 | ppl 9.63 | wps 17043.5 | wpb 857.5 | bsz 3 | num_updates 600 | best_loss 2.811
2023-04-22 00:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 600 updates
2023-04-22 00:56:43 | INFO | fairseq.trainer | Saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint100.pt
2023-04-22 00:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /proj/berzelius-2021-21/users/jacob/BioGPT/checkpoints/RE-BC5CDR-BioGPT/checkpoint100.pt
2023-04-22 00:56:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/RE-BC5CDR-BioGPT/checkpoint100.pt (epoch 100 @ 600 updates, score 3.268) (writing took 14.428583326982334 seconds)
2023-04-22 00:56:58 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2023-04-22 00:56:58 | INFO | train | epoch 100 | loss 1.029 | ppl 2.04 | wps 2958.9 | ups 0.12 | wpb 23829.8 | bsz 83.3 | num_updates 600 | lr 4.08248e-06 | gnorm 0.84 | train_wall 24 | gb_free 31.1 | wall 5184
2023-04-22 00:56:58 | INFO | fairseq_cli.train | done training in 5181.0 seconds
