{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worklog: Jacob Krucinski"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Research (2023/03/20 to 2023/04/01)\n",
    "\n",
    "* Got familiar with AitsLabs GitHub page, particularly `BioNLP` repository\n",
    "  * Looked through Klara's and Nils' folder: README, work log, and some scripts\n",
    "  * Skimmed through Klara's and Nils' final reports, along with Nils' presentation\n",
    "* NLP Refresher\n",
    "  * Reviewing a [tutorial](https://www.analyticsvidhya.com/blog/2022/02/sentiment-analysis-of-imdb-reviews-with-nlp/) I did a while ago for IMDB review sentiment analysis\n",
    "  * [Classification Metrics Formulas](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "  * [Tokenization using NLTK Package](https://realpython.com/nltk-nlp-python/#tokenizing)\n",
    "  * [Gentle Introduction to NLP](https://towardsdatascience.com/a-really-gentle-introduction-to-nlp-in-python-part-1-4712fe18ff3)\n",
    "  * [NLP with Python Tutorial](https://towardsai.net/p/nlp/natural-language-processing-nlp-with-python-tutorial-for-beginners-1f54e610a1a0#27f3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-04\n",
    "\n",
    "#### General\n",
    "First Meeting with Sonja\n",
    "\n",
    "#### Project\n",
    "Named Entity Recognition (NER) Pipeline for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Introduce myself to Sonja and see how I can contribute to her projects.\n",
    "\n",
    "#### Description\n",
    "Met with Sonja and introduced myself and my experience with ML/AI and NLP.\n",
    "Sonja gave me an overview of the NER Pipeline project they are currently working on, and where I can contribute.\n",
    "Also, discussed lab dynamics and NLP resources I can read through on my own time.\n",
    "\n",
    "#### Results/Conclusion\n",
    "N/A\n",
    "\n",
    "#### Next Steps\n",
    "Prepare for Thursday group meeting:\n",
    "* Read manuscript\n",
    "* Complete Onboarding\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-05\n",
    "\n",
    "#### Project\n",
    "Named Entity Recognition (NER) Pipeline for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Become more familiar with the NER project, specifically on a technical level (what corpora were used, what libraries/models were used, etc.).\n",
    "\n",
    "#### Description\n",
    "Worked on Onboarding tasks and read NER manuscript.\n",
    "Came up with some questions for tomorrow's meeting.\n",
    "\n",
    "#### Results/Conclusion\n",
    "N/A\n",
    "\n",
    "#### Next Steps\n",
    "N/A\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-06\n",
    "\n",
    "#### Project\n",
    "Named Entity Recognition (NER) Pipeline for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Meet CDLAI team (Peter and Rafsan) and start planning initial tasks.\n",
    "\n",
    "#### Description\n",
    "* Got account set up with Berzelius NSC\n",
    "* Created `jacob` folder for me on GitHub repository\n",
    "* Created logbook\n",
    "\n",
    "#### Results/Conclusion\n",
    "N/A\n",
    "\n",
    "#### Next Steps\n",
    "* Continue reading manuscript\n",
    "* Read BioGPT paper\n",
    "* Get familiar with HuggingFace\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-10\n",
    "(Easter Break, had some free time while traveling)\n",
    "\n",
    "#### Project\n",
    "Named Entity Recognition (NER) Pipeline for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Start gaining a deeper understanding of NLP and the models used for NER tasks,\n",
    "specifically Transformers, BERT (and BioBERT), and BioGPT\n",
    "\n",
    "#### Description\n",
    "* Read the following 3 articles on Transformers\n",
    "  * [Medium Article](https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04)\n",
    "  * [Machine Learning Mastery](https://machinelearningmastery.com/the-transformer-model/)\n",
    "  * [NVIDIA Article](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/)\n",
    "* Read the following papers\n",
    "  * [Transformers](https://arxiv.org/abs/1706.03762) (if I have time)\n",
    "  * [BERT](https://arxiv.org/abs/1810.04805)\n",
    "* Got access to Berzelius computer (AMD EPYC 7502 32-Core CPU and NVIDIA Quadro RTX 6000 GPU)\n",
    "\n",
    "#### Results/Conclusion\n",
    "N/A\n",
    "\n",
    "#### Next Steps\n",
    "asdf\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-18\n",
    "#### Project\n",
    "Named Entity Recognition (NER) Pipeline for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Finish up work from before Easter break.\n",
    "Determine next step in terms of actual work: running inferences on existing models\n",
    "Get started on next steps if possible.\n",
    "\n",
    "#### Description\n",
    "* Attended group meeting\n",
    "  * Discussed my progress since last week's meeting\n",
    "  * Laid out initial tasks for getting started with Berzelius usage\n",
    "    * Look through Klara's repository\n",
    "    * Rerun Klara's code with ChemProt/DrugProt corpuses\n",
    "    * Retrain BioGPT on the same corpuses Klara used\n",
    "* Read the following papers\n",
    "  * [BioBERT](https://arxiv.org/abs/1901.08746)\n",
    "  * [BioGPT](https://arxiv.org/abs/2210.10341)\n",
    "* Got the BioGPT text generation model to run on a COVID-19 prompt\n",
    "\n",
    "#### Results/Conclusion\n",
    "Able to clone and set up BioGPT folder on Berzelius.\n",
    "Had some issues with running example scripts.\n",
    "Spent a while debugging, and finally realized it had to do with sending jobs to the queue\n",
    "(cannot just run the code locally in a terminal, otherwise GPU resources aren't allocated).\n",
    "\n",
    "#### Next Steps\n",
    "* Start working on applying BioGPT to the corpuses used in the lab\n",
    "  * Get familiar with corpus formats\n",
    "  * Get familiar with pre-processing, training, and inference scripts\n",
    "* Review Berzelius tutorials, specifically for batch job creation\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-19\n",
    "#### Project\n",
    "Relation Extraction (RE) for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Understanding the format of the corpora used for fine-tuned RE and the pre-processing, training/validation, and inference scripts used by the BioGPT authors.\n",
    "\n",
    "#### Description\n",
    "* Reviewed BioGPT paper again to see what methods and corpora were used for RE\n",
    "  * Read through the [BC5CDR](https://github.com/JHnlp/BioCreative-V-CDR-Corpus) GitHub page and created my own notes on the PubTator/BioC formats used for the corpora, found a useful Python package for pre-processing\n",
    "  * Read through the abstracts of the following methods/models used in comparison with BioGPT\n",
    "    * [GLRE](https://arxiv.org/abs/2204.01098)\n",
    "    * [REBEL](https://github.com/Babelscape/rebel/blob/main/docs/EMNLP_2021_REBEL__Camera_Ready_.pdf)\n",
    "    * [seq2rel](https://arxiv.org/abs/2204.01098)\n",
    "* Reviewed inference script for BioGPT RE with `BC5CDR` corpus\n",
    "* Reviewed training script for `BC5CDR` corpus with \n",
    "  * Familiarized myself with the arguments\n",
    "  * Examined the [train](https://github.com/facebookresearch/fairseq/blob/main/fairseq_cli/train.py) script in thhe `fairseq` package\n",
    "\n",
    "#### Results/Conclusion\n",
    "N/A\n",
    "\n",
    "#### Next Steps\n",
    "* Continue reading about the other corpora used for RE (`KD-DTI` and `DDI`)\n",
    "* Recreate training (preprocess and training) process for BioGPT from existing checkpoint to better understand how BioGPT codebase works\n",
    "  * Review Klara's repository as an example for NER (mostly done from scratch, unlike BioGPT scripts)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-20\n",
    "#### Project\n",
    "Relation Extraction (RE) and Named Entity Recognition (NER) for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Understanding the format of the corpora used for fine-tuned RE and the pre-processing, training/validation, and inference scripts used by the BioGPT authors.\n",
    "\n",
    "#### Description\n",
    "* Looked through Klara's repository\n",
    "  * GOAL: Try to retrain BERT as she did on NER with `ChemProt` and `UniProt`\n",
    "* Read abstract and introduction of `KD-DTI` paper, and examined `test.json` data to understand format of the corpus\n",
    "* Watched a [video](https://www.youtube.com/watch?v=pO3Jsr31s_Q) from Stanford Engineering (since I couldn't log into Berzelius)\n",
    "* Created a high-level work plan in regards to NER and RE benchmarking\n",
    "\n",
    "#### Results/Conclusion\n",
    "Ran into connection issues with Berzelius, so I was unable to start any jobs and instead focused on learning more about the corpora and pre-existing scripts (particularly Klara's repository) for training.\n",
    "\n",
    "#### Next Steps\n",
    "* Discuss work plan with Sonja (determine exactly which models I should train with which corpora to benchmark, and potentially integrate into the pipeline)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-21\n",
    "#### Project\n",
    "Relation Extraction (RE) and Named Entity Recognition (NER) for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "With Berzelius online again, the goal is to start a training job to recreate some results from the BioGPT paper (i.e RE with the BC5CDR)\n",
    "\n",
    "#### Description\n",
    "* Started a job to recreate the BioGPT RE training on the BC5CDR corpus, starting from a fine-tuned checkpoint.\n",
    "\n",
    "#### Results/Conclusion\n",
    "I set the job parameters to use 1 GPU for 8 hours. Likely not enough resources, but good enough for testing and to see some saved checkpoints in the morning\n",
    "\n",
    "#### Next Steps\n",
    "* Adjust the training scripts to meet the needs for my project (on Monday, after meeting with Sonja)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-24\n",
    "#### Project\n",
    "Relation Extraction (RE) and Named Entity Recognition (NER) for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Review results from training job started last Friday. Now, with my trained model, set up a script to perform inference (on free-form text or pre-processed text)\n",
    "\n",
    "#### Description\n",
    "* Looked over log files from training job started on Friday\n",
    "  * Reviewed training/validation loss and other statistics\n",
    "  * Reviewed full model architecture for BioGPT\n",
    "* Backed up my BioGPT scripts on Berzelius\n",
    "* Started a job to perform inference using my trained BioGPT model\n",
    "\n",
    "#### Results/Conclusion\n",
    "I was able to generate a `.detok.extracted.PubTator` file with extracted relations.\n",
    "For example, this was one of the lines in that file:\n",
    "```\n",
    "24100257\tCID\tC089750\tD054549\t1.0\n",
    "```\n",
    "This would suggest there is a relation between zolmitriptan (C089750; a Serotonin 5-HT1 receptor agonist)\n",
    "and Takotsubo Cardiomyopathy (D054549), and [this](https://pubmed.ncbi.nlm.nih.gov/24100257/) webpage proves that.\n",
    "\n",
    "\n",
    "#### Next Steps\n",
    "* See if other corpora (say `EU-ADR` or `GAD`) can be used with BioGPT\n",
    "  * If so, does BioGPT outperform BioBERT trained on these corpora?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-04-25\n",
    "#### Project\n",
    "Relation Extraction (RE) for Biomedical Literature\n",
    "\n",
    "#### Aim\n",
    "Review the formats of the `EU-ADR` and `GAD` corpora and see if they can be used directly with BioGPT.\n",
    "If not, investigate whether creating a pre-processing Python script is feasible (in terms of usability and my timeframe). \n",
    "\n",
    "#### Description\n",
    "* Read the following papers\n",
    "  * [EU-ADR](https://pubmed.ncbi.nlm.nih.gov/22554700/)\n",
    "  * [GAD](https://www.nature.com/articles/ng0504-431)\n",
    "* Downloaded the corpora from the [BioBERT](https://github.com/dmis-lab/biobert) GitHub page\n",
    "\n",
    "#### Results/Conclusion\n",
    "N/A\n",
    "\n",
    "#### Next Steps\n",
    "* Finalize goals and tasks for my project at the meeting tomorrow\n",
    "* Start adapting the corpora analyzed today to BioGPT?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
