Please see config.json for configuration!
Loaded config:
{
  "ignore": {
    "add_custom_labels": true,
    "build_art_corpus": true,
    "build_mixed_corpus": true,
    "bert_finetune": true,
    "evaluation": false,
    "plot": false
  },
  "add_custom_labels": {
    "input_path": "data/processed/",
    "output_path": "corpora/"
  },
  "build_art_corpus": {
    "input_path": "data/artificial-building-blocks/",
    "train_path": "corpora/artificial_pp_train.txt",
    "dev_path": "corpora/artificial_pp_dev.txt",
    "train_class_size": 1000,
    "dev_class_size": 500
  },
  "build_mixed_corpus": {
    "train_path": "corpora/chemprot_train.txt",
    "artificial_path": "data/artificial-custom-labeled/chemical-protein/",
    "artificial_ratio": 0.1,
    "output_path": "corpora/mixed_train_10.txt"
  },
  "bert_finetune": {
    "train_path": "corpora/chemprot_train.txt",
    "dev_path": "corpora/chemprot_dev.txt",
    "model_path": "models/chemprot-oversampled-10-v2/",
    "metrics_path": "models/chemprot-oversampled-10-v2/metrics.txt",
    "oversample": true,
    "epochs": 10
  },
  "evaluation": {
    "train_path": "corpora/chemprot_train.txt",
    "dev_path": "corpora/chemprot_dev.txt",
    "model_path": "models/chemprot-oversampled-10/",
    "metrics_path": "models/chemprot-oversampled-10/metrics.txt"
  },
  "plot": {
    "train_path": "corpora/artificial_pp_train.txt",
    "dev_path": "corpora/artificial_pp_dev.txt",
    "metrics_path": "models/chemprot-oversampled-10/metrics.txt",
    "output_path": "jacob-edits/figs"
  }
}

Ignoring script: build art corpus.

Ignoring script: build mixed corpus.

Ignoring script: add custom labels.

Ignoring script: BERT finetune.

Running eval script.

** I assume this is being done for each epoch model **

corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       0.97      0.89      0.93      2583
               NOT       0.79      0.97      0.87       241
           PART-OF       0.97      0.97      0.97       308
REGULATOR-NEGATIVE       0.94      0.95      0.94      2505
REGULATOR-POSITIVE       0.82      0.97      0.89       799

          accuracy                           0.93      6436
         macro avg       0.90      0.95      0.92      6436
      weighted avg       0.93      0.93      0.93      6436

[[[3785   68]
  [ 282 2301]]

 [[6132   63]
  [   8  233]]

 [[6118   10]
  [   9  299]]

 [[3784  147]
  [ 135 2370]]

 [[5465  172]
  [  26  773]]]
[[2301   31   10  128  113]
 [   2  233    0    5    1]
 [   7    0  299    0    2]
 [  48   31    0 2370   56]
 [  11    1    0   14  773]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       0.99      0.99      0.99      2583
               NOT       0.96      1.00      0.98       241
           PART-OF       1.00      1.00      1.00       308
REGULATOR-NEGATIVE       1.00      0.99      0.99      2505
REGULATOR-POSITIVE       0.96      1.00      0.98       799

          accuracy                           0.99      6436
         macro avg       0.98      0.99      0.99      6436
      weighted avg       0.99      0.99      0.99      6436

[[[3840   13]
  [  31 2552]]

 [[6184   11]
  [   0  241]]

 [[6128    0]
  [   0  308]]

 [[3919   12]
  [  37 2468]]

 [[5605   32]
  [   0  799]]]
[[2552    6    0   12   13]
 [   0  241    0    0    0]
 [   0    0  308    0    0]
 [  13    5    0 2468   19]
 [   0    0    0    0  799]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       0.98      0.96      0.97      2583
               NOT       0.85      1.00      0.91       241
           PART-OF       0.99      0.99      0.99       308
REGULATOR-NEGATIVE       0.97      0.97      0.97      2505
REGULATOR-POSITIVE       0.96      0.94      0.95       799

          accuracy                           0.97      6436
         macro avg       0.95      0.97      0.96      6436
      weighted avg       0.97      0.97      0.97      6436

[[[3801   52]
  [  98 2485]]

 [[6151   44]
  [   1  240]]

 [[6124    4]
  [   2  306]]

 [[3851   80]
  [  63 2442]]

 [[5607   30]
  [  46  753]]]
[[2485   17    4   56   21]
 [   1  240    0    0    0]
 [   2    0  306    0    0]
 [  28   26    0 2442    9]
 [  21    1    0   24  753]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       0.98      0.98      0.98      2583
               NOT       0.93      1.00      0.96       241
           PART-OF       0.98      1.00      0.99       308
REGULATOR-NEGATIVE       0.99      0.97      0.98      2505
REGULATOR-POSITIVE       0.94      0.98      0.96       799

          accuracy                           0.98      6436
         macro avg       0.97      0.99      0.98      6436
      weighted avg       0.98      0.98      0.98      6436

[[[3806   47]
  [  49 2534]]

 [[6177   18]
  [   1  240]]

 [[6123    5]
  [   0  308]]

 [[3913   18]
  [  77 2428]]

 [[5585   52]
  [  13  786]]]
[[2534    8    4   14   23]
 [   0  240    0    1    0]
 [   0    0  308    0    0]
 [  38   10    0 2428   29]
 [   9    0    1    3  786]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       1.00      0.99      1.00      2583
               NOT       0.98      1.00      0.99       241
           PART-OF       1.00      1.00      1.00       308
REGULATOR-NEGATIVE       1.00      1.00      1.00      2505
REGULATOR-POSITIVE       0.99      1.00      0.99       799

          accuracy                           1.00      6436
         macro avg       0.99      1.00      1.00      6436
      weighted avg       1.00      1.00      1.00      6436

[[[3848    5]
  [  19 2564]]

 [[6190    5]
  [   0  241]]

 [[6128    0]
  [   0  308]]

 [[3922    9]
  [   7 2498]]

 [[5629    8]
  [   1  798]]]
[[2564    5    0    8    6]
 [   0  241    0    0    0]
 [   0    0  308    0    0]
 [   5    0    0 2498    2]
 [   0    0    0    1  798]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       1.00      0.99      1.00      2583
               NOT       0.98      1.00      0.99       241
           PART-OF       1.00      1.00      1.00       308
REGULATOR-NEGATIVE       1.00      1.00      1.00      2505
REGULATOR-POSITIVE       0.99      1.00      0.99       799

          accuracy                           1.00      6436
         macro avg       0.99      1.00      0.99      6436
      weighted avg       1.00      1.00      1.00      6436

[[[3852    1]
  [  24 2559]]

 [[6189    6]
  [   0  241]]

 [[6127    1]
  [   0  308]]

 [[3920   11]
  [   6 2499]]

 [[5626   11]
  [   0  799]]]
[[2559    5    1   11    7]
 [   0  241    0    0    0]
 [   0    0  308    0    0]
 [   1    1    0 2499    4]
 [   0    0    0    0  799]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       1.00      0.99      0.99      2583
               NOT       0.98      1.00      0.99       241
           PART-OF       1.00      1.00      1.00       308
REGULATOR-NEGATIVE       0.99      1.00      1.00      2505
REGULATOR-POSITIVE       0.99      1.00      0.99       799

          accuracy                           1.00      6436
         macro avg       0.99      1.00      1.00      6436
      weighted avg       1.00      1.00      1.00      6436

[[[3853    0]
  [  26 2557]]

 [[6191    4]
  [   1  240]]

 [[6128    0]
  [   0  308]]

 [[3914   17]
  [   3 2502]]

 [[5628    9]
  [   0  799]]]
[[2557    4    0   16    6]
 [   0  240    0    1    0]
 [   0    0  308    0    0]
 [   0    0    0 2502    3]
 [   0    0    0    0  799]]
corpora/chemprot_train.txt
                    precision    recall  f1-score   support

        INTERACTOR       1.00      0.99      0.99      2583
               NOT       0.98      1.00      0.99       241
           PART-OF       0.99      1.00      1.00       308
REGULATOR-NEGATIVE       0.99      1.00      0.99      2505
REGULATOR-POSITIVE       0.98      1.00      0.99       799

          accuracy                           0.99      6436
         macro avg       0.99      1.00      0.99      6436
      weighted avg       0.99      0.99      0.99      6436

[[[3849    4]
  [  28 2555]]

 [[6191    4]
  [   1  240]]

 [[6126    2]
  [   0  308]]

 [[3914   17]
  [  10 2495]]

 [[5624   13]
  [   1  798]]]
[[2555    4    2   15    7]
 [   0  240    0    1    0]
 [   0    0  308    0    0]
 [   4    0    0 2495    6]
 [   0    0    0    1  798]]
corpora/chemprot_train.txt
Traceback (most recent call last):
  File "/proj/berzelius-2021-21/users/jacob/conda_envs/nilsre/lib/python3.7/site-packages/transformers/modeling_utils.py", line 442, in load_state_dict
    return torch.load(checkpoint_file, map_location="cpu")
  File "/proj/berzelius-2021-21/users/jacob/conda_envs/nilsre/lib/python3.7/site-packages/torch/serialization.py", line 593, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/proj/berzelius-2021-21/users/jacob/conda_envs/nilsre/lib/python3.7/site-packages/torch/serialization.py", line 762, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '{'.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/proj/berzelius-2021-21/users/jacob/conda_envs/nilsre/lib/python3.7/site-packages/transformers/modeling_utils.py", line 456, in load_state_dict
    ) from e
ValueError: Unable to locate the file models/chemprot-oversampled-10/metrics.txt which is necessary to load this pretrained model. Make sure you have saved the model properly.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 125, in <module>
    run_eval(config["evaluation"], ignore=ignore["evaluation"])
  File "main.py", line 71, in run_eval
    evaluation.run(eval_config["train_path"], eval_config["model_path"], eval_config["metrics_path"]) 
  File "/proj/berzelius-2021-21/users/jacob/BioNLP/nils/scripts/evaluation.py", line 86, in run
    metrics[filename] = evaluate(model_path + model, input_path, metrics[filename])
  File "/proj/berzelius-2021-21/users/jacob/BioNLP/nils/scripts/evaluation.py", line 25, in evaluate
    model_path = BertForSequenceClassification.from_pretrained(input_dir, local_files_only=True, cache_dir=None)
  File "/proj/berzelius-2021-21/users/jacob/conda_envs/nilsre/lib/python3.7/site-packages/transformers/modeling_utils.py", line 2560, in from_pretrained
    state_dict = load_state_dict(resolved_archive_file)
  File "/proj/berzelius-2021-21/users/jacob/conda_envs/nilsre/lib/python3.7/site-packages/transformers/modeling_utils.py", line 459, in load_state_dict
    f"Unable to load weights from pytorch checkpoint file for '{checkpoint_file}' "
OSError: Unable to load weights from pytorch checkpoint file for 'models/chemprot-oversampled-10/metrics.txt' at 'models/chemprot-oversampled-10/metrics.txt'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.