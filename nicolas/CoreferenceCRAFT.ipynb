{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoreferenceCRAFT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BbXcynV_y3S"
      },
      "source": [
        "Installing neuralcoref from source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3lJDHKZDF8z"
      },
      "source": [
        "!git clone https://github.com/huggingface/neuralcoref.git\n",
        "%cd neuralcoref\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mythz8W1_7rH"
      },
      "source": [
        "Importing files from drive. To do parse the corpus with the following code you'd need the CRAFT-conll folder and the conllparser.py modified file on your MyDrive folder of Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPX-BmdKAAK8",
        "outputId": "42b79db2-911c-4b93-9a19-95b45b2c5827"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itf1fnrq_262"
      },
      "source": [
        "Replacing parser with modified file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdR6SwzC7wz6"
      },
      "source": [
        "!rm neuralcoref/neuralcoref/train/conllparser.py\n",
        "!cp gdrive/MyDrive/conllparser.py neuralcoref/neuralcoref/train/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYwZK7oHAppL"
      },
      "source": [
        "Parsing dev files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yUK9a49AYg3"
      },
      "source": [
        "!python -m neuralcoref.train.conllparser --path  gdrive/MyDrive/CRAFT-conll/dev/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCsvca59Q6p7"
      },
      "source": [
        "Parsing training set separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggpAOcJDoYb6"
      },
      "source": [
        "!python -m neuralcoref.train.conllparser --path  gdrive/MyDrive/CRAFT-conll/train-subset-1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtYVuVP6HX1r"
      },
      "source": [
        "!python -m neuralcoref.train.conllparser --path  gdrive/MyDrive/CRAFT-conll/train-subset-2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7gBNipdUBPb"
      },
      "source": [
        "Concatenating results in train folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miOD2JyfUAqD"
      },
      "source": [
        "%cd gdrive/MyDrive/CRAFT-conll/\n",
        "!cat train-subset-1/key.txt train-subset-2/key.txt > train/key.txt\n",
        "!mkdir train/numpy/\n",
        "!cat train-subset-1/numpy/conll_tokens.bin train-subset-2/numpy/conll_tokens.bin > train/numpy/conll_tokens.bin\n",
        "!cat train-subset-1/numpy/doc.bin train-subset-2/numpy/doc.bin > train/numpy/doc.bin\n",
        "!cat train-subset-1/numpy/locations.bin train-subset-2/numpy/locations.bin > train/numpy/locations.bin\n",
        "!cat train-subset-1/numpy/mentions_features.npy train-subset-2/numpy/mentions_features.npy > train/numpy/mentions_features.npy\n",
        "!cat train-subset-1/numpy/mentions_labels.npy train-subset-2/numpy/mentions_labels.npy > train/numpy/mentions_labels.npy\n",
        "!cat train-subset-1/numpy/mentions_pairs_length.npy train-subset-2/numpy/mentions_pairs_length.npy > train/numpy/mentions_pairs_length.npy\n",
        "!cat train-subset-1/numpy/mentions_pairs_start_index.npy train-subset-2/numpy/mentions_pairs_start_index.npy > train/numpy/mentions_pairs_start_index.npy\n",
        "!cat train-subset-1/numpy/mentions_spans.npy train-subset-2/numpy/mentions_spans.npy > train/numpy/mentions_spans.npy\n",
        "!cat train-subset-1/numpy/mentions_words.npy train-subset-2/numpy/mentions_words.npy > train/numpy/mentions_words.npy\n",
        "!cat train-subset-1/numpy/pairs_ant_index.npy train-subset-2/numpy/pairs_ant_index.npy > train/numpy/pairs_ant_index.npy\n",
        "!cat train-subset-1/numpy/pairs_features.npy train-subset-2/numpy/pairs_features.npy > train/numpy/pairs_features.npy\n",
        "!cat train-subset-1/numpy/spacy_lookup.bin train-subset-2/numpy/spacy_lookup.bin > train/numpy/spacy_lookup.bin\n",
        "!cat train-subset-1/numpy/static_word_embeddings.npy train-subset-2/numpy/static_word_embeddings.npy > train/numpy/static_word_embeddings.npy\n",
        "!cat train-subset-1/numpy/static_word_vocabulary.txt train-subset-2/numpy/static_word_vocabulary.txt > train/numpy/static_word_vocabulary.txt\n",
        "!cat train-subset-1/numpy/tuned_word_embeddings.npy train-subset-2/numpy/tuned_word_embeddings.npy > train/numpy/tuned_word_embeddings.npy\n",
        "!cat train-subset-1/numpy/tuned_word_vocabulary.txt train-subset-2/numpy/tuned_word_vocabulary.txt > train/numpy/tuned_word_vocabulary.txt\n",
        "%cd ../../.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGFBnyEYREEb"
      },
      "source": [
        "Parsing test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuXls6WtoZHD"
      },
      "source": [
        "!python -m neuralcoref.train.conllparser --path  gdrive/MyDrive/CRAFT-conll/test/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7CYYSjkb2Hd"
      },
      "source": [
        "Installing tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fddO2kQlZ4dG"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}